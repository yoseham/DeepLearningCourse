{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "978ea4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch import nn\n",
    "from easydict import EasyDict as edict\n",
    "from models import Generator, Discriminator, TruncatedVGG19\n",
    "from datasets import SRDataset\n",
    "from utils import *\n",
    "from solver import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882a111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from solver import train_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a0d55a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "config = edict()\n",
    "config.csv_folder = '../data/SRDataset'\n",
    "config.HR_data_folder = '../data/SRDataset/div2k/DIV2K_train_HR'\n",
    "config.LR_data_folder = '../data/SRDataset/div2k/DIV2K_train_LR_bicubic/X4'\n",
    "config.crop_size = 96\n",
    "config.scaling_factor = 4\n",
    "\n",
    "# Generator parameters\n",
    "config.G = edict()\n",
    "config.G.large_kernel_size = 9\n",
    "config.G.small_kernel_size = 3\n",
    "config.G.n_channels = 64\n",
    "config.G.n_blocks = 16\n",
    "\n",
    "# Discriminator parameters\n",
    "config.D = edict()\n",
    "config.D.kernel_size = 3\n",
    "config.D.n_channels = 64\n",
    "config.D.n_blocks = 8\n",
    "config.D.fc_size = 1024\n",
    "\n",
    "# Learning parameters\n",
    "config.checkpoint_init = None\n",
    "config.checkpoint = None # path to model (SRGAN) checkpoint, None if none\n",
    "config.batch_size = 64\n",
    "config.start_epoch = 0\n",
    "config.start_epoch_init = 0\n",
    "config.epochs = 2\n",
    "config.workers = 4\n",
    "config.vgg19_i = 5  # the index i in the definition for VGG loss; see paper\n",
    "config.vgg19_j = 4  # the index j in the definition for VGG loss; see paper\n",
    "config.beta = 1e-3  # the coefficient to weight the adversarial loss in the perceptual loss\n",
    "config.print_freq = 100\n",
    "config.lr = 1e-3\n",
    "config.SGD = edict()\n",
    "config.SGD.lr= 5e-2\n",
    "config.SGD.momentum=0.9\n",
    "\n",
    "# Default device\n",
    "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config.device = \"mps\"\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b93e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.checkpoint_init is None and config.checkpoint is None:\n",
    "    # Generator\n",
    "    generator = Generator(config)\n",
    "    # generator's optimizer in initialization phase\n",
    "    optimizer_g_init = torch.optim.SGD(params=filter(lambda p: p.requires_grad, generator.parameters()), \n",
    "                                       lr=config.SGD.lr, \n",
    "                                       momentum=config.SGD.momentum)\n",
    "    # generator's optimizer\n",
    "    optimizer_g = torch.optim.Adam(params=filter(lambda p: p.requires_grad, generator.parameters()),\n",
    "                                   lr=config.lr)\n",
    "\n",
    "    # Discriminator\n",
    "    discriminator = Discriminator(config)\n",
    "    optimizer_d = torch.optim.Adam(params=filter(lambda p: p.requires_grad, discriminator.parameters()),\n",
    "                                   lr=config.lr)\n",
    "\n",
    "elif config.checkpoint_init is not None and config.checkpoint is None:\n",
    "    checkpoint = torch.load(config.checkpoint_init)\n",
    "    config.start_epoch_init = checkpoint['epoch'] + 1\n",
    "    generator = checkpoint['model']\n",
    "    optimizer_g_init = checkpoint['optimizer']\n",
    "    print(\"\\nLoaded checkpoint from epoch %d.\\n\" % (checkpoint['epoch'] + 1))\n",
    "\n",
    "    # generator's optimizer\n",
    "    optimizer_g = torch.optim.Adam(params=filter(lambda p: p.requires_grad, generator.parameters()),\n",
    "                                   lr=config.lr)\n",
    "\n",
    "    # Discriminator\n",
    "    discriminator = Discriminator(config)\n",
    "    optimizer_d = torch.optim.Adam(params=filter(lambda p: p.requires_grad, discriminator.parameters()),\n",
    "                                   lr=config.lr)\n",
    "\n",
    "\n",
    "elif config.checkpoint is not None:\n",
    "    checkpoint = torch.load(config.checkpoint)\n",
    "    config.start_epoch = checkpoint['epoch'] + 1\n",
    "    generator = checkpoint['generator']\n",
    "    discriminator = checkpoint['discriminator']\n",
    "    optimizer_g = checkpoint['optimizer_g']\n",
    "    optimizer_d = checkpoint['optimizer_d']\n",
    "    print(\"\\nLoaded checkpoint from epoch %d.\\n\" % (checkpoint['epoch'] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ca630fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaoxiong.yang/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/chaoxiong.yang/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TruncatedVGG19(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truncated VGG19 network to be used in the loss calculation\n",
    "truncated_vgg19 = TruncatedVGG19(i=config.vgg19_i, j=config.vgg19_j)\n",
    "truncated_vgg19.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced01618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "init_loss_criterion = nn.MSELoss()\n",
    "content_loss_criterion = nn.MSELoss()\n",
    "adversarial_loss_criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d91cd705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to default device\n",
    "generator = generator.to(config.device)\n",
    "discriminator = discriminator.to(config.device)\n",
    "truncated_vgg19 = truncated_vgg19.to(config.device)\n",
    "content_loss_criterion = content_loss_criterion.to(config.device)\n",
    "adversarial_loss_criterion = adversarial_loss_criterion.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2184bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataloaders\n",
    "train_dataset = SRDataset(split='train', config=config)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=config.batch_size,\n",
    "                                           shuffle=True, \n",
    "                                           num_workers=config.workers,\n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a48c5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/1250]----Batch Time 6.020 (6.020)----MSE Loss 22.5502 (22.5502)\n",
      "Epoch: [0][100/1250]----Batch Time 2.301 (1.099)----MSE Loss nan (nan)\n"
     ]
    }
   ],
   "source": [
    "# initialize learning (G)\n",
    "config.n_epoch_init = 1\n",
    "\n",
    "for epoch in range(config.start_epoch_init, config.n_epoch_init):\n",
    "    train_init(train_loader=train_loader,\n",
    "         model=generator,\n",
    "         loss_criterion=init_loss_criterion,\n",
    "         optimizer=optimizer_g_init,\n",
    "         epoch=epoch,\n",
    "         device=config.device,\n",
    "         print_freq=config.print_freq\n",
    "    )\n",
    "    torch.save({'epoch': epoch,\n",
    "              'model': generator,\n",
    "              'optimizer': optimizer_g_init},\n",
    "              'checkpoint_generator.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52630e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epochs\n",
    "for epoch in range(config.start_epoch, config.epochs):\n",
    "    # At the halfway point, reduce learning rate to a tenth\n",
    "    if epoch == int(config.epochs / 2 + 1):\n",
    "        adjust_learning_rate(optimizer_g, 0.1)\n",
    "        adjust_learning_rate(optimizer_d, 0.1)\n",
    "    # One epoch's training\n",
    "    train(train_loader=train_loader,\n",
    "          generator=generator,\n",
    "          discriminator=discriminator,\n",
    "          truncated_vgg19=truncated_vgg19,\n",
    "          content_loss_criterion=content_loss_criterion,\n",
    "          adversarial_loss_criterion=adversarial_loss_criterion,\n",
    "          optimizer_g=optimizer_g,\n",
    "          optimizer_d=optimizer_d,\n",
    "          epoch=epoch,\n",
    "          device=config.device,\n",
    "          beta=config.beta,\n",
    "          print_freq=config.print_freq)\n",
    "    # Save checkpoint\n",
    "    torch.save({'epoch': epoch,\n",
    "                'generator': generator,\n",
    "                'discriminator': discriminator,\n",
    "                'optimizer_g': optimizer_g,\n",
    "                'optimizer_d': optimizer_d},\n",
    "                'checkpoint_srgan2.pth.tar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
