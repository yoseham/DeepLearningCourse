{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from datasets import SRDataset\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "csv_folder = '../data/SRDataset'  # folder with CSV data files\n",
    "test_data_names = [\"Set5\", \"Set14\", \"B100\", \"Urban100\", \"valid\"]\n",
    "HR_data_folders = ['../data/SRDataset/benchmark/Set5/HR',\n",
    "                  '../data/SRDataset/benchmark/Set14/HR',\n",
    "                  '../data/SRDataset/benchmark/B100/HR',\n",
    "                  '../data/SRDataset/benchmark/Urban100/HR',\n",
    "                  '../data/SRDataset/div2k/DIV2K_valid_HR']\n",
    "LR_data_folders = ['../data/SRDataset/benchmark/Set5/LR_bicubic/X4',\n",
    "                  '../data/SRDataset/benchmark/Set14/LR_bicubic/X4',\n",
    "                  '../data/SRDataset/benchmark/B100/LR_bicubic/X4',\n",
    "                  '../data/SRDataset/benchmark/Urban100/LR_bicubic/X4',\n",
    "                  '../data/SRDataset/div2k/DIV2K_valid_LR_bicubic/X4']\n",
    "srgan_checkpoint = \"./checkpoint_srgan.pth.tar\"\n",
    "scaling_factor = 4\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "srgan_generator = torch.load(srgan_checkpoint)['generator'].to(device)\n",
    "srgan_generator.eval()\n",
    "model = srgan_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Set5:\n",
      "\n",
      "PSNR - 12.021\n",
      "SSIM - 0.275\n",
      "\n",
      "For Set14:\n",
      "\n",
      "PSNR - 13.386\n",
      "SSIM - 0.288\n",
      "\n",
      "For B100:\n",
      "\n",
      "PSNR - 13.760\n",
      "SSIM - 0.298\n",
      "\n",
      "For Urban100:\n",
      "\n",
      "PSNR - 12.454\n",
      "SSIM - 0.266\n",
      "\n",
      "For valid:\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m sr_imgs \u001b[38;5;241m=\u001b[39m model(lr_imgs)\n\u001b[1;32m     28\u001b[0m sr_imgs_y \u001b[38;5;241m=\u001b[39m convert_image(sr_imgs, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[-1, 1]\u001b[39m\u001b[38;5;124m'\u001b[39m, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my-channel\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m hr_imgs_y \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhr_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[-1, 1]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my-channel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     30\u001b[0m psnr \u001b[38;5;241m=\u001b[39m peak_signal_noise_ratio(hr_imgs_y\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), sr_imgs_y\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), data_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255.\u001b[39m)\n\u001b[1;32m     31\u001b[0m ssim \u001b[38;5;241m=\u001b[39m structural_similarity(hr_imgs_y\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), sr_imgs_y\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), data_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255.\u001b[39m)\n",
      "File \u001b[0;32m~/DeepLearning/案例7/code/utils.py:25\u001b[0m, in \u001b[0;36mconvert_image\u001b[0;34m(img, source, target, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpil\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[0, 255]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[0, 1]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[-1, 1]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet-norm\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     22\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my-channel\u001b[39m\u001b[38;5;124m'\u001b[39m}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert to target format \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m target\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Some constants\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m rgb_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m65.481\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128.553\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24.966\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m imagenet_mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     27\u001b[0m imagenet_std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "for i in range(len(test_data_names)):\n",
    "    print(\"\\nFor %s:\\n\" % test_data_names[i])\n",
    "    # Custom dataloader\n",
    "    config = edict()\n",
    "    config.csv_folder = csv_folder\n",
    "    config.HR_data_folder = HR_data_folders[i]\n",
    "    config.LR_data_folder = LR_data_folders[i]\n",
    "    config.crop_size = 0\n",
    "    config.scaling_factor = scaling_factor\n",
    "    test_dataset = SRDataset(split=test_data_names[i], config=config)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=4,\n",
    "                                              pin_memory=True)\n",
    "    PSNRs = AverageMeter()\n",
    "    SSIMs = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, (lr_imgs, hr_imgs) in enumerate(test_loader):\n",
    "            lr_imgs = lr_imgs.to(device)\n",
    "            hr_imgs = hr_imgs.to(device)\n",
    "            lr_imgs = convert_image(lr_imgs, source='[0, 1]', target='imagenet-norm', device=device)\n",
    "            hr_imgs = convert_image(hr_imgs, source='[0, 1]', target='[-1, 1]', device=device)\n",
    "            \n",
    "            sr_imgs = model(lr_imgs)\n",
    "            \n",
    "            sr_imgs_y = convert_image(sr_imgs, source='[-1, 1]', target='y-channel', device=device).squeeze(0)\n",
    "            hr_imgs_y = convert_image(hr_imgs, source='[-1, 1]', target='y-channel', device=device).squeeze(0)\n",
    "            psnr = peak_signal_noise_ratio(hr_imgs_y.cpu().numpy(), sr_imgs_y.cpu().numpy(), data_range=255.)\n",
    "            ssim = structural_similarity(hr_imgs_y.cpu().numpy(), sr_imgs_y.cpu().numpy(), data_range=255.)\n",
    "            PSNRs.update(psnr, lr_imgs.size(0))\n",
    "            SSIMs.update(ssim, lr_imgs.size(0))\n",
    "            \n",
    "    # Print average PSNR and SSIM\n",
    "    print('PSNR - {psnrs.avg:.3f}'.format(psnrs=PSNRs))\n",
    "    print('SSIM - {ssims.avg:.3f}'.format(ssims=SSIMs))\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
