{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 案例2: 构建自己的多层感知机: MNIST 手写数字识别\n",
    "\n",
    "### 本案例要求如下\n",
    "- #### 实现SGD优化器 (`./optimizer.py`)\n",
    "- #### 实现全连接层FCLayer前向和后向计算 (`layers/fc_layer.py`)\n",
    "- #### 实现激活层SigmoidLayer前向和后向计算 (`layers/sigmoid_layer.py`)\n",
    "- #### 实现激活层ReLULayer前向和后向计算 (`layers/relu_layer.py`)\n",
    "- #### 实现损失层EuclideanLossLayer (`criterion/euclidean_loss.py`)\n",
    "- #### 实现损失层SoftmaxCrossEntropyLossLayer (`criterion/softmax_cross_entropy.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaoxiong.yang/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "from network import Network\n",
    "from solver import train, test\n",
    "from plot import plot_loss_and_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 读入MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    # 归一化处理\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.reshape(image, [784])\n",
    "    image = image / 255.0\n",
    "    image = image - tf.reduce_mean(image)\n",
    "    return image\n",
    "\n",
    "def decode_label(label):\n",
    "    # 将标签变为one-hot编码\n",
    "    return tf.one_hot(label, depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "x_train = tf.data.Dataset.from_tensor_slices(x_train).map(decode_image)\n",
    "y_train = tf.data.Dataset.from_tensor_slices(y_train).map(decode_label)\n",
    "data_train = tf.data.Dataset.zip((x_train, y_train))\n",
    "\n",
    "x_test = tf.data.Dataset.from_tensor_slices(x_test).map(decode_image)\n",
    "y_test = tf.data.Dataset.from_tensor_slices(y_test).map(decode_label)\n",
    "data_test = tf.data.Dataset.zip((x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 超参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "max_epoch = 20\n",
    "init_std = 0.01\n",
    "\n",
    "learning_rate_SGD = 0.001\n",
    "weight_decay = 0.1\n",
    "\n",
    "disp_freq = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. 使用欧式距离损失训练多层感知机(MLP with Euclidean Loss)\n",
    "第一部分将使用欧式距离损失训练多层感知机. \n",
    "分别使用**Sigmoid**激活函数和**ReLU**激活函数.\n",
    "### TODO\n",
    "执行以下代码之前，请完成 **./optimizer.py** 和 **criterion/euclidean_loss.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from criterion import EuclideanLossLayer\n",
    "from optimizer import SGD\n",
    "\n",
    "criterion = EuclideanLossLayer()\n",
    "\n",
    "sgd = SGD(learning_rate_SGD, weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.1 使用欧式距离损失和Sigmoid激活函数训练多层感知机\n",
    "训练带有一个隐含层且神经元个数为128的多层感知机，使用欧式距离损失和Sigmoid激活函数.\n",
    "\n",
    "### TODO\n",
    "执行以下代码之前，请完成 **layers/fc_layer.py** 和 **layers/sigmoid_layer.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from layers import FCLayer, SigmoidLayer\n",
    "\n",
    "sigmoidMLP = Network()\n",
    "# 使用FCLayer和SigmoidLayer构建多层感知机\n",
    "# 128为隐含层的神经元数目\n",
    "sigmoidMLP.add(FCLayer(784, 128))\n",
    "sigmoidMLP.add(SigmoidLayer())\n",
    "sigmoidMLP.add(FCLayer(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chaoxiong.yang/DeepLearning/实验二/mlp/solver.py:15: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n",
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 21:02:25.860230: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-09-20 21:02:25.860883: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-09-20 21:02:26.031853: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-09-20 21:02:26.043043: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][20]\t Batch [0][550]\t Training Loss 26.2506\t Accuracy 0.1100\n",
      "Epoch [0][20]\t Batch [50][550]\t Training Loss 8.2680\t Accuracy 0.1925\n",
      "Epoch [0][20]\t Batch [100][550]\t Training Loss 6.5154\t Accuracy 0.2815\n",
      "Epoch [0][20]\t Batch [150][550]\t Training Loss 5.8323\t Accuracy 0.3462\n",
      "Epoch [0][20]\t Batch [200][550]\t Training Loss 5.4116\t Accuracy 0.4067\n",
      "Epoch [0][20]\t Batch [250][550]\t Training Loss 5.1286\t Accuracy 0.4604\n",
      "Epoch [0][20]\t Batch [300][550]\t Training Loss 4.9187\t Accuracy 0.5042\n",
      "Epoch [0][20]\t Batch [350][550]\t Training Loss 4.7571\t Accuracy 0.5395\n",
      "Epoch [0][20]\t Batch [400][550]\t Training Loss 4.6244\t Accuracy 0.5688\n",
      "Epoch [0][20]\t Batch [450][550]\t Training Loss 4.5101\t Accuracy 0.5937\n",
      "Epoch [0][20]\t Batch [500][550]\t Training Loss 4.4126\t Accuracy 0.6150\n",
      "\n",
      "Epoch [0]\t Average training loss 4.3266\t Average training accuracy 0.6333\n",
      "Epoch [0]\t Average validation loss 3.3201\t Average validation accuracy 0.8448\n",
      "\n",
      "Epoch [1][20]\t Batch [0][550]\t Training Loss 3.2892\t Accuracy 0.8300\n",
      "Epoch [1][20]\t Batch [50][550]\t Training Loss 3.3732\t Accuracy 0.8365\n",
      "Epoch [1][20]\t Batch [100][550]\t Training Loss 3.3638\t Accuracy 0.8385\n",
      "Epoch [1][20]\t Batch [150][550]\t Training Loss 3.3668\t Accuracy 0.8323\n",
      "Epoch [1][20]\t Batch [200][550]\t Training Loss 3.3443\t Accuracy 0.8358\n",
      "Epoch [1][20]\t Batch [250][550]\t Training Loss 3.3248\t Accuracy 0.8373\n",
      "Epoch [1][20]\t Batch [300][550]\t Training Loss 3.3083\t Accuracy 0.8392\n",
      "Epoch [1][20]\t Batch [350][550]\t Training Loss 3.2968\t Accuracy 0.8388\n",
      "Epoch [1][20]\t Batch [400][550]\t Training Loss 3.2818\t Accuracy 0.8408\n",
      "Epoch [1][20]\t Batch [450][550]\t Training Loss 3.2665\t Accuracy 0.8422\n",
      "Epoch [1][20]\t Batch [500][550]\t Training Loss 3.2519\t Accuracy 0.8432\n",
      "\n",
      "Epoch [1]\t Average training loss 3.2340\t Average training accuracy 0.8446\n",
      "Epoch [1]\t Average validation loss 2.9045\t Average validation accuracy 0.8894\n",
      "\n",
      "Epoch [2][20]\t Batch [0][550]\t Training Loss 2.8923\t Accuracy 0.8900\n",
      "Epoch [2][20]\t Batch [50][550]\t Training Loss 2.9988\t Accuracy 0.8733\n",
      "Epoch [2][20]\t Batch [100][550]\t Training Loss 2.9988\t Accuracy 0.8705\n",
      "Epoch [2][20]\t Batch [150][550]\t Training Loss 3.0175\t Accuracy 0.8658\n",
      "Epoch [2][20]\t Batch [200][550]\t Training Loss 3.0045\t Accuracy 0.8682\n",
      "Epoch [2][20]\t Batch [250][550]\t Training Loss 2.9929\t Accuracy 0.8683\n",
      "Epoch [2][20]\t Batch [300][550]\t Training Loss 2.9846\t Accuracy 0.8690\n",
      "Epoch [2][20]\t Batch [350][550]\t Training Loss 2.9810\t Accuracy 0.8682\n",
      "Epoch [2][20]\t Batch [400][550]\t Training Loss 2.9724\t Accuracy 0.8694\n",
      "Epoch [2][20]\t Batch [450][550]\t Training Loss 2.9636\t Accuracy 0.8704\n",
      "Epoch [2][20]\t Batch [500][550]\t Training Loss 2.9553\t Accuracy 0.8708\n",
      "\n",
      "Epoch [2]\t Average training loss 2.9426\t Average training accuracy 0.8713\n",
      "Epoch [2]\t Average validation loss 2.6537\t Average validation accuracy 0.9076\n",
      "\n",
      "Epoch [3][20]\t Batch [0][550]\t Training Loss 2.6509\t Accuracy 0.9200\n",
      "Epoch [3][20]\t Batch [50][550]\t Training Loss 2.7557\t Accuracy 0.8922\n",
      "Epoch [3][20]\t Batch [100][550]\t Training Loss 2.7623\t Accuracy 0.8874\n",
      "Epoch [3][20]\t Batch [150][550]\t Training Loss 2.7861\t Accuracy 0.8823\n",
      "Epoch [3][20]\t Batch [200][550]\t Training Loss 2.7765\t Accuracy 0.8843\n",
      "Epoch [3][20]\t Batch [250][550]\t Training Loss 2.7674\t Accuracy 0.8848\n",
      "Epoch [3][20]\t Batch [300][550]\t Training Loss 2.7613\t Accuracy 0.8853\n",
      "Epoch [3][20]\t Batch [350][550]\t Training Loss 2.7607\t Accuracy 0.8845\n",
      "Epoch [3][20]\t Batch [400][550]\t Training Loss 2.7549\t Accuracy 0.8853\n",
      "Epoch [3][20]\t Batch [450][550]\t Training Loss 2.7493\t Accuracy 0.8861\n",
      "Epoch [3][20]\t Batch [500][550]\t Training Loss 2.7440\t Accuracy 0.8860\n",
      "\n",
      "Epoch [3]\t Average training loss 2.7343\t Average training accuracy 0.8864\n",
      "Epoch [3]\t Average validation loss 2.4700\t Average validation accuracy 0.9190\n",
      "\n",
      "Epoch [4][20]\t Batch [0][550]\t Training Loss 2.4637\t Accuracy 0.9300\n",
      "Epoch [4][20]\t Batch [50][550]\t Training Loss 2.5707\t Accuracy 0.9063\n",
      "Epoch [4][20]\t Batch [100][550]\t Training Loss 2.5837\t Accuracy 0.8998\n",
      "Epoch [4][20]\t Batch [150][550]\t Training Loss 2.6107\t Accuracy 0.8948\n",
      "Epoch [4][20]\t Batch [200][550]\t Training Loss 2.6031\t Accuracy 0.8963\n",
      "Epoch [4][20]\t Batch [250][550]\t Training Loss 2.5966\t Accuracy 0.8968\n",
      "Epoch [4][20]\t Batch [300][550]\t Training Loss 2.5924\t Accuracy 0.8969\n",
      "Epoch [4][20]\t Batch [350][550]\t Training Loss 2.5938\t Accuracy 0.8962\n",
      "Epoch [4][20]\t Batch [400][550]\t Training Loss 2.5905\t Accuracy 0.8963\n",
      "Epoch [4][20]\t Batch [450][550]\t Training Loss 2.5875\t Accuracy 0.8966\n",
      "Epoch [4][20]\t Batch [500][550]\t Training Loss 2.5849\t Accuracy 0.8963\n",
      "\n",
      "Epoch [4]\t Average training loss 2.5775\t Average training accuracy 0.8965\n",
      "Epoch [4]\t Average validation loss 2.3356\t Average validation accuracy 0.9254\n",
      "\n",
      "Epoch [5][20]\t Batch [0][550]\t Training Loss 2.3241\t Accuracy 0.9500\n",
      "Epoch [5][20]\t Batch [50][550]\t Training Loss 2.4339\t Accuracy 0.9124\n",
      "Epoch [5][20]\t Batch [100][550]\t Training Loss 2.4512\t Accuracy 0.9071\n",
      "Epoch [5][20]\t Batch [150][550]\t Training Loss 2.4802\t Accuracy 0.9028\n",
      "Epoch [5][20]\t Batch [200][550]\t Training Loss 2.4734\t Accuracy 0.9040\n",
      "Epoch [5][20]\t Batch [250][550]\t Training Loss 2.4686\t Accuracy 0.9046\n",
      "Epoch [5][20]\t Batch [300][550]\t Training Loss 2.4659\t Accuracy 0.9048\n",
      "Epoch [5][20]\t Batch [350][550]\t Training Loss 2.4686\t Accuracy 0.9044\n",
      "Epoch [5][20]\t Batch [400][550]\t Training Loss 2.4671\t Accuracy 0.9043\n",
      "Epoch [5][20]\t Batch [450][550]\t Training Loss 2.4658\t Accuracy 0.9045\n",
      "Epoch [5][20]\t Batch [500][550]\t Training Loss 2.4651\t Accuracy 0.9040\n",
      "\n",
      "Epoch [5]\t Average training loss 2.4594\t Average training accuracy 0.9043\n",
      "Epoch [5]\t Average validation loss 2.2340\t Average validation accuracy 0.9320\n",
      "\n",
      "Epoch [6][20]\t Batch [0][550]\t Training Loss 2.2213\t Accuracy 0.9500\n",
      "Epoch [6][20]\t Batch [50][550]\t Training Loss 2.3316\t Accuracy 0.9182\n",
      "Epoch [6][20]\t Batch [100][550]\t Training Loss 2.3516\t Accuracy 0.9131\n",
      "Epoch [6][20]\t Batch [150][550]\t Training Loss 2.3820\t Accuracy 0.9093\n",
      "Epoch [6][20]\t Batch [200][550]\t Training Loss 2.3757\t Accuracy 0.9103\n",
      "Epoch [6][20]\t Batch [250][550]\t Training Loss 2.3721\t Accuracy 0.9107\n",
      "Epoch [6][20]\t Batch [300][550]\t Training Loss 2.3708\t Accuracy 0.9113\n",
      "Epoch [6][20]\t Batch [350][550]\t Training Loss 2.3742\t Accuracy 0.9108\n",
      "Epoch [6][20]\t Batch [400][550]\t Training Loss 2.3742\t Accuracy 0.9107\n",
      "Epoch [6][20]\t Batch [450][550]\t Training Loss 2.3742\t Accuracy 0.9106\n",
      "Epoch [6][20]\t Batch [500][550]\t Training Loss 2.3750\t Accuracy 0.9099\n",
      "\n",
      "Epoch [6]\t Average training loss 2.3705\t Average training accuracy 0.9101\n",
      "Epoch [6]\t Average validation loss 2.1572\t Average validation accuracy 0.9352\n",
      "\n",
      "Epoch [7][20]\t Batch [0][550]\t Training Loss 2.1500\t Accuracy 0.9500\n",
      "Epoch [7][20]\t Batch [50][550]\t Training Loss 2.2561\t Accuracy 0.9225\n",
      "Epoch [7][20]\t Batch [100][550]\t Training Loss 2.2777\t Accuracy 0.9176\n",
      "Epoch [7][20]\t Batch [150][550]\t Training Loss 2.3089\t Accuracy 0.9142\n",
      "Epoch [7][20]\t Batch [200][550]\t Training Loss 2.3027\t Accuracy 0.9156\n",
      "Epoch [7][20]\t Batch [250][550]\t Training Loss 2.2999\t Accuracy 0.9159\n",
      "Epoch [7][20]\t Batch [300][550]\t Training Loss 2.2995\t Accuracy 0.9161\n",
      "Epoch [7][20]\t Batch [350][550]\t Training Loss 2.3033\t Accuracy 0.9155\n",
      "Epoch [7][20]\t Batch [400][550]\t Training Loss 2.3043\t Accuracy 0.9154\n",
      "Epoch [7][20]\t Batch [450][550]\t Training Loss 2.3050\t Accuracy 0.9153\n",
      "Epoch [7][20]\t Batch [500][550]\t Training Loss 2.3069\t Accuracy 0.9145\n",
      "\n",
      "Epoch [7]\t Average training loss 2.3032\t Average training accuracy 0.9146\n",
      "Epoch [7]\t Average validation loss 2.0975\t Average validation accuracy 0.9378\n",
      "\n",
      "Epoch [8][20]\t Batch [0][550]\t Training Loss 2.0975\t Accuracy 0.9500\n",
      "Epoch [8][20]\t Batch [50][550]\t Training Loss 2.1979\t Accuracy 0.9255\n",
      "Epoch [8][20]\t Batch [100][550]\t Training Loss 2.2205\t Accuracy 0.9207\n",
      "Epoch [8][20]\t Batch [150][550]\t Training Loss 2.2519\t Accuracy 0.9175\n",
      "Epoch [8][20]\t Batch [200][550]\t Training Loss 2.2458\t Accuracy 0.9193\n",
      "Epoch [8][20]\t Batch [250][550]\t Training Loss 2.2433\t Accuracy 0.9198\n",
      "Epoch [8][20]\t Batch [300][550]\t Training Loss 2.2436\t Accuracy 0.9199\n",
      "Epoch [8][20]\t Batch [350][550]\t Training Loss 2.2476\t Accuracy 0.9195\n",
      "Epoch [8][20]\t Batch [400][550]\t Training Loss 2.2491\t Accuracy 0.9191\n",
      "Epoch [8][20]\t Batch [450][550]\t Training Loss 2.2502\t Accuracy 0.9190\n",
      "Epoch [8][20]\t Batch [500][550]\t Training Loss 2.2529\t Accuracy 0.9181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8]\t Average training loss 2.2496\t Average training accuracy 0.9181\n",
      "Epoch [8]\t Average validation loss 2.0489\t Average validation accuracy 0.9384\n",
      "\n",
      "Epoch [9][20]\t Batch [0][550]\t Training Loss 2.0557\t Accuracy 0.9500\n",
      "Epoch [9][20]\t Batch [50][550]\t Training Loss 2.1506\t Accuracy 0.9286\n",
      "Epoch [9][20]\t Batch [100][550]\t Training Loss 2.1739\t Accuracy 0.9230\n",
      "Epoch [9][20]\t Batch [150][550]\t Training Loss 2.2053\t Accuracy 0.9197\n",
      "Epoch [9][20]\t Batch [200][550]\t Training Loss 2.1991\t Accuracy 0.9214\n",
      "Epoch [9][20]\t Batch [250][550]\t Training Loss 2.1968\t Accuracy 0.9218\n",
      "Epoch [9][20]\t Batch [300][550]\t Training Loss 2.1976\t Accuracy 0.9221\n",
      "Epoch [9][20]\t Batch [350][550]\t Training Loss 2.2016\t Accuracy 0.9219\n",
      "Epoch [9][20]\t Batch [400][550]\t Training Loss 2.2036\t Accuracy 0.9215\n",
      "Epoch [9][20]\t Batch [450][550]\t Training Loss 2.2050\t Accuracy 0.9213\n",
      "Epoch [9][20]\t Batch [500][550]\t Training Loss 2.2082\t Accuracy 0.9206\n",
      "\n",
      "Epoch [9]\t Average training loss 2.2052\t Average training accuracy 0.9205\n",
      "Epoch [9]\t Average validation loss 2.0083\t Average validation accuracy 0.9408\n",
      "\n",
      "Epoch [10][20]\t Batch [0][550]\t Training Loss 2.0208\t Accuracy 0.9500\n",
      "Epoch [10][20]\t Batch [50][550]\t Training Loss 2.1107\t Accuracy 0.9322\n",
      "Epoch [10][20]\t Batch [100][550]\t Training Loss 2.1345\t Accuracy 0.9257\n",
      "Epoch [10][20]\t Batch [150][550]\t Training Loss 2.1658\t Accuracy 0.9223\n",
      "Epoch [10][20]\t Batch [200][550]\t Training Loss 2.1596\t Accuracy 0.9241\n",
      "Epoch [10][20]\t Batch [250][550]\t Training Loss 2.1573\t Accuracy 0.9243\n",
      "Epoch [10][20]\t Batch [300][550]\t Training Loss 2.1585\t Accuracy 0.9248\n",
      "Epoch [10][20]\t Batch [350][550]\t Training Loss 2.1625\t Accuracy 0.9244\n",
      "Epoch [10][20]\t Batch [400][550]\t Training Loss 2.1649\t Accuracy 0.9242\n",
      "Epoch [10][20]\t Batch [450][550]\t Training Loss 2.1664\t Accuracy 0.9241\n",
      "Epoch [10][20]\t Batch [500][550]\t Training Loss 2.1700\t Accuracy 0.9233\n",
      "\n",
      "Epoch [10]\t Average training loss 2.1673\t Average training accuracy 0.9233\n",
      "Epoch [10]\t Average validation loss 1.9737\t Average validation accuracy 0.9434\n",
      "\n",
      "Epoch [11][20]\t Batch [0][550]\t Training Loss 1.9905\t Accuracy 0.9500\n",
      "Epoch [11][20]\t Batch [50][550]\t Training Loss 2.0763\t Accuracy 0.9333\n",
      "Epoch [11][20]\t Batch [100][550]\t Training Loss 2.1005\t Accuracy 0.9283\n",
      "Epoch [11][20]\t Batch [150][550]\t Training Loss 2.1314\t Accuracy 0.9246\n",
      "Epoch [11][20]\t Batch [200][550]\t Training Loss 2.1253\t Accuracy 0.9263\n",
      "Epoch [11][20]\t Batch [250][550]\t Training Loss 2.1230\t Accuracy 0.9263\n",
      "Epoch [11][20]\t Batch [300][550]\t Training Loss 2.1245\t Accuracy 0.9268\n",
      "Epoch [11][20]\t Batch [350][550]\t Training Loss 2.1285\t Accuracy 0.9264\n",
      "Epoch [11][20]\t Batch [400][550]\t Training Loss 2.1311\t Accuracy 0.9261\n",
      "Epoch [11][20]\t Batch [450][550]\t Training Loss 2.1328\t Accuracy 0.9260\n",
      "Epoch [11][20]\t Batch [500][550]\t Training Loss 2.1368\t Accuracy 0.9252\n",
      "\n",
      "Epoch [11]\t Average training loss 2.1342\t Average training accuracy 0.9253\n",
      "Epoch [11]\t Average validation loss 1.9436\t Average validation accuracy 0.9460\n",
      "\n",
      "Epoch [12][20]\t Batch [0][550]\t Training Loss 1.9635\t Accuracy 0.9500\n",
      "Epoch [12][20]\t Batch [50][550]\t Training Loss 2.0460\t Accuracy 0.9343\n",
      "Epoch [12][20]\t Batch [100][550]\t Training Loss 2.0707\t Accuracy 0.9300\n",
      "Epoch [12][20]\t Batch [150][550]\t Training Loss 2.1011\t Accuracy 0.9267\n",
      "Epoch [12][20]\t Batch [200][550]\t Training Loss 2.0951\t Accuracy 0.9280\n",
      "Epoch [12][20]\t Batch [250][550]\t Training Loss 2.0927\t Accuracy 0.9280\n",
      "Epoch [12][20]\t Batch [300][550]\t Training Loss 2.0945\t Accuracy 0.9283\n",
      "Epoch [12][20]\t Batch [350][550]\t Training Loss 2.0985\t Accuracy 0.9280\n",
      "Epoch [12][20]\t Batch [400][550]\t Training Loss 2.1013\t Accuracy 0.9279\n",
      "Epoch [12][20]\t Batch [450][550]\t Training Loss 2.1031\t Accuracy 0.9277\n",
      "Epoch [12][20]\t Batch [500][550]\t Training Loss 2.1073\t Accuracy 0.9270\n",
      "\n",
      "Epoch [12]\t Average training loss 2.1049\t Average training accuracy 0.9270\n",
      "Epoch [12]\t Average validation loss 1.9172\t Average validation accuracy 0.9474\n",
      "\n",
      "Epoch [13][20]\t Batch [0][550]\t Training Loss 1.9390\t Accuracy 0.9500\n",
      "Epoch [13][20]\t Batch [50][550]\t Training Loss 2.0191\t Accuracy 0.9353\n",
      "Epoch [13][20]\t Batch [100][550]\t Training Loss 2.0440\t Accuracy 0.9312\n",
      "Epoch [13][20]\t Batch [150][550]\t Training Loss 2.0740\t Accuracy 0.9281\n",
      "Epoch [13][20]\t Batch [200][550]\t Training Loss 2.0680\t Accuracy 0.9292\n",
      "Epoch [13][20]\t Batch [250][550]\t Training Loss 2.0656\t Accuracy 0.9291\n",
      "Epoch [13][20]\t Batch [300][550]\t Training Loss 2.0677\t Accuracy 0.9296\n",
      "Epoch [13][20]\t Batch [350][550]\t Training Loss 2.0716\t Accuracy 0.9293\n",
      "Epoch [13][20]\t Batch [400][550]\t Training Loss 2.0747\t Accuracy 0.9293\n",
      "Epoch [13][20]\t Batch [450][550]\t Training Loss 2.0765\t Accuracy 0.9290\n",
      "Epoch [13][20]\t Batch [500][550]\t Training Loss 2.0810\t Accuracy 0.9283\n",
      "\n",
      "Epoch [13]\t Average training loss 2.0787\t Average training accuracy 0.9283\n",
      "Epoch [13]\t Average validation loss 1.8938\t Average validation accuracy 0.9496\n",
      "\n",
      "Epoch [14][20]\t Batch [0][550]\t Training Loss 1.9167\t Accuracy 0.9500\n",
      "Epoch [14][20]\t Batch [50][550]\t Training Loss 1.9950\t Accuracy 0.9375\n",
      "Epoch [14][20]\t Batch [100][550]\t Training Loss 2.0201\t Accuracy 0.9332\n",
      "Epoch [14][20]\t Batch [150][550]\t Training Loss 2.0496\t Accuracy 0.9303\n",
      "Epoch [14][20]\t Batch [200][550]\t Training Loss 2.0437\t Accuracy 0.9311\n",
      "Epoch [14][20]\t Batch [250][550]\t Training Loss 2.0411\t Accuracy 0.9309\n",
      "Epoch [14][20]\t Batch [300][550]\t Training Loss 2.0436\t Accuracy 0.9314\n",
      "Epoch [14][20]\t Batch [350][550]\t Training Loss 2.0475\t Accuracy 0.9310\n",
      "Epoch [14][20]\t Batch [400][550]\t Training Loss 2.0506\t Accuracy 0.9310\n",
      "Epoch [14][20]\t Batch [450][550]\t Training Loss 2.0525\t Accuracy 0.9306\n",
      "Epoch [14][20]\t Batch [500][550]\t Training Loss 2.0572\t Accuracy 0.9301\n",
      "\n",
      "Epoch [14]\t Average training loss 2.0550\t Average training accuracy 0.9301\n",
      "Epoch [14]\t Average validation loss 1.8728\t Average validation accuracy 0.9510\n",
      "\n",
      "Epoch [15][20]\t Batch [0][550]\t Training Loss 1.8963\t Accuracy 0.9500\n",
      "Epoch [15][20]\t Batch [50][550]\t Training Loss 1.9731\t Accuracy 0.9384\n",
      "Epoch [15][20]\t Batch [100][550]\t Training Loss 1.9984\t Accuracy 0.9345\n",
      "Epoch [15][20]\t Batch [150][550]\t Training Loss 2.0274\t Accuracy 0.9317\n",
      "Epoch [15][20]\t Batch [200][550]\t Training Loss 2.0215\t Accuracy 0.9325\n",
      "Epoch [15][20]\t Batch [250][550]\t Training Loss 2.0189\t Accuracy 0.9324\n",
      "Epoch [15][20]\t Batch [300][550]\t Training Loss 2.0217\t Accuracy 0.9328\n",
      "Epoch [15][20]\t Batch [350][550]\t Training Loss 2.0255\t Accuracy 0.9325\n",
      "Epoch [15][20]\t Batch [400][550]\t Training Loss 2.0289\t Accuracy 0.9324\n",
      "Epoch [15][20]\t Batch [450][550]\t Training Loss 2.0308\t Accuracy 0.9320\n",
      "Epoch [15][20]\t Batch [500][550]\t Training Loss 2.0357\t Accuracy 0.9316\n",
      "\n",
      "Epoch [15]\t Average training loss 2.0335\t Average training accuracy 0.9315\n",
      "Epoch [15]\t Average validation loss 1.8541\t Average validation accuracy 0.9512\n",
      "\n",
      "Epoch [16][20]\t Batch [0][550]\t Training Loss 1.8776\t Accuracy 0.9500\n",
      "Epoch [16][20]\t Batch [50][550]\t Training Loss 1.9531\t Accuracy 0.9400\n",
      "Epoch [16][20]\t Batch [100][550]\t Training Loss 1.9786\t Accuracy 0.9358\n",
      "Epoch [16][20]\t Batch [150][550]\t Training Loss 2.0072\t Accuracy 0.9330\n",
      "Epoch [16][20]\t Batch [200][550]\t Training Loss 2.0014\t Accuracy 0.9339\n",
      "Epoch [16][20]\t Batch [250][550]\t Training Loss 1.9987\t Accuracy 0.9337\n",
      "Epoch [16][20]\t Batch [300][550]\t Training Loss 2.0018\t Accuracy 0.9342\n",
      "Epoch [16][20]\t Batch [350][550]\t Training Loss 2.0056\t Accuracy 0.9338\n",
      "Epoch [16][20]\t Batch [400][550]\t Training Loss 2.0090\t Accuracy 0.9337\n",
      "Epoch [16][20]\t Batch [450][550]\t Training Loss 2.0110\t Accuracy 0.9334\n",
      "Epoch [16][20]\t Batch [500][550]\t Training Loss 2.0160\t Accuracy 0.9329\n",
      "\n",
      "Epoch [16]\t Average training loss 2.0139\t Average training accuracy 0.9329\n",
      "Epoch [16]\t Average validation loss 1.8372\t Average validation accuracy 0.9524\n",
      "\n",
      "Epoch [17][20]\t Batch [0][550]\t Training Loss 1.8605\t Accuracy 0.9500\n",
      "Epoch [17][20]\t Batch [50][550]\t Training Loss 1.9349\t Accuracy 0.9412\n",
      "Epoch [17][20]\t Batch [100][550]\t Training Loss 1.9606\t Accuracy 0.9368\n",
      "Epoch [17][20]\t Batch [150][550]\t Training Loss 1.9887\t Accuracy 0.9342\n",
      "Epoch [17][20]\t Batch [200][550]\t Training Loss 1.9829\t Accuracy 0.9350\n",
      "Epoch [17][20]\t Batch [250][550]\t Training Loss 1.9802\t Accuracy 0.9349\n",
      "Epoch [17][20]\t Batch [300][550]\t Training Loss 1.9835\t Accuracy 0.9352\n",
      "Epoch [17][20]\t Batch [350][550]\t Training Loss 1.9874\t Accuracy 0.9349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17][20]\t Batch [400][550]\t Training Loss 1.9909\t Accuracy 0.9347\n",
      "Epoch [17][20]\t Batch [450][550]\t Training Loss 1.9929\t Accuracy 0.9344\n",
      "Epoch [17][20]\t Batch [500][550]\t Training Loss 1.9980\t Accuracy 0.9340\n",
      "\n",
      "Epoch [17]\t Average training loss 1.9960\t Average training accuracy 0.9340\n",
      "Epoch [17]\t Average validation loss 1.8219\t Average validation accuracy 0.9528\n",
      "\n",
      "Epoch [18][20]\t Batch [0][550]\t Training Loss 1.8448\t Accuracy 0.9500\n",
      "Epoch [18][20]\t Batch [50][550]\t Training Loss 1.9181\t Accuracy 0.9429\n",
      "Epoch [18][20]\t Batch [100][550]\t Training Loss 1.9440\t Accuracy 0.9383\n",
      "Epoch [18][20]\t Batch [150][550]\t Training Loss 1.9716\t Accuracy 0.9359\n",
      "Epoch [18][20]\t Batch [200][550]\t Training Loss 1.9659\t Accuracy 0.9365\n",
      "Epoch [18][20]\t Batch [250][550]\t Training Loss 1.9632\t Accuracy 0.9363\n",
      "Epoch [18][20]\t Batch [300][550]\t Training Loss 1.9668\t Accuracy 0.9363\n",
      "Epoch [18][20]\t Batch [350][550]\t Training Loss 1.9706\t Accuracy 0.9358\n",
      "Epoch [18][20]\t Batch [400][550]\t Training Loss 1.9742\t Accuracy 0.9356\n",
      "Epoch [18][20]\t Batch [450][550]\t Training Loss 1.9762\t Accuracy 0.9354\n",
      "Epoch [18][20]\t Batch [500][550]\t Training Loss 1.9814\t Accuracy 0.9349\n",
      "\n",
      "Epoch [18]\t Average training loss 1.9794\t Average training accuracy 0.9349\n",
      "Epoch [18]\t Average validation loss 1.8081\t Average validation accuracy 0.9530\n",
      "\n",
      "Epoch [19][20]\t Batch [0][550]\t Training Loss 1.8303\t Accuracy 0.9500\n",
      "Epoch [19][20]\t Batch [50][550]\t Training Loss 1.9026\t Accuracy 0.9439\n",
      "Epoch [19][20]\t Batch [100][550]\t Training Loss 1.9287\t Accuracy 0.9394\n",
      "Epoch [19][20]\t Batch [150][550]\t Training Loss 1.9558\t Accuracy 0.9370\n",
      "Epoch [19][20]\t Batch [200][550]\t Training Loss 1.9502\t Accuracy 0.9376\n",
      "Epoch [19][20]\t Batch [250][550]\t Training Loss 1.9474\t Accuracy 0.9376\n",
      "Epoch [19][20]\t Batch [300][550]\t Training Loss 1.9513\t Accuracy 0.9376\n",
      "Epoch [19][20]\t Batch [350][550]\t Training Loss 1.9551\t Accuracy 0.9371\n",
      "Epoch [19][20]\t Batch [400][550]\t Training Loss 1.9587\t Accuracy 0.9369\n",
      "Epoch [19][20]\t Batch [450][550]\t Training Loss 1.9608\t Accuracy 0.9366\n",
      "Epoch [19][20]\t Batch [500][550]\t Training Loss 1.9661\t Accuracy 0.9362\n",
      "\n",
      "Epoch [19]\t Average training loss 1.9641\t Average training accuracy 0.9363\n",
      "Epoch [19]\t Average validation loss 1.7954\t Average validation accuracy 0.9538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sigmoidMLP, sigmoid_loss, sigmoid_acc = train(sigmoidMLP, criterion, sgd, data_train, max_epoch, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "The test accuracy is 0.9388.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(sigmoidMLP, criterion, data_test, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.2 使用欧式距离损失和ReLU激活函数训练多层感知机\n",
    "训练带有一个隐含层且神经元个数为128的多层感知机，使用欧式距离损失和ReLU激活函数.\n",
    "\n",
    "### TODO\n",
    "执行以下代码之前，请完成 **layers/relu_layer.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from layers import ReLULayer\n",
    "\n",
    "reluMLP = Network()\n",
    "# 使用FCLayer和ReLULayer构建多层感知机\n",
    "reluMLP.add(FCLayer(784, 128))\n",
    "reluMLP.add(ReLULayer())\n",
    "reluMLP.add(FCLayer(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][20]\t Batch [0][550]\t Training Loss 12.5907\t Accuracy 0.1600\n",
      "Epoch [0][20]\t Batch [50][550]\t Training Loss 5.0506\t Accuracy 0.5016\n",
      "Epoch [0][20]\t Batch [100][550]\t Training Loss 4.3306\t Accuracy 0.6279\n",
      "Epoch [0][20]\t Batch [150][550]\t Training Loss 4.0040\t Accuracy 0.6843\n",
      "Epoch [0][20]\t Batch [200][550]\t Training Loss 3.7769\t Accuracy 0.7230\n",
      "Epoch [0][20]\t Batch [250][550]\t Training Loss 3.6080\t Accuracy 0.7495\n",
      "Epoch [0][20]\t Batch [300][550]\t Training Loss 3.4852\t Accuracy 0.7679\n",
      "Epoch [0][20]\t Batch [350][550]\t Training Loss 3.3850\t Accuracy 0.7821\n",
      "Epoch [0][20]\t Batch [400][550]\t Training Loss 3.2994\t Accuracy 0.7940\n",
      "Epoch [0][20]\t Batch [450][550]\t Training Loss 3.2272\t Accuracy 0.8040\n",
      "Epoch [0][20]\t Batch [500][550]\t Training Loss 3.1669\t Accuracy 0.8115\n",
      "\n",
      "Epoch [0]\t Average training loss 3.1076\t Average training accuracy 0.8188\n",
      "Epoch [0]\t Average validation loss 2.3403\t Average validation accuracy 0.9220\n",
      "\n",
      "Epoch [1][20]\t Batch [0][550]\t Training Loss 2.2797\t Accuracy 0.9300\n",
      "Epoch [1][20]\t Batch [50][550]\t Training Loss 2.4119\t Accuracy 0.9059\n",
      "Epoch [1][20]\t Batch [100][550]\t Training Loss 2.4118\t Accuracy 0.9042\n",
      "Epoch [1][20]\t Batch [150][550]\t Training Loss 2.4321\t Accuracy 0.9010\n",
      "Epoch [1][20]\t Batch [200][550]\t Training Loss 2.4179\t Accuracy 0.9031\n",
      "Epoch [1][20]\t Batch [250][550]\t Training Loss 2.4046\t Accuracy 0.9052\n",
      "Epoch [1][20]\t Batch [300][550]\t Training Loss 2.4005\t Accuracy 0.9055\n",
      "Epoch [1][20]\t Batch [350][550]\t Training Loss 2.3940\t Accuracy 0.9058\n",
      "Epoch [1][20]\t Batch [400][550]\t Training Loss 2.3877\t Accuracy 0.9067\n",
      "Epoch [1][20]\t Batch [450][550]\t Training Loss 2.3798\t Accuracy 0.9078\n",
      "Epoch [1][20]\t Batch [500][550]\t Training Loss 2.3758\t Accuracy 0.9079\n",
      "\n",
      "Epoch [1]\t Average training loss 2.3643\t Average training accuracy 0.9085\n",
      "Epoch [1]\t Average validation loss 2.1108\t Average validation accuracy 0.9380\n",
      "\n",
      "Epoch [2][20]\t Batch [0][550]\t Training Loss 2.0907\t Accuracy 0.9500\n",
      "Epoch [2][20]\t Batch [50][550]\t Training Loss 2.1791\t Accuracy 0.9269\n",
      "Epoch [2][20]\t Batch [100][550]\t Training Loss 2.1973\t Accuracy 0.9228\n",
      "Epoch [2][20]\t Batch [150][550]\t Training Loss 2.2232\t Accuracy 0.9207\n",
      "Epoch [2][20]\t Batch [200][550]\t Training Loss 2.2144\t Accuracy 0.9220\n",
      "Epoch [2][20]\t Batch [250][550]\t Training Loss 2.2086\t Accuracy 0.9235\n",
      "Epoch [2][20]\t Batch [300][550]\t Training Loss 2.2112\t Accuracy 0.9230\n",
      "Epoch [2][20]\t Batch [350][550]\t Training Loss 2.2106\t Accuracy 0.9226\n",
      "Epoch [2][20]\t Batch [400][550]\t Training Loss 2.2103\t Accuracy 0.9230\n",
      "Epoch [2][20]\t Batch [450][550]\t Training Loss 2.2068\t Accuracy 0.9237\n",
      "Epoch [2][20]\t Batch [500][550]\t Training Loss 2.2080\t Accuracy 0.9229\n",
      "\n",
      "Epoch [2]\t Average training loss 2.2011\t Average training accuracy 0.9231\n",
      "Epoch [2]\t Average validation loss 2.0116\t Average validation accuracy 0.9446\n",
      "\n",
      "Epoch [3][20]\t Batch [0][550]\t Training Loss 2.0102\t Accuracy 0.9600\n",
      "Epoch [3][20]\t Batch [50][550]\t Training Loss 2.0727\t Accuracy 0.9367\n",
      "Epoch [3][20]\t Batch [100][550]\t Training Loss 2.0971\t Accuracy 0.9325\n",
      "Epoch [3][20]\t Batch [150][550]\t Training Loss 2.1232\t Accuracy 0.9293\n",
      "Epoch [3][20]\t Batch [200][550]\t Training Loss 2.1147\t Accuracy 0.9302\n",
      "Epoch [3][20]\t Batch [250][550]\t Training Loss 2.1103\t Accuracy 0.9314\n",
      "Epoch [3][20]\t Batch [300][550]\t Training Loss 2.1147\t Accuracy 0.9310\n",
      "Epoch [3][20]\t Batch [350][550]\t Training Loss 2.1155\t Accuracy 0.9306\n",
      "Epoch [3][20]\t Batch [400][550]\t Training Loss 2.1164\t Accuracy 0.9309\n",
      "Epoch [3][20]\t Batch [450][550]\t Training Loss 2.1137\t Accuracy 0.9315\n",
      "Epoch [3][20]\t Batch [500][550]\t Training Loss 2.1165\t Accuracy 0.9308\n",
      "\n",
      "Epoch [3]\t Average training loss 2.1106\t Average training accuracy 0.9310\n",
      "Epoch [3]\t Average validation loss 1.9490\t Average validation accuracy 0.9506\n",
      "\n",
      "Epoch [4][20]\t Batch [0][550]\t Training Loss 1.9493\t Accuracy 0.9600\n",
      "Epoch [4][20]\t Batch [50][550]\t Training Loss 1.9993\t Accuracy 0.9408\n",
      "Epoch [4][20]\t Batch [100][550]\t Training Loss 2.0278\t Accuracy 0.9373\n",
      "Epoch [4][20]\t Batch [150][550]\t Training Loss 2.0529\t Accuracy 0.9353\n",
      "Epoch [4][20]\t Batch [200][550]\t Training Loss 2.0449\t Accuracy 0.9367\n",
      "Epoch [4][20]\t Batch [250][550]\t Training Loss 2.0410\t Accuracy 0.9377\n",
      "Epoch [4][20]\t Batch [300][550]\t Training Loss 2.0464\t Accuracy 0.9371\n",
      "Epoch [4][20]\t Batch [350][550]\t Training Loss 2.0477\t Accuracy 0.9365\n",
      "Epoch [4][20]\t Batch [400][550]\t Training Loss 2.0491\t Accuracy 0.9368\n",
      "Epoch [4][20]\t Batch [450][550]\t Training Loss 2.0467\t Accuracy 0.9374\n",
      "Epoch [4][20]\t Batch [500][550]\t Training Loss 2.0503\t Accuracy 0.9368\n",
      "\n",
      "Epoch [4]\t Average training loss 2.0447\t Average training accuracy 0.9370\n",
      "Epoch [4]\t Average validation loss 1.9021\t Average validation accuracy 0.9540\n",
      "\n",
      "Epoch [5][20]\t Batch [0][550]\t Training Loss 1.9003\t Accuracy 0.9700\n",
      "Epoch [5][20]\t Batch [50][550]\t Training Loss 1.9436\t Accuracy 0.9445\n",
      "Epoch [5][20]\t Batch [100][550]\t Training Loss 1.9736\t Accuracy 0.9411\n",
      "Epoch [5][20]\t Batch [150][550]\t Training Loss 1.9979\t Accuracy 0.9396\n",
      "Epoch [5][20]\t Batch [200][550]\t Training Loss 1.9905\t Accuracy 0.9412\n",
      "Epoch [5][20]\t Batch [250][550]\t Training Loss 1.9866\t Accuracy 0.9422\n",
      "Epoch [5][20]\t Batch [300][550]\t Training Loss 1.9928\t Accuracy 0.9414\n",
      "Epoch [5][20]\t Batch [350][550]\t Training Loss 1.9943\t Accuracy 0.9410\n",
      "Epoch [5][20]\t Batch [400][550]\t Training Loss 1.9960\t Accuracy 0.9410\n",
      "Epoch [5][20]\t Batch [450][550]\t Training Loss 1.9939\t Accuracy 0.9418\n",
      "Epoch [5][20]\t Batch [500][550]\t Training Loss 1.9981\t Accuracy 0.9411\n",
      "\n",
      "Epoch [5]\t Average training loss 1.9927\t Average training accuracy 0.9413\n",
      "Epoch [5]\t Average validation loss 1.8646\t Average validation accuracy 0.9570\n",
      "\n",
      "Epoch [6][20]\t Batch [0][550]\t Training Loss 1.8603\t Accuracy 0.9700\n",
      "Epoch [6][20]\t Batch [50][550]\t Training Loss 1.8984\t Accuracy 0.9494\n",
      "Epoch [6][20]\t Batch [100][550]\t Training Loss 1.9299\t Accuracy 0.9451\n",
      "Epoch [6][20]\t Batch [150][550]\t Training Loss 1.9527\t Accuracy 0.9444\n",
      "Epoch [6][20]\t Batch [200][550]\t Training Loss 1.9458\t Accuracy 0.9456\n",
      "Epoch [6][20]\t Batch [250][550]\t Training Loss 1.9421\t Accuracy 0.9461\n",
      "Epoch [6][20]\t Batch [300][550]\t Training Loss 1.9490\t Accuracy 0.9451\n",
      "Epoch [6][20]\t Batch [350][550]\t Training Loss 1.9506\t Accuracy 0.9446\n",
      "Epoch [6][20]\t Batch [400][550]\t Training Loss 1.9524\t Accuracy 0.9446\n",
      "Epoch [6][20]\t Batch [450][550]\t Training Loss 1.9506\t Accuracy 0.9451\n",
      "Epoch [6][20]\t Batch [500][550]\t Training Loss 1.9551\t Accuracy 0.9444\n",
      "\n",
      "Epoch [6]\t Average training loss 1.9500\t Average training accuracy 0.9446\n",
      "Epoch [6]\t Average validation loss 1.8355\t Average validation accuracy 0.9588\n",
      "\n",
      "Epoch [7][20]\t Batch [0][550]\t Training Loss 1.8315\t Accuracy 0.9700\n",
      "Epoch [7][20]\t Batch [50][550]\t Training Loss 1.8620\t Accuracy 0.9524\n",
      "Epoch [7][20]\t Batch [100][550]\t Training Loss 1.8938\t Accuracy 0.9481\n",
      "Epoch [7][20]\t Batch [150][550]\t Training Loss 1.9152\t Accuracy 0.9471\n",
      "Epoch [7][20]\t Batch [200][550]\t Training Loss 1.9085\t Accuracy 0.9479\n",
      "Epoch [7][20]\t Batch [250][550]\t Training Loss 1.9049\t Accuracy 0.9482\n",
      "Epoch [7][20]\t Batch [300][550]\t Training Loss 1.9126\t Accuracy 0.9472\n",
      "Epoch [7][20]\t Batch [350][550]\t Training Loss 1.9141\t Accuracy 0.9472\n",
      "Epoch [7][20]\t Batch [400][550]\t Training Loss 1.9159\t Accuracy 0.9472\n",
      "Epoch [7][20]\t Batch [450][550]\t Training Loss 1.9144\t Accuracy 0.9476\n",
      "Epoch [7][20]\t Batch [500][550]\t Training Loss 1.9192\t Accuracy 0.9468\n",
      "\n",
      "Epoch [7]\t Average training loss 1.9142\t Average training accuracy 0.9471\n",
      "Epoch [7]\t Average validation loss 1.8109\t Average validation accuracy 0.9590\n",
      "\n",
      "Epoch [8][20]\t Batch [0][550]\t Training Loss 1.8076\t Accuracy 0.9700\n",
      "Epoch [8][20]\t Batch [50][550]\t Training Loss 1.8309\t Accuracy 0.9543\n",
      "Epoch [8][20]\t Batch [100][550]\t Training Loss 1.8627\t Accuracy 0.9499\n",
      "Epoch [8][20]\t Batch [150][550]\t Training Loss 1.8828\t Accuracy 0.9494\n",
      "Epoch [8][20]\t Batch [200][550]\t Training Loss 1.8763\t Accuracy 0.9502\n",
      "Epoch [8][20]\t Batch [250][550]\t Training Loss 1.8728\t Accuracy 0.9506\n",
      "Epoch [8][20]\t Batch [300][550]\t Training Loss 1.8809\t Accuracy 0.9497\n",
      "Epoch [8][20]\t Batch [350][550]\t Training Loss 1.8823\t Accuracy 0.9496\n",
      "Epoch [8][20]\t Batch [400][550]\t Training Loss 1.8842\t Accuracy 0.9494\n",
      "Epoch [8][20]\t Batch [450][550]\t Training Loss 1.8829\t Accuracy 0.9498\n",
      "Epoch [8][20]\t Batch [500][550]\t Training Loss 1.8880\t Accuracy 0.9490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8]\t Average training loss 1.8831\t Average training accuracy 0.9494\n",
      "Epoch [8]\t Average validation loss 1.7909\t Average validation accuracy 0.9606\n",
      "\n",
      "Epoch [9][20]\t Batch [0][550]\t Training Loss 1.7884\t Accuracy 0.9700\n",
      "Epoch [9][20]\t Batch [50][550]\t Training Loss 1.8041\t Accuracy 0.9553\n",
      "Epoch [9][20]\t Batch [100][550]\t Training Loss 1.8358\t Accuracy 0.9511\n",
      "Epoch [9][20]\t Batch [150][550]\t Training Loss 1.8551\t Accuracy 0.9509\n",
      "Epoch [9][20]\t Batch [200][550]\t Training Loss 1.8485\t Accuracy 0.9519\n",
      "Epoch [9][20]\t Batch [250][550]\t Training Loss 1.8450\t Accuracy 0.9522\n",
      "Epoch [9][20]\t Batch [300][550]\t Training Loss 1.8534\t Accuracy 0.9513\n",
      "Epoch [9][20]\t Batch [350][550]\t Training Loss 1.8547\t Accuracy 0.9512\n",
      "Epoch [9][20]\t Batch [400][550]\t Training Loss 1.8567\t Accuracy 0.9511\n",
      "Epoch [9][20]\t Batch [450][550]\t Training Loss 1.8556\t Accuracy 0.9514\n",
      "Epoch [9][20]\t Batch [500][550]\t Training Loss 1.8608\t Accuracy 0.9507\n",
      "\n",
      "Epoch [9]\t Average training loss 1.8561\t Average training accuracy 0.9509\n",
      "Epoch [9]\t Average validation loss 1.7723\t Average validation accuracy 0.9624\n",
      "\n",
      "Epoch [10][20]\t Batch [0][550]\t Training Loss 1.7716\t Accuracy 0.9700\n",
      "Epoch [10][20]\t Batch [50][550]\t Training Loss 1.7806\t Accuracy 0.9569\n",
      "Epoch [10][20]\t Batch [100][550]\t Training Loss 1.8122\t Accuracy 0.9528\n",
      "Epoch [10][20]\t Batch [150][550]\t Training Loss 1.8308\t Accuracy 0.9527\n",
      "Epoch [10][20]\t Batch [200][550]\t Training Loss 1.8242\t Accuracy 0.9538\n",
      "Epoch [10][20]\t Batch [250][550]\t Training Loss 1.8205\t Accuracy 0.9543\n",
      "Epoch [10][20]\t Batch [300][550]\t Training Loss 1.8293\t Accuracy 0.9533\n",
      "Epoch [10][20]\t Batch [350][550]\t Training Loss 1.8303\t Accuracy 0.9532\n",
      "Epoch [10][20]\t Batch [400][550]\t Training Loss 1.8323\t Accuracy 0.9530\n",
      "Epoch [10][20]\t Batch [450][550]\t Training Loss 1.8315\t Accuracy 0.9531\n",
      "Epoch [10][20]\t Batch [500][550]\t Training Loss 1.8368\t Accuracy 0.9523\n",
      "\n",
      "Epoch [10]\t Average training loss 1.8322\t Average training accuracy 0.9526\n",
      "Epoch [10]\t Average validation loss 1.7559\t Average validation accuracy 0.9636\n",
      "\n",
      "Epoch [11][20]\t Batch [0][550]\t Training Loss 1.7572\t Accuracy 0.9700\n",
      "Epoch [11][20]\t Batch [50][550]\t Training Loss 1.7594\t Accuracy 0.9584\n",
      "Epoch [11][20]\t Batch [100][550]\t Training Loss 1.7907\t Accuracy 0.9547\n",
      "Epoch [11][20]\t Batch [150][550]\t Training Loss 1.8088\t Accuracy 0.9545\n",
      "Epoch [11][20]\t Batch [200][550]\t Training Loss 1.8023\t Accuracy 0.9559\n",
      "Epoch [11][20]\t Batch [250][550]\t Training Loss 1.7983\t Accuracy 0.9562\n",
      "Epoch [11][20]\t Batch [300][550]\t Training Loss 1.8074\t Accuracy 0.9551\n",
      "Epoch [11][20]\t Batch [350][550]\t Training Loss 1.8084\t Accuracy 0.9548\n",
      "Epoch [11][20]\t Batch [400][550]\t Training Loss 1.8105\t Accuracy 0.9546\n",
      "Epoch [11][20]\t Batch [450][550]\t Training Loss 1.8099\t Accuracy 0.9547\n",
      "Epoch [11][20]\t Batch [500][550]\t Training Loss 1.8152\t Accuracy 0.9541\n",
      "\n",
      "Epoch [11]\t Average training loss 1.8108\t Average training accuracy 0.9542\n",
      "Epoch [11]\t Average validation loss 1.7422\t Average validation accuracy 0.9644\n",
      "\n",
      "Epoch [12][20]\t Batch [0][550]\t Training Loss 1.7415\t Accuracy 0.9700\n",
      "Epoch [12][20]\t Batch [50][550]\t Training Loss 1.7396\t Accuracy 0.9608\n",
      "Epoch [12][20]\t Batch [100][550]\t Training Loss 1.7709\t Accuracy 0.9565\n",
      "Epoch [12][20]\t Batch [150][550]\t Training Loss 1.7886\t Accuracy 0.9566\n",
      "Epoch [12][20]\t Batch [200][550]\t Training Loss 1.7822\t Accuracy 0.9578\n",
      "Epoch [12][20]\t Batch [250][550]\t Training Loss 1.7781\t Accuracy 0.9580\n",
      "Epoch [12][20]\t Batch [300][550]\t Training Loss 1.7875\t Accuracy 0.9568\n",
      "Epoch [12][20]\t Batch [350][550]\t Training Loss 1.7884\t Accuracy 0.9566\n",
      "Epoch [12][20]\t Batch [400][550]\t Training Loss 1.7906\t Accuracy 0.9562\n",
      "Epoch [12][20]\t Batch [450][550]\t Training Loss 1.7902\t Accuracy 0.9563\n",
      "Epoch [12][20]\t Batch [500][550]\t Training Loss 1.7955\t Accuracy 0.9557\n",
      "\n",
      "Epoch [12]\t Average training loss 1.7913\t Average training accuracy 0.9558\n",
      "Epoch [12]\t Average validation loss 1.7289\t Average validation accuracy 0.9654\n",
      "\n",
      "Epoch [13][20]\t Batch [0][550]\t Training Loss 1.7235\t Accuracy 0.9700\n",
      "Epoch [13][20]\t Batch [50][550]\t Training Loss 1.7210\t Accuracy 0.9631\n",
      "Epoch [13][20]\t Batch [100][550]\t Training Loss 1.7523\t Accuracy 0.9586\n",
      "Epoch [13][20]\t Batch [150][550]\t Training Loss 1.7698\t Accuracy 0.9583\n",
      "Epoch [13][20]\t Batch [200][550]\t Training Loss 1.7635\t Accuracy 0.9593\n",
      "Epoch [13][20]\t Batch [250][550]\t Training Loss 1.7593\t Accuracy 0.9594\n",
      "Epoch [13][20]\t Batch [300][550]\t Training Loss 1.7691\t Accuracy 0.9582\n",
      "Epoch [13][20]\t Batch [350][550]\t Training Loss 1.7699\t Accuracy 0.9580\n",
      "Epoch [13][20]\t Batch [400][550]\t Training Loss 1.7721\t Accuracy 0.9576\n",
      "Epoch [13][20]\t Batch [450][550]\t Training Loss 1.7719\t Accuracy 0.9577\n",
      "Epoch [13][20]\t Batch [500][550]\t Training Loss 1.7773\t Accuracy 0.9571\n",
      "\n",
      "Epoch [13]\t Average training loss 1.7732\t Average training accuracy 0.9572\n",
      "Epoch [13]\t Average validation loss 1.7170\t Average validation accuracy 0.9660\n",
      "\n",
      "Epoch [14][20]\t Batch [0][550]\t Training Loss 1.7076\t Accuracy 0.9700\n",
      "Epoch [14][20]\t Batch [50][550]\t Training Loss 1.7037\t Accuracy 0.9643\n",
      "Epoch [14][20]\t Batch [100][550]\t Training Loss 1.7353\t Accuracy 0.9591\n",
      "Epoch [14][20]\t Batch [150][550]\t Training Loss 1.7524\t Accuracy 0.9590\n",
      "Epoch [14][20]\t Batch [200][550]\t Training Loss 1.7464\t Accuracy 0.9601\n",
      "Epoch [14][20]\t Batch [250][550]\t Training Loss 1.7421\t Accuracy 0.9603\n",
      "Epoch [14][20]\t Batch [300][550]\t Training Loss 1.7521\t Accuracy 0.9593\n",
      "Epoch [14][20]\t Batch [350][550]\t Training Loss 1.7529\t Accuracy 0.9591\n",
      "Epoch [14][20]\t Batch [400][550]\t Training Loss 1.7553\t Accuracy 0.9588\n",
      "Epoch [14][20]\t Batch [450][550]\t Training Loss 1.7551\t Accuracy 0.9589\n",
      "Epoch [14][20]\t Batch [500][550]\t Training Loss 1.7605\t Accuracy 0.9582\n",
      "\n",
      "Epoch [14]\t Average training loss 1.7566\t Average training accuracy 0.9583\n",
      "Epoch [14]\t Average validation loss 1.7052\t Average validation accuracy 0.9658\n",
      "\n",
      "Epoch [15][20]\t Batch [0][550]\t Training Loss 1.6923\t Accuracy 0.9700\n",
      "Epoch [15][20]\t Batch [50][550]\t Training Loss 1.6881\t Accuracy 0.9651\n",
      "Epoch [15][20]\t Batch [100][550]\t Training Loss 1.7198\t Accuracy 0.9600\n",
      "Epoch [15][20]\t Batch [150][550]\t Training Loss 1.7366\t Accuracy 0.9599\n",
      "Epoch [15][20]\t Batch [200][550]\t Training Loss 1.7307\t Accuracy 0.9610\n",
      "Epoch [15][20]\t Batch [250][550]\t Training Loss 1.7264\t Accuracy 0.9613\n",
      "Epoch [15][20]\t Batch [300][550]\t Training Loss 1.7366\t Accuracy 0.9601\n",
      "Epoch [15][20]\t Batch [350][550]\t Training Loss 1.7375\t Accuracy 0.9601\n",
      "Epoch [15][20]\t Batch [400][550]\t Training Loss 1.7399\t Accuracy 0.9599\n",
      "Epoch [15][20]\t Batch [450][550]\t Training Loss 1.7398\t Accuracy 0.9600\n",
      "Epoch [15][20]\t Batch [500][550]\t Training Loss 1.7453\t Accuracy 0.9593\n",
      "\n",
      "Epoch [15]\t Average training loss 1.7415\t Average training accuracy 0.9594\n",
      "Epoch [15]\t Average validation loss 1.6945\t Average validation accuracy 0.9664\n",
      "\n",
      "Epoch [16][20]\t Batch [0][550]\t Training Loss 1.6752\t Accuracy 0.9700\n",
      "Epoch [16][20]\t Batch [50][550]\t Training Loss 1.6738\t Accuracy 0.9665\n",
      "Epoch [16][20]\t Batch [100][550]\t Training Loss 1.7052\t Accuracy 0.9617\n",
      "Epoch [16][20]\t Batch [150][550]\t Training Loss 1.7217\t Accuracy 0.9613\n",
      "Epoch [16][20]\t Batch [200][550]\t Training Loss 1.7160\t Accuracy 0.9624\n",
      "Epoch [16][20]\t Batch [250][550]\t Training Loss 1.7117\t Accuracy 0.9625\n",
      "Epoch [16][20]\t Batch [300][550]\t Training Loss 1.7221\t Accuracy 0.9613\n",
      "Epoch [16][20]\t Batch [350][550]\t Training Loss 1.7230\t Accuracy 0.9612\n",
      "Epoch [16][20]\t Batch [400][550]\t Training Loss 1.7255\t Accuracy 0.9610\n",
      "Epoch [16][20]\t Batch [450][550]\t Training Loss 1.7254\t Accuracy 0.9610\n",
      "Epoch [16][20]\t Batch [500][550]\t Training Loss 1.7310\t Accuracy 0.9603\n",
      "\n",
      "Epoch [16]\t Average training loss 1.7273\t Average training accuracy 0.9605\n",
      "Epoch [16]\t Average validation loss 1.6850\t Average validation accuracy 0.9670\n",
      "\n",
      "Epoch [17][20]\t Batch [0][550]\t Training Loss 1.6599\t Accuracy 0.9700\n",
      "Epoch [17][20]\t Batch [50][550]\t Training Loss 1.6602\t Accuracy 0.9675\n",
      "Epoch [17][20]\t Batch [100][550]\t Training Loss 1.6914\t Accuracy 0.9632\n",
      "Epoch [17][20]\t Batch [150][550]\t Training Loss 1.7078\t Accuracy 0.9625\n",
      "Epoch [17][20]\t Batch [200][550]\t Training Loss 1.7024\t Accuracy 0.9634\n",
      "Epoch [17][20]\t Batch [250][550]\t Training Loss 1.6981\t Accuracy 0.9636\n",
      "Epoch [17][20]\t Batch [300][550]\t Training Loss 1.7086\t Accuracy 0.9625\n",
      "Epoch [17][20]\t Batch [350][550]\t Training Loss 1.7095\t Accuracy 0.9623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17][20]\t Batch [400][550]\t Training Loss 1.7121\t Accuracy 0.9622\n",
      "Epoch [17][20]\t Batch [450][550]\t Training Loss 1.7120\t Accuracy 0.9621\n",
      "Epoch [17][20]\t Batch [500][550]\t Training Loss 1.7176\t Accuracy 0.9613\n",
      "\n",
      "Epoch [17]\t Average training loss 1.7141\t Average training accuracy 0.9615\n",
      "Epoch [17]\t Average validation loss 1.6762\t Average validation accuracy 0.9670\n",
      "\n",
      "Epoch [18][20]\t Batch [0][550]\t Training Loss 1.6460\t Accuracy 0.9700\n",
      "Epoch [18][20]\t Batch [50][550]\t Training Loss 1.6480\t Accuracy 0.9678\n",
      "Epoch [18][20]\t Batch [100][550]\t Training Loss 1.6785\t Accuracy 0.9639\n",
      "Epoch [18][20]\t Batch [150][550]\t Training Loss 1.6947\t Accuracy 0.9630\n",
      "Epoch [18][20]\t Batch [200][550]\t Training Loss 1.6896\t Accuracy 0.9638\n",
      "Epoch [18][20]\t Batch [250][550]\t Training Loss 1.6852\t Accuracy 0.9642\n",
      "Epoch [18][20]\t Batch [300][550]\t Training Loss 1.6959\t Accuracy 0.9631\n",
      "Epoch [18][20]\t Batch [350][550]\t Training Loss 1.6970\t Accuracy 0.9629\n",
      "Epoch [18][20]\t Batch [400][550]\t Training Loss 1.6995\t Accuracy 0.9628\n",
      "Epoch [18][20]\t Batch [450][550]\t Training Loss 1.6995\t Accuracy 0.9627\n",
      "Epoch [18][20]\t Batch [500][550]\t Training Loss 1.7051\t Accuracy 0.9619\n",
      "\n",
      "Epoch [18]\t Average training loss 1.7017\t Average training accuracy 0.9621\n",
      "Epoch [18]\t Average validation loss 1.6684\t Average validation accuracy 0.9674\n",
      "\n",
      "Epoch [19][20]\t Batch [0][550]\t Training Loss 1.6339\t Accuracy 0.9800\n",
      "Epoch [19][20]\t Batch [50][550]\t Training Loss 1.6365\t Accuracy 0.9680\n",
      "Epoch [19][20]\t Batch [100][550]\t Training Loss 1.6666\t Accuracy 0.9645\n",
      "Epoch [19][20]\t Batch [150][550]\t Training Loss 1.6826\t Accuracy 0.9636\n",
      "Epoch [19][20]\t Batch [200][550]\t Training Loss 1.6778\t Accuracy 0.9646\n",
      "Epoch [19][20]\t Batch [250][550]\t Training Loss 1.6734\t Accuracy 0.9649\n",
      "Epoch [19][20]\t Batch [300][550]\t Training Loss 1.6843\t Accuracy 0.9638\n",
      "Epoch [19][20]\t Batch [350][550]\t Training Loss 1.6854\t Accuracy 0.9636\n",
      "Epoch [19][20]\t Batch [400][550]\t Training Loss 1.6879\t Accuracy 0.9635\n",
      "Epoch [19][20]\t Batch [450][550]\t Training Loss 1.6879\t Accuracy 0.9635\n",
      "Epoch [19][20]\t Batch [500][550]\t Training Loss 1.6935\t Accuracy 0.9627\n",
      "\n",
      "Epoch [19]\t Average training loss 1.6903\t Average training accuracy 0.9629\n",
      "Epoch [19]\t Average validation loss 1.6607\t Average validation accuracy 0.9678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reluMLP, relu_loss, relu_acc = train(reluMLP, criterion, sgd, data_train, max_epoch, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "The test accuracy is 0.9590.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(reluMLP, criterion, data_test, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 绘制曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_and_acc({'Sigmoid': [sigmoid_loss, sigmoid_acc],\n",
    "                   'relu': [relu_loss, relu_acc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. 使用Softmax交叉熵损失训练多层感知机(MLP with Softmax Cross-Entropy Loss)\n",
    "第二部分将使用Softmax交叉熵损失训练多层感知机. \n",
    "分别使用**Sigmoid**激活函数和**ReLU**激活函数.\n",
    "\n",
    "### TODO\n",
    "执行以下代码之前，请完成 **criterion/softmax_cross_entropy_loss.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from criterion import SoftmaxCrossEntropyLossLayer\n",
    "\n",
    "criterion = SoftmaxCrossEntropyLossLayer()\n",
    "\n",
    "sgd = SGD(learning_rate_SGD, weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.1 使用Softmax交叉熵损失和Sigmoid激活函数训练多层感知机\n",
    "训练带有一个隐含层且神经元个数为128的多层感知机，使用Softmax交叉熵损失和Sigmoid激活函数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sigmoidMLP = Network()\n",
    "# 使用FCLayer和SigmoidLayer构建多层感知机\n",
    "# 128为隐含层的神经元数目\n",
    "sigmoidMLP.add(FCLayer(784, 128))\n",
    "sigmoidMLP.add(SigmoidLayer())\n",
    "sigmoidMLP.add(FCLayer(128, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][20]\t Batch [0][550]\t Training Loss 2.8934\t Accuracy 0.1400\n",
      "Epoch [0][20]\t Batch [50][550]\t Training Loss 1.8810\t Accuracy 0.5108\n",
      "Epoch [0][20]\t Batch [100][550]\t Training Loss 1.5511\t Accuracy 0.6375\n",
      "Epoch [0][20]\t Batch [150][550]\t Training Loss 1.3478\t Accuracy 0.6901\n",
      "Epoch [0][20]\t Batch [200][550]\t Training Loss 1.2056\t Accuracy 0.7251\n",
      "Epoch [0][20]\t Batch [250][550]\t Training Loss 1.0961\t Accuracy 0.7507\n",
      "Epoch [0][20]\t Batch [300][550]\t Training Loss 1.0136\t Accuracy 0.7690\n",
      "Epoch [0][20]\t Batch [350][550]\t Training Loss 0.9538\t Accuracy 0.7817\n",
      "Epoch [0][20]\t Batch [400][550]\t Training Loss 0.9001\t Accuracy 0.7925\n",
      "Epoch [0][20]\t Batch [450][550]\t Training Loss 0.8564\t Accuracy 0.8010\n",
      "Epoch [0][20]\t Batch [500][550]\t Training Loss 0.8196\t Accuracy 0.8083\n",
      "\n",
      "Epoch [0]\t Average training loss 0.7877\t Average training accuracy 0.8147\n",
      "Epoch [0]\t Average validation loss 0.3675\t Average validation accuracy 0.9114\n",
      "\n",
      "Epoch [1][20]\t Batch [0][550]\t Training Loss 0.4342\t Accuracy 0.9000\n",
      "Epoch [1][20]\t Batch [50][550]\t Training Loss 0.4168\t Accuracy 0.8906\n",
      "Epoch [1][20]\t Batch [100][550]\t Training Loss 0.4200\t Accuracy 0.8896\n",
      "Epoch [1][20]\t Batch [150][550]\t Training Loss 0.4267\t Accuracy 0.8861\n",
      "Epoch [1][20]\t Batch [200][550]\t Training Loss 0.4205\t Accuracy 0.8881\n",
      "Epoch [1][20]\t Batch [250][550]\t Training Loss 0.4140\t Accuracy 0.8899\n",
      "Epoch [1][20]\t Batch [300][550]\t Training Loss 0.4101\t Accuracy 0.8904\n",
      "Epoch [1][20]\t Batch [350][550]\t Training Loss 0.4103\t Accuracy 0.8893\n",
      "Epoch [1][20]\t Batch [400][550]\t Training Loss 0.4063\t Accuracy 0.8902\n",
      "Epoch [1][20]\t Batch [450][550]\t Training Loss 0.4035\t Accuracy 0.8907\n",
      "Epoch [1][20]\t Batch [500][550]\t Training Loss 0.4014\t Accuracy 0.8909\n",
      "\n",
      "Epoch [1]\t Average training loss 0.3987\t Average training accuracy 0.8912\n",
      "Epoch [1]\t Average validation loss 0.2874\t Average validation accuracy 0.9256\n",
      "\n",
      "Epoch [2][20]\t Batch [0][550]\t Training Loss 0.3395\t Accuracy 0.9400\n",
      "Epoch [2][20]\t Batch [50][550]\t Training Loss 0.3319\t Accuracy 0.9094\n",
      "Epoch [2][20]\t Batch [100][550]\t Training Loss 0.3412\t Accuracy 0.9058\n",
      "Epoch [2][20]\t Batch [150][550]\t Training Loss 0.3521\t Accuracy 0.9024\n",
      "Epoch [2][20]\t Batch [200][550]\t Training Loss 0.3478\t Accuracy 0.9039\n",
      "Epoch [2][20]\t Batch [250][550]\t Training Loss 0.3450\t Accuracy 0.9047\n",
      "Epoch [2][20]\t Batch [300][550]\t Training Loss 0.3440\t Accuracy 0.9047\n",
      "Epoch [2][20]\t Batch [350][550]\t Training Loss 0.3461\t Accuracy 0.9033\n",
      "Epoch [2][20]\t Batch [400][550]\t Training Loss 0.3446\t Accuracy 0.9037\n",
      "Epoch [2][20]\t Batch [450][550]\t Training Loss 0.3439\t Accuracy 0.9035\n",
      "Epoch [2][20]\t Batch [500][550]\t Training Loss 0.3439\t Accuracy 0.9035\n",
      "\n",
      "Epoch [2]\t Average training loss 0.3432\t Average training accuracy 0.9035\n",
      "Epoch [2]\t Average validation loss 0.2579\t Average validation accuracy 0.9322\n",
      "\n",
      "Epoch [3][20]\t Batch [0][550]\t Training Loss 0.2997\t Accuracy 0.9400\n",
      "Epoch [3][20]\t Batch [50][550]\t Training Loss 0.2971\t Accuracy 0.9182\n",
      "Epoch [3][20]\t Batch [100][550]\t Training Loss 0.3078\t Accuracy 0.9142\n",
      "Epoch [3][20]\t Batch [150][550]\t Training Loss 0.3196\t Accuracy 0.9101\n",
      "Epoch [3][20]\t Batch [200][550]\t Training Loss 0.3154\t Accuracy 0.9115\n",
      "Epoch [3][20]\t Batch [250][550]\t Training Loss 0.3138\t Accuracy 0.9121\n",
      "Epoch [3][20]\t Batch [300][550]\t Training Loss 0.3135\t Accuracy 0.9123\n",
      "Epoch [3][20]\t Batch [350][550]\t Training Loss 0.3158\t Accuracy 0.9109\n",
      "Epoch [3][20]\t Batch [400][550]\t Training Loss 0.3151\t Accuracy 0.9108\n",
      "Epoch [3][20]\t Batch [450][550]\t Training Loss 0.3149\t Accuracy 0.9107\n",
      "Epoch [3][20]\t Batch [500][550]\t Training Loss 0.3155\t Accuracy 0.9105\n",
      "\n",
      "Epoch [3]\t Average training loss 0.3153\t Average training accuracy 0.9103\n",
      "Epoch [3]\t Average validation loss 0.2406\t Average validation accuracy 0.9354\n",
      "\n",
      "Epoch [4][20]\t Batch [0][550]\t Training Loss 0.2751\t Accuracy 0.9400\n",
      "Epoch [4][20]\t Batch [50][550]\t Training Loss 0.2759\t Accuracy 0.9233\n",
      "Epoch [4][20]\t Batch [100][550]\t Training Loss 0.2869\t Accuracy 0.9192\n",
      "Epoch [4][20]\t Batch [150][550]\t Training Loss 0.2989\t Accuracy 0.9151\n",
      "Epoch [4][20]\t Batch [200][550]\t Training Loss 0.2947\t Accuracy 0.9164\n",
      "Epoch [4][20]\t Batch [250][550]\t Training Loss 0.2936\t Accuracy 0.9170\n",
      "Epoch [4][20]\t Batch [300][550]\t Training Loss 0.2936\t Accuracy 0.9173\n",
      "Epoch [4][20]\t Batch [350][550]\t Training Loss 0.2958\t Accuracy 0.9159\n",
      "Epoch [4][20]\t Batch [400][550]\t Training Loss 0.2954\t Accuracy 0.9158\n",
      "Epoch [4][20]\t Batch [450][550]\t Training Loss 0.2956\t Accuracy 0.9157\n",
      "Epoch [4][20]\t Batch [500][550]\t Training Loss 0.2963\t Accuracy 0.9155\n",
      "\n",
      "Epoch [4]\t Average training loss 0.2965\t Average training accuracy 0.9152\n",
      "Epoch [4]\t Average validation loss 0.2281\t Average validation accuracy 0.9376\n",
      "\n",
      "Epoch [5][20]\t Batch [0][550]\t Training Loss 0.2573\t Accuracy 0.9400\n",
      "Epoch [5][20]\t Batch [50][550]\t Training Loss 0.2602\t Accuracy 0.9276\n",
      "Epoch [5][20]\t Batch [100][550]\t Training Loss 0.2712\t Accuracy 0.9239\n",
      "Epoch [5][20]\t Batch [150][550]\t Training Loss 0.2830\t Accuracy 0.9201\n",
      "Epoch [5][20]\t Batch [200][550]\t Training Loss 0.2788\t Accuracy 0.9212\n",
      "Epoch [5][20]\t Batch [250][550]\t Training Loss 0.2782\t Accuracy 0.9215\n",
      "Epoch [5][20]\t Batch [300][550]\t Training Loss 0.2783\t Accuracy 0.9218\n",
      "Epoch [5][20]\t Batch [350][550]\t Training Loss 0.2804\t Accuracy 0.9205\n",
      "Epoch [5][20]\t Batch [400][550]\t Training Loss 0.2802\t Accuracy 0.9201\n",
      "Epoch [5][20]\t Batch [450][550]\t Training Loss 0.2805\t Accuracy 0.9201\n",
      "Epoch [5][20]\t Batch [500][550]\t Training Loss 0.2814\t Accuracy 0.9200\n",
      "\n",
      "Epoch [5]\t Average training loss 0.2816\t Average training accuracy 0.9196\n",
      "Epoch [5]\t Average validation loss 0.2179\t Average validation accuracy 0.9408\n",
      "\n",
      "Epoch [6][20]\t Batch [0][550]\t Training Loss 0.2433\t Accuracy 0.9400\n",
      "Epoch [6][20]\t Batch [50][550]\t Training Loss 0.2473\t Accuracy 0.9310\n",
      "Epoch [6][20]\t Batch [100][550]\t Training Loss 0.2581\t Accuracy 0.9266\n",
      "Epoch [6][20]\t Batch [150][550]\t Training Loss 0.2696\t Accuracy 0.9231\n",
      "Epoch [6][20]\t Batch [200][550]\t Training Loss 0.2655\t Accuracy 0.9240\n",
      "Epoch [6][20]\t Batch [250][550]\t Training Loss 0.2652\t Accuracy 0.9242\n",
      "Epoch [6][20]\t Batch [300][550]\t Training Loss 0.2654\t Accuracy 0.9247\n",
      "Epoch [6][20]\t Batch [350][550]\t Training Loss 0.2673\t Accuracy 0.9236\n",
      "Epoch [6][20]\t Batch [400][550]\t Training Loss 0.2672\t Accuracy 0.9234\n",
      "Epoch [6][20]\t Batch [450][550]\t Training Loss 0.2676\t Accuracy 0.9233\n",
      "Epoch [6][20]\t Batch [500][550]\t Training Loss 0.2686\t Accuracy 0.9231\n",
      "\n",
      "Epoch [6]\t Average training loss 0.2688\t Average training accuracy 0.9229\n",
      "Epoch [6]\t Average validation loss 0.2089\t Average validation accuracy 0.9440\n",
      "\n",
      "Epoch [7][20]\t Batch [0][550]\t Training Loss 0.2316\t Accuracy 0.9400\n",
      "Epoch [7][20]\t Batch [50][550]\t Training Loss 0.2361\t Accuracy 0.9355\n",
      "Epoch [7][20]\t Batch [100][550]\t Training Loss 0.2466\t Accuracy 0.9312\n",
      "Epoch [7][20]\t Batch [150][550]\t Training Loss 0.2576\t Accuracy 0.9270\n",
      "Epoch [7][20]\t Batch [200][550]\t Training Loss 0.2536\t Accuracy 0.9279\n",
      "Epoch [7][20]\t Batch [250][550]\t Training Loss 0.2535\t Accuracy 0.9281\n",
      "Epoch [7][20]\t Batch [300][550]\t Training Loss 0.2539\t Accuracy 0.9282\n",
      "Epoch [7][20]\t Batch [350][550]\t Training Loss 0.2556\t Accuracy 0.9274\n",
      "Epoch [7][20]\t Batch [400][550]\t Training Loss 0.2556\t Accuracy 0.9269\n",
      "Epoch [7][20]\t Batch [450][550]\t Training Loss 0.2560\t Accuracy 0.9266\n",
      "Epoch [7][20]\t Batch [500][550]\t Training Loss 0.2571\t Accuracy 0.9264\n",
      "\n",
      "Epoch [7]\t Average training loss 0.2573\t Average training accuracy 0.9261\n",
      "Epoch [7]\t Average validation loss 0.2007\t Average validation accuracy 0.9450\n",
      "\n",
      "Epoch [8][20]\t Batch [0][550]\t Training Loss 0.2214\t Accuracy 0.9500\n",
      "Epoch [8][20]\t Batch [50][550]\t Training Loss 0.2259\t Accuracy 0.9378\n",
      "Epoch [8][20]\t Batch [100][550]\t Training Loss 0.2361\t Accuracy 0.9344\n",
      "Epoch [8][20]\t Batch [150][550]\t Training Loss 0.2466\t Accuracy 0.9306\n",
      "Epoch [8][20]\t Batch [200][550]\t Training Loss 0.2428\t Accuracy 0.9312\n",
      "Epoch [8][20]\t Batch [250][550]\t Training Loss 0.2429\t Accuracy 0.9318\n",
      "Epoch [8][20]\t Batch [300][550]\t Training Loss 0.2433\t Accuracy 0.9316\n",
      "Epoch [8][20]\t Batch [350][550]\t Training Loss 0.2449\t Accuracy 0.9309\n",
      "Epoch [8][20]\t Batch [400][550]\t Training Loss 0.2450\t Accuracy 0.9304\n",
      "Epoch [8][20]\t Batch [450][550]\t Training Loss 0.2454\t Accuracy 0.9302\n",
      "Epoch [8][20]\t Batch [500][550]\t Training Loss 0.2465\t Accuracy 0.9299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8]\t Average training loss 0.2468\t Average training accuracy 0.9297\n",
      "Epoch [8]\t Average validation loss 0.1932\t Average validation accuracy 0.9476\n",
      "\n",
      "Epoch [9][20]\t Batch [0][550]\t Training Loss 0.2121\t Accuracy 0.9500\n",
      "Epoch [9][20]\t Batch [50][550]\t Training Loss 0.2164\t Accuracy 0.9406\n",
      "Epoch [9][20]\t Batch [100][550]\t Training Loss 0.2264\t Accuracy 0.9367\n",
      "Epoch [9][20]\t Batch [150][550]\t Training Loss 0.2363\t Accuracy 0.9336\n",
      "Epoch [9][20]\t Batch [200][550]\t Training Loss 0.2327\t Accuracy 0.9343\n",
      "Epoch [9][20]\t Batch [250][550]\t Training Loss 0.2329\t Accuracy 0.9347\n",
      "Epoch [9][20]\t Batch [300][550]\t Training Loss 0.2335\t Accuracy 0.9347\n",
      "Epoch [9][20]\t Batch [350][550]\t Training Loss 0.2349\t Accuracy 0.9340\n",
      "Epoch [9][20]\t Batch [400][550]\t Training Loss 0.2350\t Accuracy 0.9337\n",
      "Epoch [9][20]\t Batch [450][550]\t Training Loss 0.2355\t Accuracy 0.9334\n",
      "Epoch [9][20]\t Batch [500][550]\t Training Loss 0.2367\t Accuracy 0.9330\n",
      "\n",
      "Epoch [9]\t Average training loss 0.2369\t Average training accuracy 0.9328\n",
      "Epoch [9]\t Average validation loss 0.1862\t Average validation accuracy 0.9502\n",
      "\n",
      "Epoch [10][20]\t Batch [0][550]\t Training Loss 0.2035\t Accuracy 0.9500\n",
      "Epoch [10][20]\t Batch [50][550]\t Training Loss 0.2076\t Accuracy 0.9420\n",
      "Epoch [10][20]\t Batch [100][550]\t Training Loss 0.2173\t Accuracy 0.9386\n",
      "Epoch [10][20]\t Batch [150][550]\t Training Loss 0.2267\t Accuracy 0.9356\n",
      "Epoch [10][20]\t Batch [200][550]\t Training Loss 0.2233\t Accuracy 0.9366\n",
      "Epoch [10][20]\t Batch [250][550]\t Training Loss 0.2237\t Accuracy 0.9368\n",
      "Epoch [10][20]\t Batch [300][550]\t Training Loss 0.2243\t Accuracy 0.9368\n",
      "Epoch [10][20]\t Batch [350][550]\t Training Loss 0.2256\t Accuracy 0.9363\n",
      "Epoch [10][20]\t Batch [400][550]\t Training Loss 0.2258\t Accuracy 0.9359\n",
      "Epoch [10][20]\t Batch [450][550]\t Training Loss 0.2263\t Accuracy 0.9357\n",
      "Epoch [10][20]\t Batch [500][550]\t Training Loss 0.2275\t Accuracy 0.9352\n",
      "\n",
      "Epoch [10]\t Average training loss 0.2277\t Average training accuracy 0.9352\n",
      "Epoch [10]\t Average validation loss 0.1798\t Average validation accuracy 0.9524\n",
      "\n",
      "Epoch [11][20]\t Batch [0][550]\t Training Loss 0.1954\t Accuracy 0.9500\n",
      "Epoch [11][20]\t Batch [50][550]\t Training Loss 0.1994\t Accuracy 0.9447\n",
      "Epoch [11][20]\t Batch [100][550]\t Training Loss 0.2089\t Accuracy 0.9407\n",
      "Epoch [11][20]\t Batch [150][550]\t Training Loss 0.2177\t Accuracy 0.9379\n",
      "Epoch [11][20]\t Batch [200][550]\t Training Loss 0.2146\t Accuracy 0.9389\n",
      "Epoch [11][20]\t Batch [250][550]\t Training Loss 0.2150\t Accuracy 0.9391\n",
      "Epoch [11][20]\t Batch [300][550]\t Training Loss 0.2158\t Accuracy 0.9392\n",
      "Epoch [11][20]\t Batch [350][550]\t Training Loss 0.2170\t Accuracy 0.9388\n",
      "Epoch [11][20]\t Batch [400][550]\t Training Loss 0.2171\t Accuracy 0.9385\n",
      "Epoch [11][20]\t Batch [450][550]\t Training Loss 0.2177\t Accuracy 0.9382\n",
      "Epoch [11][20]\t Batch [500][550]\t Training Loss 0.2189\t Accuracy 0.9378\n",
      "\n",
      "Epoch [11]\t Average training loss 0.2191\t Average training accuracy 0.9378\n",
      "Epoch [11]\t Average validation loss 0.1739\t Average validation accuracy 0.9546\n",
      "\n",
      "Epoch [12][20]\t Batch [0][550]\t Training Loss 0.1878\t Accuracy 0.9500\n",
      "Epoch [12][20]\t Batch [50][550]\t Training Loss 0.1918\t Accuracy 0.9478\n",
      "Epoch [12][20]\t Batch [100][550]\t Training Loss 0.2010\t Accuracy 0.9432\n",
      "Epoch [12][20]\t Batch [150][550]\t Training Loss 0.2093\t Accuracy 0.9405\n",
      "Epoch [12][20]\t Batch [200][550]\t Training Loss 0.2064\t Accuracy 0.9412\n",
      "Epoch [12][20]\t Batch [250][550]\t Training Loss 0.2069\t Accuracy 0.9415\n",
      "Epoch [12][20]\t Batch [300][550]\t Training Loss 0.2077\t Accuracy 0.9416\n",
      "Epoch [12][20]\t Batch [350][550]\t Training Loss 0.2089\t Accuracy 0.9409\n",
      "Epoch [12][20]\t Batch [400][550]\t Training Loss 0.2091\t Accuracy 0.9407\n",
      "Epoch [12][20]\t Batch [450][550]\t Training Loss 0.2096\t Accuracy 0.9404\n",
      "Epoch [12][20]\t Batch [500][550]\t Training Loss 0.2109\t Accuracy 0.9400\n",
      "\n",
      "Epoch [12]\t Average training loss 0.2111\t Average training accuracy 0.9400\n",
      "Epoch [12]\t Average validation loss 0.1684\t Average validation accuracy 0.9560\n",
      "\n",
      "Epoch [13][20]\t Batch [0][550]\t Training Loss 0.1807\t Accuracy 0.9600\n",
      "Epoch [13][20]\t Batch [50][550]\t Training Loss 0.1846\t Accuracy 0.9506\n",
      "Epoch [13][20]\t Batch [100][550]\t Training Loss 0.1937\t Accuracy 0.9455\n",
      "Epoch [13][20]\t Batch [150][550]\t Training Loss 0.2015\t Accuracy 0.9430\n",
      "Epoch [13][20]\t Batch [200][550]\t Training Loss 0.1988\t Accuracy 0.9439\n",
      "Epoch [13][20]\t Batch [250][550]\t Training Loss 0.1994\t Accuracy 0.9438\n",
      "Epoch [13][20]\t Batch [300][550]\t Training Loss 0.2002\t Accuracy 0.9438\n",
      "Epoch [13][20]\t Batch [350][550]\t Training Loss 0.2014\t Accuracy 0.9432\n",
      "Epoch [13][20]\t Batch [400][550]\t Training Loss 0.2015\t Accuracy 0.9431\n",
      "Epoch [13][20]\t Batch [450][550]\t Training Loss 0.2021\t Accuracy 0.9429\n",
      "Epoch [13][20]\t Batch [500][550]\t Training Loss 0.2034\t Accuracy 0.9424\n",
      "\n",
      "Epoch [13]\t Average training loss 0.2036\t Average training accuracy 0.9423\n",
      "Epoch [13]\t Average validation loss 0.1634\t Average validation accuracy 0.9576\n",
      "\n",
      "Epoch [14][20]\t Batch [0][550]\t Training Loss 0.1740\t Accuracy 0.9600\n",
      "Epoch [14][20]\t Batch [50][550]\t Training Loss 0.1779\t Accuracy 0.9524\n",
      "Epoch [14][20]\t Batch [100][550]\t Training Loss 0.1869\t Accuracy 0.9470\n",
      "Epoch [14][20]\t Batch [150][550]\t Training Loss 0.1942\t Accuracy 0.9448\n",
      "Epoch [14][20]\t Batch [200][550]\t Training Loss 0.1916\t Accuracy 0.9458\n",
      "Epoch [14][20]\t Batch [250][550]\t Training Loss 0.1923\t Accuracy 0.9455\n",
      "Epoch [14][20]\t Batch [300][550]\t Training Loss 0.1932\t Accuracy 0.9456\n",
      "Epoch [14][20]\t Batch [350][550]\t Training Loss 0.1943\t Accuracy 0.9452\n",
      "Epoch [14][20]\t Batch [400][550]\t Training Loss 0.1945\t Accuracy 0.9451\n",
      "Epoch [14][20]\t Batch [450][550]\t Training Loss 0.1950\t Accuracy 0.9449\n",
      "Epoch [14][20]\t Batch [500][550]\t Training Loss 0.1964\t Accuracy 0.9444\n",
      "\n",
      "Epoch [14]\t Average training loss 0.1966\t Average training accuracy 0.9445\n",
      "Epoch [14]\t Average validation loss 0.1587\t Average validation accuracy 0.9596\n",
      "\n",
      "Epoch [15][20]\t Batch [0][550]\t Training Loss 0.1677\t Accuracy 0.9600\n",
      "Epoch [15][20]\t Batch [50][550]\t Training Loss 0.1716\t Accuracy 0.9533\n",
      "Epoch [15][20]\t Batch [100][550]\t Training Loss 0.1805\t Accuracy 0.9486\n",
      "Epoch [15][20]\t Batch [150][550]\t Training Loss 0.1873\t Accuracy 0.9466\n",
      "Epoch [15][20]\t Batch [200][550]\t Training Loss 0.1850\t Accuracy 0.9476\n",
      "Epoch [15][20]\t Batch [250][550]\t Training Loss 0.1856\t Accuracy 0.9474\n",
      "Epoch [15][20]\t Batch [300][550]\t Training Loss 0.1866\t Accuracy 0.9473\n",
      "Epoch [15][20]\t Batch [350][550]\t Training Loss 0.1877\t Accuracy 0.9470\n",
      "Epoch [15][20]\t Batch [400][550]\t Training Loss 0.1878\t Accuracy 0.9468\n",
      "Epoch [15][20]\t Batch [450][550]\t Training Loss 0.1884\t Accuracy 0.9466\n",
      "Epoch [15][20]\t Batch [500][550]\t Training Loss 0.1898\t Accuracy 0.9461\n",
      "\n",
      "Epoch [15]\t Average training loss 0.1900\t Average training accuracy 0.9463\n",
      "Epoch [15]\t Average validation loss 0.1544\t Average validation accuracy 0.9618\n",
      "\n",
      "Epoch [16][20]\t Batch [0][550]\t Training Loss 0.1618\t Accuracy 0.9600\n",
      "Epoch [16][20]\t Batch [50][550]\t Training Loss 0.1658\t Accuracy 0.9549\n",
      "Epoch [16][20]\t Batch [100][550]\t Training Loss 0.1745\t Accuracy 0.9504\n",
      "Epoch [16][20]\t Batch [150][550]\t Training Loss 0.1808\t Accuracy 0.9487\n",
      "Epoch [16][20]\t Batch [200][550]\t Training Loss 0.1787\t Accuracy 0.9496\n",
      "Epoch [16][20]\t Batch [250][550]\t Training Loss 0.1794\t Accuracy 0.9492\n",
      "Epoch [16][20]\t Batch [300][550]\t Training Loss 0.1804\t Accuracy 0.9490\n",
      "Epoch [16][20]\t Batch [350][550]\t Training Loss 0.1815\t Accuracy 0.9486\n",
      "Epoch [16][20]\t Batch [400][550]\t Training Loss 0.1816\t Accuracy 0.9485\n",
      "Epoch [16][20]\t Batch [450][550]\t Training Loss 0.1822\t Accuracy 0.9482\n",
      "Epoch [16][20]\t Batch [500][550]\t Training Loss 0.1836\t Accuracy 0.9477\n",
      "\n",
      "Epoch [16]\t Average training loss 0.1838\t Average training accuracy 0.9479\n",
      "Epoch [16]\t Average validation loss 0.1503\t Average validation accuracy 0.9626\n",
      "\n",
      "Epoch [17][20]\t Batch [0][550]\t Training Loss 0.1564\t Accuracy 0.9600\n",
      "Epoch [17][20]\t Batch [50][550]\t Training Loss 0.1602\t Accuracy 0.9578\n",
      "Epoch [17][20]\t Batch [100][550]\t Training Loss 0.1689\t Accuracy 0.9523\n",
      "Epoch [17][20]\t Batch [150][550]\t Training Loss 0.1747\t Accuracy 0.9505\n",
      "Epoch [17][20]\t Batch [200][550]\t Training Loss 0.1728\t Accuracy 0.9514\n",
      "Epoch [17][20]\t Batch [250][550]\t Training Loss 0.1735\t Accuracy 0.9509\n",
      "Epoch [17][20]\t Batch [300][550]\t Training Loss 0.1746\t Accuracy 0.9509\n",
      "Epoch [17][20]\t Batch [350][550]\t Training Loss 0.1756\t Accuracy 0.9505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17][20]\t Batch [400][550]\t Training Loss 0.1758\t Accuracy 0.9504\n",
      "Epoch [17][20]\t Batch [450][550]\t Training Loss 0.1764\t Accuracy 0.9502\n",
      "Epoch [17][20]\t Batch [500][550]\t Training Loss 0.1778\t Accuracy 0.9498\n",
      "\n",
      "Epoch [17]\t Average training loss 0.1779\t Average training accuracy 0.9499\n",
      "Epoch [17]\t Average validation loss 0.1465\t Average validation accuracy 0.9638\n",
      "\n",
      "Epoch [18][20]\t Batch [0][550]\t Training Loss 0.1513\t Accuracy 0.9700\n",
      "Epoch [18][20]\t Batch [50][550]\t Training Loss 0.1551\t Accuracy 0.9586\n",
      "Epoch [18][20]\t Batch [100][550]\t Training Loss 0.1636\t Accuracy 0.9530\n",
      "Epoch [18][20]\t Batch [150][550]\t Training Loss 0.1690\t Accuracy 0.9519\n",
      "Epoch [18][20]\t Batch [200][550]\t Training Loss 0.1672\t Accuracy 0.9529\n",
      "Epoch [18][20]\t Batch [250][550]\t Training Loss 0.1680\t Accuracy 0.9524\n",
      "Epoch [18][20]\t Batch [300][550]\t Training Loss 0.1691\t Accuracy 0.9525\n",
      "Epoch [18][20]\t Batch [350][550]\t Training Loss 0.1701\t Accuracy 0.9522\n",
      "Epoch [18][20]\t Batch [400][550]\t Training Loss 0.1703\t Accuracy 0.9521\n",
      "Epoch [18][20]\t Batch [450][550]\t Training Loss 0.1708\t Accuracy 0.9519\n",
      "Epoch [18][20]\t Batch [500][550]\t Training Loss 0.1723\t Accuracy 0.9514\n",
      "\n",
      "Epoch [18]\t Average training loss 0.1724\t Average training accuracy 0.9515\n",
      "Epoch [18]\t Average validation loss 0.1430\t Average validation accuracy 0.9648\n",
      "\n",
      "Epoch [19][20]\t Batch [0][550]\t Training Loss 0.1465\t Accuracy 0.9700\n",
      "Epoch [19][20]\t Batch [50][550]\t Training Loss 0.1502\t Accuracy 0.9600\n",
      "Epoch [19][20]\t Batch [100][550]\t Training Loss 0.1586\t Accuracy 0.9542\n",
      "Epoch [19][20]\t Batch [150][550]\t Training Loss 0.1636\t Accuracy 0.9532\n",
      "Epoch [19][20]\t Batch [200][550]\t Training Loss 0.1620\t Accuracy 0.9542\n",
      "Epoch [19][20]\t Batch [250][550]\t Training Loss 0.1627\t Accuracy 0.9538\n",
      "Epoch [19][20]\t Batch [300][550]\t Training Loss 0.1639\t Accuracy 0.9539\n",
      "Epoch [19][20]\t Batch [350][550]\t Training Loss 0.1649\t Accuracy 0.9536\n",
      "Epoch [19][20]\t Batch [400][550]\t Training Loss 0.1651\t Accuracy 0.9535\n",
      "Epoch [19][20]\t Batch [450][550]\t Training Loss 0.1656\t Accuracy 0.9533\n",
      "Epoch [19][20]\t Batch [500][550]\t Training Loss 0.1670\t Accuracy 0.9530\n",
      "\n",
      "Epoch [19]\t Average training loss 0.1672\t Average training accuracy 0.9529\n",
      "Epoch [19]\t Average validation loss 0.1396\t Average validation accuracy 0.9654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sigmoidMLP, sigmoid_loss, sigmoid_acc = train(sigmoidMLP, criterion, sgd, data_train, max_epoch, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "The test accuracy is 0.9507.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(sigmoidMLP, criterion, data_test, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.2 使用Softmax交叉熵损失和ReLU激活函数训练多层感知机\n",
    "训练带有一个隐含层且神经元个数为128的多层感知机，使用Softmax交叉熵损失和ReLU激活函数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reluMLP = Network()\n",
    "# 使用FCLayer和SigmoidLayer构建多层感知机\n",
    "# 128为隐含层的神经元数目\n",
    "reluMLP.add(FCLayer(784, 128))\n",
    "reluMLP.add(ReLULayer())\n",
    "reluMLP.add(FCLayer(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][20]\t Batch [0][550]\t Training Loss 2.4977\t Accuracy 0.0900\n",
      "Epoch [0][20]\t Batch [50][550]\t Training Loss 0.9540\t Accuracy 0.7394\n",
      "Epoch [0][20]\t Batch [100][550]\t Training Loss 0.7160\t Accuracy 0.8054\n",
      "Epoch [0][20]\t Batch [150][550]\t Training Loss 0.6197\t Accuracy 0.8295\n",
      "Epoch [0][20]\t Batch [200][550]\t Training Loss 0.5536\t Accuracy 0.8480\n",
      "Epoch [0][20]\t Batch [250][550]\t Training Loss 0.5094\t Accuracy 0.8598\n",
      "Epoch [0][20]\t Batch [300][550]\t Training Loss 0.4766\t Accuracy 0.8686\n",
      "Epoch [0][20]\t Batch [350][550]\t Training Loss 0.4532\t Accuracy 0.8746\n",
      "Epoch [0][20]\t Batch [400][550]\t Training Loss 0.4321\t Accuracy 0.8798\n",
      "Epoch [0][20]\t Batch [450][550]\t Training Loss 0.4151\t Accuracy 0.8843\n",
      "Epoch [0][20]\t Batch [500][550]\t Training Loss 0.4022\t Accuracy 0.8875\n",
      "\n",
      "Epoch [0]\t Average training loss 0.3901\t Average training accuracy 0.8910\n",
      "Epoch [0]\t Average validation loss 0.1963\t Average validation accuracy 0.9498\n",
      "\n",
      "Epoch [1][20]\t Batch [0][550]\t Training Loss 0.2567\t Accuracy 0.9400\n",
      "Epoch [1][20]\t Batch [50][550]\t Training Loss 0.2176\t Accuracy 0.9412\n",
      "Epoch [1][20]\t Batch [100][550]\t Training Loss 0.2271\t Accuracy 0.9375\n",
      "Epoch [1][20]\t Batch [150][550]\t Training Loss 0.2331\t Accuracy 0.9348\n",
      "Epoch [1][20]\t Batch [200][550]\t Training Loss 0.2274\t Accuracy 0.9365\n",
      "Epoch [1][20]\t Batch [250][550]\t Training Loss 0.2247\t Accuracy 0.9372\n",
      "Epoch [1][20]\t Batch [300][550]\t Training Loss 0.2230\t Accuracy 0.9377\n",
      "Epoch [1][20]\t Batch [350][550]\t Training Loss 0.2213\t Accuracy 0.9380\n",
      "Epoch [1][20]\t Batch [400][550]\t Training Loss 0.2185\t Accuracy 0.9386\n",
      "Epoch [1][20]\t Batch [450][550]\t Training Loss 0.2168\t Accuracy 0.9391\n",
      "Epoch [1][20]\t Batch [500][550]\t Training Loss 0.2165\t Accuracy 0.9391\n",
      "\n",
      "Epoch [1]\t Average training loss 0.2149\t Average training accuracy 0.9396\n",
      "Epoch [1]\t Average validation loss 0.1524\t Average validation accuracy 0.9608\n",
      "\n",
      "Epoch [2][20]\t Batch [0][550]\t Training Loss 0.1740\t Accuracy 0.9500\n",
      "Epoch [2][20]\t Batch [50][550]\t Training Loss 0.1619\t Accuracy 0.9561\n",
      "Epoch [2][20]\t Batch [100][550]\t Training Loss 0.1712\t Accuracy 0.9505\n",
      "Epoch [2][20]\t Batch [150][550]\t Training Loss 0.1757\t Accuracy 0.9496\n",
      "Epoch [2][20]\t Batch [200][550]\t Training Loss 0.1725\t Accuracy 0.9504\n",
      "Epoch [2][20]\t Batch [250][550]\t Training Loss 0.1712\t Accuracy 0.9510\n",
      "Epoch [2][20]\t Batch [300][550]\t Training Loss 0.1712\t Accuracy 0.9509\n",
      "Epoch [2][20]\t Batch [350][550]\t Training Loss 0.1705\t Accuracy 0.9510\n",
      "Epoch [2][20]\t Batch [400][550]\t Training Loss 0.1691\t Accuracy 0.9517\n",
      "Epoch [2][20]\t Batch [450][550]\t Training Loss 0.1686\t Accuracy 0.9518\n",
      "Epoch [2][20]\t Batch [500][550]\t Training Loss 0.1694\t Accuracy 0.9517\n",
      "\n",
      "Epoch [2]\t Average training loss 0.1687\t Average training accuracy 0.9520\n",
      "Epoch [2]\t Average validation loss 0.1293\t Average validation accuracy 0.9654\n",
      "\n",
      "Epoch [3][20]\t Batch [0][550]\t Training Loss 0.1342\t Accuracy 0.9500\n",
      "Epoch [3][20]\t Batch [50][550]\t Training Loss 0.1316\t Accuracy 0.9653\n",
      "Epoch [3][20]\t Batch [100][550]\t Training Loss 0.1400\t Accuracy 0.9602\n",
      "Epoch [3][20]\t Batch [150][550]\t Training Loss 0.1434\t Accuracy 0.9594\n",
      "Epoch [3][20]\t Batch [200][550]\t Training Loss 0.1414\t Accuracy 0.9597\n",
      "Epoch [3][20]\t Batch [250][550]\t Training Loss 0.1406\t Accuracy 0.9600\n",
      "Epoch [3][20]\t Batch [300][550]\t Training Loss 0.1411\t Accuracy 0.9598\n",
      "Epoch [3][20]\t Batch [350][550]\t Training Loss 0.1408\t Accuracy 0.9599\n",
      "Epoch [3][20]\t Batch [400][550]\t Training Loss 0.1400\t Accuracy 0.9603\n",
      "Epoch [3][20]\t Batch [450][550]\t Training Loss 0.1399\t Accuracy 0.9602\n",
      "Epoch [3][20]\t Batch [500][550]\t Training Loss 0.1411\t Accuracy 0.9599\n",
      "\n",
      "Epoch [3]\t Average training loss 0.1408\t Average training accuracy 0.9601\n",
      "Epoch [3]\t Average validation loss 0.1150\t Average validation accuracy 0.9692\n",
      "\n",
      "Epoch [4][20]\t Batch [0][550]\t Training Loss 0.1128\t Accuracy 0.9600\n",
      "Epoch [4][20]\t Batch [50][550]\t Training Loss 0.1122\t Accuracy 0.9706\n",
      "Epoch [4][20]\t Batch [100][550]\t Training Loss 0.1192\t Accuracy 0.9663\n",
      "Epoch [4][20]\t Batch [150][550]\t Training Loss 0.1218\t Accuracy 0.9656\n",
      "Epoch [4][20]\t Batch [200][550]\t Training Loss 0.1205\t Accuracy 0.9658\n",
      "Epoch [4][20]\t Batch [250][550]\t Training Loss 0.1199\t Accuracy 0.9661\n",
      "Epoch [4][20]\t Batch [300][550]\t Training Loss 0.1206\t Accuracy 0.9661\n",
      "Epoch [4][20]\t Batch [350][550]\t Training Loss 0.1205\t Accuracy 0.9661\n",
      "Epoch [4][20]\t Batch [400][550]\t Training Loss 0.1200\t Accuracy 0.9667\n",
      "Epoch [4][20]\t Batch [450][550]\t Training Loss 0.1202\t Accuracy 0.9665\n",
      "Epoch [4][20]\t Batch [500][550]\t Training Loss 0.1216\t Accuracy 0.9660\n",
      "\n",
      "Epoch [4]\t Average training loss 0.1214\t Average training accuracy 0.9662\n",
      "Epoch [4]\t Average validation loss 0.1054\t Average validation accuracy 0.9716\n",
      "\n",
      "Epoch [5][20]\t Batch [0][550]\t Training Loss 0.0975\t Accuracy 0.9700\n",
      "Epoch [5][20]\t Batch [50][550]\t Training Loss 0.0981\t Accuracy 0.9747\n",
      "Epoch [5][20]\t Batch [100][550]\t Training Loss 0.1040\t Accuracy 0.9721\n",
      "Epoch [5][20]\t Batch [150][550]\t Training Loss 0.1060\t Accuracy 0.9709\n",
      "Epoch [5][20]\t Batch [200][550]\t Training Loss 0.1052\t Accuracy 0.9708\n",
      "Epoch [5][20]\t Batch [250][550]\t Training Loss 0.1047\t Accuracy 0.9706\n",
      "Epoch [5][20]\t Batch [300][550]\t Training Loss 0.1055\t Accuracy 0.9707\n",
      "Epoch [5][20]\t Batch [350][550]\t Training Loss 0.1055\t Accuracy 0.9706\n",
      "Epoch [5][20]\t Batch [400][550]\t Training Loss 0.1052\t Accuracy 0.9709\n",
      "Epoch [5][20]\t Batch [450][550]\t Training Loss 0.1056\t Accuracy 0.9706\n",
      "Epoch [5][20]\t Batch [500][550]\t Training Loss 0.1070\t Accuracy 0.9701\n",
      "\n",
      "Epoch [5]\t Average training loss 0.1068\t Average training accuracy 0.9702\n",
      "Epoch [5]\t Average validation loss 0.0985\t Average validation accuracy 0.9738\n",
      "\n",
      "Epoch [6][20]\t Batch [0][550]\t Training Loss 0.0858\t Accuracy 0.9800\n",
      "Epoch [6][20]\t Batch [50][550]\t Training Loss 0.0876\t Accuracy 0.9767\n",
      "Epoch [6][20]\t Batch [100][550]\t Training Loss 0.0926\t Accuracy 0.9748\n",
      "Epoch [6][20]\t Batch [150][550]\t Training Loss 0.0938\t Accuracy 0.9736\n",
      "Epoch [6][20]\t Batch [200][550]\t Training Loss 0.0933\t Accuracy 0.9735\n",
      "Epoch [6][20]\t Batch [250][550]\t Training Loss 0.0929\t Accuracy 0.9736\n",
      "Epoch [6][20]\t Batch [300][550]\t Training Loss 0.0938\t Accuracy 0.9736\n",
      "Epoch [6][20]\t Batch [350][550]\t Training Loss 0.0938\t Accuracy 0.9735\n",
      "Epoch [6][20]\t Batch [400][550]\t Training Loss 0.0937\t Accuracy 0.9738\n",
      "Epoch [6][20]\t Batch [450][550]\t Training Loss 0.0941\t Accuracy 0.9736\n",
      "Epoch [6][20]\t Batch [500][550]\t Training Loss 0.0955\t Accuracy 0.9733\n",
      "\n",
      "Epoch [6]\t Average training loss 0.0954\t Average training accuracy 0.9733\n",
      "Epoch [6]\t Average validation loss 0.0930\t Average validation accuracy 0.9754\n",
      "\n",
      "Epoch [7][20]\t Batch [0][550]\t Training Loss 0.0770\t Accuracy 0.9800\n",
      "Epoch [7][20]\t Batch [50][550]\t Training Loss 0.0792\t Accuracy 0.9780\n",
      "Epoch [7][20]\t Batch [100][550]\t Training Loss 0.0833\t Accuracy 0.9768\n",
      "Epoch [7][20]\t Batch [150][550]\t Training Loss 0.0841\t Accuracy 0.9761\n",
      "Epoch [7][20]\t Batch [200][550]\t Training Loss 0.0838\t Accuracy 0.9764\n",
      "Epoch [7][20]\t Batch [250][550]\t Training Loss 0.0834\t Accuracy 0.9765\n",
      "Epoch [7][20]\t Batch [300][550]\t Training Loss 0.0844\t Accuracy 0.9764\n",
      "Epoch [7][20]\t Batch [350][550]\t Training Loss 0.0844\t Accuracy 0.9765\n",
      "Epoch [7][20]\t Batch [400][550]\t Training Loss 0.0844\t Accuracy 0.9768\n",
      "Epoch [7][20]\t Batch [450][550]\t Training Loss 0.0848\t Accuracy 0.9767\n",
      "Epoch [7][20]\t Batch [500][550]\t Training Loss 0.0861\t Accuracy 0.9764\n",
      "\n",
      "Epoch [7]\t Average training loss 0.0860\t Average training accuracy 0.9765\n",
      "Epoch [7]\t Average validation loss 0.0886\t Average validation accuracy 0.9762\n",
      "\n",
      "Epoch [8][20]\t Batch [0][550]\t Training Loss 0.0698\t Accuracy 0.9800\n",
      "Epoch [8][20]\t Batch [50][550]\t Training Loss 0.0721\t Accuracy 0.9806\n",
      "Epoch [8][20]\t Batch [100][550]\t Training Loss 0.0755\t Accuracy 0.9794\n",
      "Epoch [8][20]\t Batch [150][550]\t Training Loss 0.0759\t Accuracy 0.9785\n",
      "Epoch [8][20]\t Batch [200][550]\t Training Loss 0.0758\t Accuracy 0.9787\n",
      "Epoch [8][20]\t Batch [250][550]\t Training Loss 0.0755\t Accuracy 0.9789\n",
      "Epoch [8][20]\t Batch [300][550]\t Training Loss 0.0765\t Accuracy 0.9788\n",
      "Epoch [8][20]\t Batch [350][550]\t Training Loss 0.0765\t Accuracy 0.9790\n",
      "Epoch [8][20]\t Batch [400][550]\t Training Loss 0.0766\t Accuracy 0.9791\n",
      "Epoch [8][20]\t Batch [450][550]\t Training Loss 0.0771\t Accuracy 0.9790\n",
      "Epoch [8][20]\t Batch [500][550]\t Training Loss 0.0783\t Accuracy 0.9787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8]\t Average training loss 0.0782\t Average training accuracy 0.9786\n",
      "Epoch [8]\t Average validation loss 0.0853\t Average validation accuracy 0.9770\n",
      "\n",
      "Epoch [9][20]\t Batch [0][550]\t Training Loss 0.0636\t Accuracy 0.9800\n",
      "Epoch [9][20]\t Batch [50][550]\t Training Loss 0.0661\t Accuracy 0.9825\n",
      "Epoch [9][20]\t Batch [100][550]\t Training Loss 0.0691\t Accuracy 0.9818\n",
      "Epoch [9][20]\t Batch [150][550]\t Training Loss 0.0691\t Accuracy 0.9808\n",
      "Epoch [9][20]\t Batch [200][550]\t Training Loss 0.0692\t Accuracy 0.9808\n",
      "Epoch [9][20]\t Batch [250][550]\t Training Loss 0.0688\t Accuracy 0.9810\n",
      "Epoch [9][20]\t Batch [300][550]\t Training Loss 0.0698\t Accuracy 0.9809\n",
      "Epoch [9][20]\t Batch [350][550]\t Training Loss 0.0698\t Accuracy 0.9809\n",
      "Epoch [9][20]\t Batch [400][550]\t Training Loss 0.0700\t Accuracy 0.9809\n",
      "Epoch [9][20]\t Batch [450][550]\t Training Loss 0.0705\t Accuracy 0.9809\n",
      "Epoch [9][20]\t Batch [500][550]\t Training Loss 0.0717\t Accuracy 0.9806\n",
      "\n",
      "Epoch [9]\t Average training loss 0.0716\t Average training accuracy 0.9806\n",
      "Epoch [9]\t Average validation loss 0.0827\t Average validation accuracy 0.9776\n",
      "\n",
      "Epoch [10][20]\t Batch [0][550]\t Training Loss 0.0583\t Accuracy 0.9800\n",
      "Epoch [10][20]\t Batch [50][550]\t Training Loss 0.0611\t Accuracy 0.9845\n",
      "Epoch [10][20]\t Batch [100][550]\t Training Loss 0.0636\t Accuracy 0.9837\n",
      "Epoch [10][20]\t Batch [150][550]\t Training Loss 0.0633\t Accuracy 0.9828\n",
      "Epoch [10][20]\t Batch [200][550]\t Training Loss 0.0634\t Accuracy 0.9827\n",
      "Epoch [10][20]\t Batch [250][550]\t Training Loss 0.0631\t Accuracy 0.9828\n",
      "Epoch [10][20]\t Batch [300][550]\t Training Loss 0.0641\t Accuracy 0.9828\n",
      "Epoch [10][20]\t Batch [350][550]\t Training Loss 0.0641\t Accuracy 0.9829\n",
      "Epoch [10][20]\t Batch [400][550]\t Training Loss 0.0644\t Accuracy 0.9829\n",
      "Epoch [10][20]\t Batch [450][550]\t Training Loss 0.0648\t Accuracy 0.9829\n",
      "Epoch [10][20]\t Batch [500][550]\t Training Loss 0.0659\t Accuracy 0.9825\n",
      "\n",
      "Epoch [10]\t Average training loss 0.0658\t Average training accuracy 0.9823\n",
      "Epoch [10]\t Average validation loss 0.0808\t Average validation accuracy 0.9774\n",
      "\n",
      "Epoch [11][20]\t Batch [0][550]\t Training Loss 0.0541\t Accuracy 0.9800\n",
      "Epoch [11][20]\t Batch [50][550]\t Training Loss 0.0568\t Accuracy 0.9857\n",
      "Epoch [11][20]\t Batch [100][550]\t Training Loss 0.0588\t Accuracy 0.9848\n",
      "Epoch [11][20]\t Batch [150][550]\t Training Loss 0.0582\t Accuracy 0.9844\n",
      "Epoch [11][20]\t Batch [200][550]\t Training Loss 0.0584\t Accuracy 0.9841\n",
      "Epoch [11][20]\t Batch [250][550]\t Training Loss 0.0581\t Accuracy 0.9842\n",
      "Epoch [11][20]\t Batch [300][550]\t Training Loss 0.0591\t Accuracy 0.9843\n",
      "Epoch [11][20]\t Batch [350][550]\t Training Loss 0.0592\t Accuracy 0.9844\n",
      "Epoch [11][20]\t Batch [400][550]\t Training Loss 0.0594\t Accuracy 0.9843\n",
      "Epoch [11][20]\t Batch [450][550]\t Training Loss 0.0599\t Accuracy 0.9842\n",
      "Epoch [11][20]\t Batch [500][550]\t Training Loss 0.0609\t Accuracy 0.9838\n",
      "\n",
      "Epoch [11]\t Average training loss 0.0608\t Average training accuracy 0.9838\n",
      "Epoch [11]\t Average validation loss 0.0791\t Average validation accuracy 0.9780\n",
      "\n",
      "Epoch [12][20]\t Batch [0][550]\t Training Loss 0.0501\t Accuracy 0.9800\n",
      "Epoch [12][20]\t Batch [50][550]\t Training Loss 0.0530\t Accuracy 0.9863\n",
      "Epoch [12][20]\t Batch [100][550]\t Training Loss 0.0548\t Accuracy 0.9856\n",
      "Epoch [12][20]\t Batch [150][550]\t Training Loss 0.0539\t Accuracy 0.9854\n",
      "Epoch [12][20]\t Batch [200][550]\t Training Loss 0.0542\t Accuracy 0.9850\n",
      "Epoch [12][20]\t Batch [250][550]\t Training Loss 0.0538\t Accuracy 0.9851\n",
      "Epoch [12][20]\t Batch [300][550]\t Training Loss 0.0548\t Accuracy 0.9853\n",
      "Epoch [12][20]\t Batch [350][550]\t Training Loss 0.0548\t Accuracy 0.9852\n",
      "Epoch [12][20]\t Batch [400][550]\t Training Loss 0.0551\t Accuracy 0.9851\n",
      "Epoch [12][20]\t Batch [450][550]\t Training Loss 0.0555\t Accuracy 0.9851\n",
      "Epoch [12][20]\t Batch [500][550]\t Training Loss 0.0564\t Accuracy 0.9849\n",
      "\n",
      "Epoch [12]\t Average training loss 0.0563\t Average training accuracy 0.9848\n",
      "Epoch [12]\t Average validation loss 0.0777\t Average validation accuracy 0.9784\n",
      "\n",
      "Epoch [13][20]\t Batch [0][550]\t Training Loss 0.0472\t Accuracy 0.9800\n",
      "Epoch [13][20]\t Batch [50][550]\t Training Loss 0.0496\t Accuracy 0.9869\n",
      "Epoch [13][20]\t Batch [100][550]\t Training Loss 0.0511\t Accuracy 0.9868\n",
      "Epoch [13][20]\t Batch [150][550]\t Training Loss 0.0501\t Accuracy 0.9865\n",
      "Epoch [13][20]\t Batch [200][550]\t Training Loss 0.0503\t Accuracy 0.9860\n",
      "Epoch [13][20]\t Batch [250][550]\t Training Loss 0.0500\t Accuracy 0.9860\n",
      "Epoch [13][20]\t Batch [300][550]\t Training Loss 0.0510\t Accuracy 0.9862\n",
      "Epoch [13][20]\t Batch [350][550]\t Training Loss 0.0510\t Accuracy 0.9862\n",
      "Epoch [13][20]\t Batch [400][550]\t Training Loss 0.0513\t Accuracy 0.9862\n",
      "Epoch [13][20]\t Batch [450][550]\t Training Loss 0.0517\t Accuracy 0.9862\n",
      "Epoch [13][20]\t Batch [500][550]\t Training Loss 0.0525\t Accuracy 0.9859\n",
      "\n",
      "Epoch [13]\t Average training loss 0.0524\t Average training accuracy 0.9859\n",
      "Epoch [13]\t Average validation loss 0.0765\t Average validation accuracy 0.9786\n",
      "\n",
      "Epoch [14][20]\t Batch [0][550]\t Training Loss 0.0443\t Accuracy 0.9800\n",
      "Epoch [14][20]\t Batch [50][550]\t Training Loss 0.0465\t Accuracy 0.9878\n",
      "Epoch [14][20]\t Batch [100][550]\t Training Loss 0.0478\t Accuracy 0.9874\n",
      "Epoch [14][20]\t Batch [150][550]\t Training Loss 0.0466\t Accuracy 0.9876\n",
      "Epoch [14][20]\t Batch [200][550]\t Training Loss 0.0468\t Accuracy 0.9870\n",
      "Epoch [14][20]\t Batch [250][550]\t Training Loss 0.0465\t Accuracy 0.9871\n",
      "Epoch [14][20]\t Batch [300][550]\t Training Loss 0.0475\t Accuracy 0.9872\n",
      "Epoch [14][20]\t Batch [350][550]\t Training Loss 0.0475\t Accuracy 0.9871\n",
      "Epoch [14][20]\t Batch [400][550]\t Training Loss 0.0478\t Accuracy 0.9871\n",
      "Epoch [14][20]\t Batch [450][550]\t Training Loss 0.0482\t Accuracy 0.9871\n",
      "Epoch [14][20]\t Batch [500][550]\t Training Loss 0.0489\t Accuracy 0.9869\n",
      "\n",
      "Epoch [14]\t Average training loss 0.0488\t Average training accuracy 0.9869\n",
      "Epoch [14]\t Average validation loss 0.0756\t Average validation accuracy 0.9782\n",
      "\n",
      "Epoch [15][20]\t Batch [0][550]\t Training Loss 0.0419\t Accuracy 0.9800\n",
      "Epoch [15][20]\t Batch [50][550]\t Training Loss 0.0437\t Accuracy 0.9892\n",
      "Epoch [15][20]\t Batch [100][550]\t Training Loss 0.0448\t Accuracy 0.9886\n",
      "Epoch [15][20]\t Batch [150][550]\t Training Loss 0.0435\t Accuracy 0.9885\n",
      "Epoch [15][20]\t Batch [200][550]\t Training Loss 0.0437\t Accuracy 0.9881\n",
      "Epoch [15][20]\t Batch [250][550]\t Training Loss 0.0434\t Accuracy 0.9882\n",
      "Epoch [15][20]\t Batch [300][550]\t Training Loss 0.0444\t Accuracy 0.9882\n",
      "Epoch [15][20]\t Batch [350][550]\t Training Loss 0.0443\t Accuracy 0.9881\n",
      "Epoch [15][20]\t Batch [400][550]\t Training Loss 0.0446\t Accuracy 0.9882\n",
      "Epoch [15][20]\t Batch [450][550]\t Training Loss 0.0450\t Accuracy 0.9882\n",
      "Epoch [15][20]\t Batch [500][550]\t Training Loss 0.0456\t Accuracy 0.9880\n",
      "\n",
      "Epoch [15]\t Average training loss 0.0455\t Average training accuracy 0.9880\n",
      "Epoch [15]\t Average validation loss 0.0749\t Average validation accuracy 0.9782\n",
      "\n",
      "Epoch [16][20]\t Batch [0][550]\t Training Loss 0.0401\t Accuracy 0.9800\n",
      "Epoch [16][20]\t Batch [50][550]\t Training Loss 0.0411\t Accuracy 0.9904\n",
      "Epoch [16][20]\t Batch [100][550]\t Training Loss 0.0420\t Accuracy 0.9896\n",
      "Epoch [16][20]\t Batch [150][550]\t Training Loss 0.0407\t Accuracy 0.9895\n",
      "Epoch [16][20]\t Batch [200][550]\t Training Loss 0.0408\t Accuracy 0.9892\n",
      "Epoch [16][20]\t Batch [250][550]\t Training Loss 0.0405\t Accuracy 0.9895\n",
      "Epoch [16][20]\t Batch [300][550]\t Training Loss 0.0415\t Accuracy 0.9896\n",
      "Epoch [16][20]\t Batch [350][550]\t Training Loss 0.0415\t Accuracy 0.9895\n",
      "Epoch [16][20]\t Batch [400][550]\t Training Loss 0.0418\t Accuracy 0.9894\n",
      "Epoch [16][20]\t Batch [450][550]\t Training Loss 0.0421\t Accuracy 0.9893\n",
      "Epoch [16][20]\t Batch [500][550]\t Training Loss 0.0427\t Accuracy 0.9891\n",
      "\n",
      "Epoch [16]\t Average training loss 0.0426\t Average training accuracy 0.9891\n",
      "Epoch [16]\t Average validation loss 0.0742\t Average validation accuracy 0.9784\n",
      "\n",
      "Epoch [17][20]\t Batch [0][550]\t Training Loss 0.0382\t Accuracy 0.9900\n",
      "Epoch [17][20]\t Batch [50][550]\t Training Loss 0.0388\t Accuracy 0.9906\n",
      "Epoch [17][20]\t Batch [100][550]\t Training Loss 0.0396\t Accuracy 0.9904\n",
      "Epoch [17][20]\t Batch [150][550]\t Training Loss 0.0381\t Accuracy 0.9907\n",
      "Epoch [17][20]\t Batch [200][550]\t Training Loss 0.0383\t Accuracy 0.9901\n",
      "Epoch [17][20]\t Batch [250][550]\t Training Loss 0.0380\t Accuracy 0.9904\n",
      "Epoch [17][20]\t Batch [300][550]\t Training Loss 0.0389\t Accuracy 0.9905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17][20]\t Batch [350][550]\t Training Loss 0.0389\t Accuracy 0.9905\n",
      "Epoch [17][20]\t Batch [400][550]\t Training Loss 0.0392\t Accuracy 0.9904\n",
      "Epoch [17][20]\t Batch [450][550]\t Training Loss 0.0395\t Accuracy 0.9902\n",
      "Epoch [17][20]\t Batch [500][550]\t Training Loss 0.0401\t Accuracy 0.9900\n",
      "\n",
      "Epoch [17]\t Average training loss 0.0399\t Average training accuracy 0.9900\n",
      "Epoch [17]\t Average validation loss 0.0738\t Average validation accuracy 0.9788\n",
      "\n",
      "Epoch [18][20]\t Batch [0][550]\t Training Loss 0.0362\t Accuracy 0.9900\n",
      "Epoch [18][20]\t Batch [50][550]\t Training Loss 0.0367\t Accuracy 0.9910\n",
      "Epoch [18][20]\t Batch [100][550]\t Training Loss 0.0373\t Accuracy 0.9911\n",
      "Epoch [18][20]\t Batch [150][550]\t Training Loss 0.0358\t Accuracy 0.9915\n",
      "Epoch [18][20]\t Batch [200][550]\t Training Loss 0.0359\t Accuracy 0.9910\n",
      "Epoch [18][20]\t Batch [250][550]\t Training Loss 0.0356\t Accuracy 0.9914\n",
      "Epoch [18][20]\t Batch [300][550]\t Training Loss 0.0366\t Accuracy 0.9914\n",
      "Epoch [18][20]\t Batch [350][550]\t Training Loss 0.0365\t Accuracy 0.9915\n",
      "Epoch [18][20]\t Batch [400][550]\t Training Loss 0.0369\t Accuracy 0.9914\n",
      "Epoch [18][20]\t Batch [450][550]\t Training Loss 0.0371\t Accuracy 0.9912\n",
      "Epoch [18][20]\t Batch [500][550]\t Training Loss 0.0376\t Accuracy 0.9910\n",
      "\n",
      "Epoch [18]\t Average training loss 0.0375\t Average training accuracy 0.9909\n",
      "Epoch [18]\t Average validation loss 0.0734\t Average validation accuracy 0.9790\n",
      "\n",
      "Epoch [19][20]\t Batch [0][550]\t Training Loss 0.0349\t Accuracy 0.9900\n",
      "Epoch [19][20]\t Batch [50][550]\t Training Loss 0.0347\t Accuracy 0.9918\n",
      "Epoch [19][20]\t Batch [100][550]\t Training Loss 0.0352\t Accuracy 0.9916\n",
      "Epoch [19][20]\t Batch [150][550]\t Training Loss 0.0337\t Accuracy 0.9919\n",
      "Epoch [19][20]\t Batch [200][550]\t Training Loss 0.0338\t Accuracy 0.9917\n",
      "Epoch [19][20]\t Batch [250][550]\t Training Loss 0.0335\t Accuracy 0.9922\n",
      "Epoch [19][20]\t Batch [300][550]\t Training Loss 0.0344\t Accuracy 0.9921\n",
      "Epoch [19][20]\t Batch [350][550]\t Training Loss 0.0344\t Accuracy 0.9921\n",
      "Epoch [19][20]\t Batch [400][550]\t Training Loss 0.0347\t Accuracy 0.9920\n",
      "Epoch [19][20]\t Batch [450][550]\t Training Loss 0.0350\t Accuracy 0.9918\n",
      "Epoch [19][20]\t Batch [500][550]\t Training Loss 0.0354\t Accuracy 0.9916\n",
      "\n",
      "Epoch [19]\t Average training loss 0.0352\t Average training accuracy 0.9916\n",
      "Epoch [19]\t Average validation loss 0.0731\t Average validation accuracy 0.9792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reluMLP, relu_loss, relu_acc = train(reluMLP, criterion, sgd, data_train, max_epoch, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "The test accuracy is 0.9760.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(reluMLP, criterion, data_test, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 绘制曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_and_acc({'Sigmoid': [sigmoid_loss, sigmoid_acc],\n",
    "                   'relu': [relu_loss, relu_acc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 具有两层隐含层的多层感知机\n",
    "\n",
    "接下来，根据案例要求，还需要完成**构造具有两个隐含层的多层感知机，自行选取合适的激活函数和损失函数，与只有一个隐含层的结果相比较**.\n",
    "\n",
    "注意: 请在下方插入新的代码块，不要直接修改上面的代码."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "twoLayerMLP = Network()\n",
    "twoLayerMLP.add(FCLayer(784, 128))\n",
    "twoLayerMLP.add(ReLULayer())\n",
    "twoLayerMLP.add(FCLayer(128, 64))\n",
    "twoLayerMLP.add(ReLULayer())\n",
    "twoLayerMLP.add(FCLayer(64, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][20]\t Batch [0][550]\t Training Loss 2.7464\t Accuracy 0.0800\n",
      "Epoch [0][20]\t Batch [50][550]\t Training Loss 0.9401\t Accuracy 0.7318\n",
      "Epoch [0][20]\t Batch [100][550]\t Training Loss 0.6946\t Accuracy 0.7993\n",
      "Epoch [0][20]\t Batch [150][550]\t Training Loss 0.5939\t Accuracy 0.8270\n",
      "Epoch [0][20]\t Batch [200][550]\t Training Loss 0.5260\t Accuracy 0.8469\n",
      "Epoch [0][20]\t Batch [250][550]\t Training Loss 0.4790\t Accuracy 0.8607\n",
      "Epoch [0][20]\t Batch [300][550]\t Training Loss 0.4458\t Accuracy 0.8703\n",
      "Epoch [0][20]\t Batch [350][550]\t Training Loss 0.4198\t Accuracy 0.8775\n",
      "Epoch [0][20]\t Batch [400][550]\t Training Loss 0.3983\t Accuracy 0.8835\n",
      "Epoch [0][20]\t Batch [450][550]\t Training Loss 0.3799\t Accuracy 0.8890\n",
      "Epoch [0][20]\t Batch [500][550]\t Training Loss 0.3669\t Accuracy 0.8924\n",
      "\n",
      "Epoch [0]\t Average training loss 0.3542\t Average training accuracy 0.8964\n",
      "Epoch [0]\t Average validation loss 0.1739\t Average validation accuracy 0.9532\n",
      "\n",
      "Epoch [1][20]\t Batch [0][550]\t Training Loss 0.2057\t Accuracy 0.9600\n",
      "Epoch [1][20]\t Batch [50][550]\t Training Loss 0.1771\t Accuracy 0.9516\n",
      "Epoch [1][20]\t Batch [100][550]\t Training Loss 0.1855\t Accuracy 0.9471\n",
      "Epoch [1][20]\t Batch [150][550]\t Training Loss 0.1919\t Accuracy 0.9448\n",
      "Epoch [1][20]\t Batch [200][550]\t Training Loss 0.1863\t Accuracy 0.9464\n",
      "Epoch [1][20]\t Batch [250][550]\t Training Loss 0.1821\t Accuracy 0.9478\n",
      "Epoch [1][20]\t Batch [300][550]\t Training Loss 0.1798\t Accuracy 0.9485\n",
      "Epoch [1][20]\t Batch [350][550]\t Training Loss 0.1772\t Accuracy 0.9487\n",
      "Epoch [1][20]\t Batch [400][550]\t Training Loss 0.1749\t Accuracy 0.9494\n",
      "Epoch [1][20]\t Batch [450][550]\t Training Loss 0.1727\t Accuracy 0.9504\n",
      "Epoch [1][20]\t Batch [500][550]\t Training Loss 0.1732\t Accuracy 0.9500\n",
      "\n",
      "Epoch [1]\t Average training loss 0.1716\t Average training accuracy 0.9506\n",
      "Epoch [1]\t Average validation loss 0.1334\t Average validation accuracy 0.9636\n",
      "\n",
      "Epoch [2][20]\t Batch [0][550]\t Training Loss 0.1381\t Accuracy 0.9700\n",
      "Epoch [2][20]\t Batch [50][550]\t Training Loss 0.1217\t Accuracy 0.9673\n",
      "Epoch [2][20]\t Batch [100][550]\t Training Loss 0.1292\t Accuracy 0.9634\n",
      "Epoch [2][20]\t Batch [150][550]\t Training Loss 0.1338\t Accuracy 0.9623\n",
      "Epoch [2][20]\t Batch [200][550]\t Training Loss 0.1312\t Accuracy 0.9632\n",
      "Epoch [2][20]\t Batch [250][550]\t Training Loss 0.1287\t Accuracy 0.9639\n",
      "Epoch [2][20]\t Batch [300][550]\t Training Loss 0.1276\t Accuracy 0.9644\n",
      "Epoch [2][20]\t Batch [350][550]\t Training Loss 0.1263\t Accuracy 0.9643\n",
      "Epoch [2][20]\t Batch [400][550]\t Training Loss 0.1253\t Accuracy 0.9646\n",
      "Epoch [2][20]\t Batch [450][550]\t Training Loss 0.1245\t Accuracy 0.9649\n",
      "Epoch [2][20]\t Batch [500][550]\t Training Loss 0.1261\t Accuracy 0.9642\n",
      "\n",
      "Epoch [2]\t Average training loss 0.1254\t Average training accuracy 0.9644\n",
      "Epoch [2]\t Average validation loss 0.1117\t Average validation accuracy 0.9698\n",
      "\n",
      "Epoch [3][20]\t Batch [0][550]\t Training Loss 0.0985\t Accuracy 0.9800\n",
      "Epoch [3][20]\t Batch [50][550]\t Training Loss 0.0934\t Accuracy 0.9743\n",
      "Epoch [3][20]\t Batch [100][550]\t Training Loss 0.1000\t Accuracy 0.9713\n",
      "Epoch [3][20]\t Batch [150][550]\t Training Loss 0.1024\t Accuracy 0.9709\n",
      "Epoch [3][20]\t Batch [200][550]\t Training Loss 0.1015\t Accuracy 0.9709\n",
      "Epoch [3][20]\t Batch [250][550]\t Training Loss 0.0997\t Accuracy 0.9714\n",
      "Epoch [3][20]\t Batch [300][550]\t Training Loss 0.0991\t Accuracy 0.9715\n",
      "Epoch [3][20]\t Batch [350][550]\t Training Loss 0.0983\t Accuracy 0.9717\n",
      "Epoch [3][20]\t Batch [400][550]\t Training Loss 0.0978\t Accuracy 0.9721\n",
      "Epoch [3][20]\t Batch [450][550]\t Training Loss 0.0976\t Accuracy 0.9723\n",
      "Epoch [3][20]\t Batch [500][550]\t Training Loss 0.0993\t Accuracy 0.9717\n",
      "\n",
      "Epoch [3]\t Average training loss 0.0990\t Average training accuracy 0.9718\n",
      "Epoch [3]\t Average validation loss 0.0986\t Average validation accuracy 0.9728\n",
      "\n",
      "Epoch [4][20]\t Batch [0][550]\t Training Loss 0.0752\t Accuracy 0.9900\n",
      "Epoch [4][20]\t Batch [50][550]\t Training Loss 0.0758\t Accuracy 0.9810\n",
      "Epoch [4][20]\t Batch [100][550]\t Training Loss 0.0810\t Accuracy 0.9786\n",
      "Epoch [4][20]\t Batch [150][550]\t Training Loss 0.0827\t Accuracy 0.9777\n",
      "Epoch [4][20]\t Batch [200][550]\t Training Loss 0.0822\t Accuracy 0.9776\n",
      "Epoch [4][20]\t Batch [250][550]\t Training Loss 0.0808\t Accuracy 0.9775\n",
      "Epoch [4][20]\t Batch [300][550]\t Training Loss 0.0805\t Accuracy 0.9773\n",
      "Epoch [4][20]\t Batch [350][550]\t Training Loss 0.0799\t Accuracy 0.9775\n",
      "Epoch [4][20]\t Batch [400][550]\t Training Loss 0.0796\t Accuracy 0.9777\n",
      "Epoch [4][20]\t Batch [450][550]\t Training Loss 0.0798\t Accuracy 0.9779\n",
      "Epoch [4][20]\t Batch [500][550]\t Training Loss 0.0814\t Accuracy 0.9772\n",
      "\n",
      "Epoch [4]\t Average training loss 0.0812\t Average training accuracy 0.9773\n",
      "Epoch [4]\t Average validation loss 0.0911\t Average validation accuracy 0.9752\n",
      "\n",
      "Epoch [5][20]\t Batch [0][550]\t Training Loss 0.0606\t Accuracy 0.9900\n",
      "Epoch [5][20]\t Batch [50][550]\t Training Loss 0.0636\t Accuracy 0.9845\n",
      "Epoch [5][20]\t Batch [100][550]\t Training Loss 0.0678\t Accuracy 0.9829\n",
      "Epoch [5][20]\t Batch [150][550]\t Training Loss 0.0693\t Accuracy 0.9817\n",
      "Epoch [5][20]\t Batch [200][550]\t Training Loss 0.0687\t Accuracy 0.9816\n",
      "Epoch [5][20]\t Batch [250][550]\t Training Loss 0.0675\t Accuracy 0.9818\n",
      "Epoch [5][20]\t Batch [300][550]\t Training Loss 0.0672\t Accuracy 0.9821\n",
      "Epoch [5][20]\t Batch [350][550]\t Training Loss 0.0668\t Accuracy 0.9821\n",
      "Epoch [5][20]\t Batch [400][550]\t Training Loss 0.0666\t Accuracy 0.9821\n",
      "Epoch [5][20]\t Batch [450][550]\t Training Loss 0.0669\t Accuracy 0.9820\n",
      "Epoch [5][20]\t Batch [500][550]\t Training Loss 0.0683\t Accuracy 0.9814\n",
      "\n",
      "Epoch [5]\t Average training loss 0.0681\t Average training accuracy 0.9814\n",
      "Epoch [5]\t Average validation loss 0.0867\t Average validation accuracy 0.9756\n",
      "\n",
      "Epoch [6][20]\t Batch [0][550]\t Training Loss 0.0489\t Accuracy 0.9900\n",
      "Epoch [6][20]\t Batch [50][550]\t Training Loss 0.0548\t Accuracy 0.9861\n",
      "Epoch [6][20]\t Batch [100][550]\t Training Loss 0.0580\t Accuracy 0.9858\n",
      "Epoch [6][20]\t Batch [150][550]\t Training Loss 0.0590\t Accuracy 0.9852\n",
      "Epoch [6][20]\t Batch [200][550]\t Training Loss 0.0583\t Accuracy 0.9850\n",
      "Epoch [6][20]\t Batch [250][550]\t Training Loss 0.0570\t Accuracy 0.9850\n",
      "Epoch [6][20]\t Batch [300][550]\t Training Loss 0.0568\t Accuracy 0.9854\n",
      "Epoch [6][20]\t Batch [350][550]\t Training Loss 0.0565\t Accuracy 0.9854\n",
      "Epoch [6][20]\t Batch [400][550]\t Training Loss 0.0564\t Accuracy 0.9853\n",
      "Epoch [6][20]\t Batch [450][550]\t Training Loss 0.0568\t Accuracy 0.9852\n",
      "Epoch [6][20]\t Batch [500][550]\t Training Loss 0.0580\t Accuracy 0.9846\n",
      "\n",
      "Epoch [6]\t Average training loss 0.0578\t Average training accuracy 0.9845\n",
      "Epoch [6]\t Average validation loss 0.0842\t Average validation accuracy 0.9754\n",
      "\n",
      "Epoch [7][20]\t Batch [0][550]\t Training Loss 0.0378\t Accuracy 0.9900\n",
      "Epoch [7][20]\t Batch [50][550]\t Training Loss 0.0475\t Accuracy 0.9876\n",
      "Epoch [7][20]\t Batch [100][550]\t Training Loss 0.0502\t Accuracy 0.9874\n",
      "Epoch [7][20]\t Batch [150][550]\t Training Loss 0.0505\t Accuracy 0.9872\n",
      "Epoch [7][20]\t Batch [200][550]\t Training Loss 0.0498\t Accuracy 0.9874\n",
      "Epoch [7][20]\t Batch [250][550]\t Training Loss 0.0485\t Accuracy 0.9875\n",
      "Epoch [7][20]\t Batch [300][550]\t Training Loss 0.0484\t Accuracy 0.9879\n",
      "Epoch [7][20]\t Batch [350][550]\t Training Loss 0.0483\t Accuracy 0.9877\n",
      "Epoch [7][20]\t Batch [400][550]\t Training Loss 0.0483\t Accuracy 0.9876\n",
      "Epoch [7][20]\t Batch [450][550]\t Training Loss 0.0486\t Accuracy 0.9875\n",
      "Epoch [7][20]\t Batch [500][550]\t Training Loss 0.0496\t Accuracy 0.9871\n",
      "\n",
      "Epoch [7]\t Average training loss 0.0494\t Average training accuracy 0.9871\n",
      "Epoch [7]\t Average validation loss 0.0826\t Average validation accuracy 0.9758\n",
      "\n",
      "Epoch [8][20]\t Batch [0][550]\t Training Loss 0.0304\t Accuracy 0.9900\n",
      "Epoch [8][20]\t Batch [50][550]\t Training Loss 0.0416\t Accuracy 0.9898\n",
      "Epoch [8][20]\t Batch [100][550]\t Training Loss 0.0438\t Accuracy 0.9897\n",
      "Epoch [8][20]\t Batch [150][550]\t Training Loss 0.0437\t Accuracy 0.9894\n",
      "Epoch [8][20]\t Batch [200][550]\t Training Loss 0.0429\t Accuracy 0.9896\n",
      "Epoch [8][20]\t Batch [250][550]\t Training Loss 0.0416\t Accuracy 0.9895\n",
      "Epoch [8][20]\t Batch [300][550]\t Training Loss 0.0415\t Accuracy 0.9898\n",
      "Epoch [8][20]\t Batch [350][550]\t Training Loss 0.0414\t Accuracy 0.9897\n",
      "Epoch [8][20]\t Batch [400][550]\t Training Loss 0.0415\t Accuracy 0.9896\n",
      "Epoch [8][20]\t Batch [450][550]\t Training Loss 0.0418\t Accuracy 0.9894\n",
      "Epoch [8][20]\t Batch [500][550]\t Training Loss 0.0426\t Accuracy 0.9892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8]\t Average training loss 0.0424\t Average training accuracy 0.9893\n",
      "Epoch [8]\t Average validation loss 0.0819\t Average validation accuracy 0.9770\n",
      "\n",
      "Epoch [9][20]\t Batch [0][550]\t Training Loss 0.0250\t Accuracy 0.9900\n",
      "Epoch [9][20]\t Batch [50][550]\t Training Loss 0.0366\t Accuracy 0.9912\n",
      "Epoch [9][20]\t Batch [100][550]\t Training Loss 0.0384\t Accuracy 0.9909\n",
      "Epoch [9][20]\t Batch [150][550]\t Training Loss 0.0377\t Accuracy 0.9907\n",
      "Epoch [9][20]\t Batch [200][550]\t Training Loss 0.0369\t Accuracy 0.9909\n",
      "Epoch [9][20]\t Batch [250][550]\t Training Loss 0.0357\t Accuracy 0.9910\n",
      "Epoch [9][20]\t Batch [300][550]\t Training Loss 0.0357\t Accuracy 0.9913\n",
      "Epoch [9][20]\t Batch [350][550]\t Training Loss 0.0358\t Accuracy 0.9913\n",
      "Epoch [9][20]\t Batch [400][550]\t Training Loss 0.0359\t Accuracy 0.9913\n",
      "Epoch [9][20]\t Batch [450][550]\t Training Loss 0.0361\t Accuracy 0.9913\n",
      "Epoch [9][20]\t Batch [500][550]\t Training Loss 0.0368\t Accuracy 0.9912\n",
      "\n",
      "Epoch [9]\t Average training loss 0.0366\t Average training accuracy 0.9912\n",
      "Epoch [9]\t Average validation loss 0.0816\t Average validation accuracy 0.9772\n",
      "\n",
      "Epoch [10][20]\t Batch [0][550]\t Training Loss 0.0210\t Accuracy 0.9900\n",
      "Epoch [10][20]\t Batch [50][550]\t Training Loss 0.0323\t Accuracy 0.9924\n",
      "Epoch [10][20]\t Batch [100][550]\t Training Loss 0.0340\t Accuracy 0.9921\n",
      "Epoch [10][20]\t Batch [150][550]\t Training Loss 0.0327\t Accuracy 0.9922\n",
      "Epoch [10][20]\t Batch [200][550]\t Training Loss 0.0318\t Accuracy 0.9925\n",
      "Epoch [10][20]\t Batch [250][550]\t Training Loss 0.0307\t Accuracy 0.9927\n",
      "Epoch [10][20]\t Batch [300][550]\t Training Loss 0.0307\t Accuracy 0.9927\n",
      "Epoch [10][20]\t Batch [350][550]\t Training Loss 0.0308\t Accuracy 0.9928\n",
      "Epoch [10][20]\t Batch [400][550]\t Training Loss 0.0311\t Accuracy 0.9928\n",
      "Epoch [10][20]\t Batch [450][550]\t Training Loss 0.0312\t Accuracy 0.9928\n",
      "Epoch [10][20]\t Batch [500][550]\t Training Loss 0.0318\t Accuracy 0.9927\n",
      "\n",
      "Epoch [10]\t Average training loss 0.0315\t Average training accuracy 0.9926\n",
      "Epoch [10]\t Average validation loss 0.0813\t Average validation accuracy 0.9782\n",
      "\n",
      "Epoch [11][20]\t Batch [0][550]\t Training Loss 0.0186\t Accuracy 0.9900\n",
      "Epoch [11][20]\t Batch [50][550]\t Training Loss 0.0283\t Accuracy 0.9937\n",
      "Epoch [11][20]\t Batch [100][550]\t Training Loss 0.0299\t Accuracy 0.9933\n",
      "Epoch [11][20]\t Batch [150][550]\t Training Loss 0.0283\t Accuracy 0.9938\n",
      "Epoch [11][20]\t Batch [200][550]\t Training Loss 0.0274\t Accuracy 0.9940\n",
      "Epoch [11][20]\t Batch [250][550]\t Training Loss 0.0264\t Accuracy 0.9941\n",
      "Epoch [11][20]\t Batch [300][550]\t Training Loss 0.0264\t Accuracy 0.9941\n",
      "Epoch [11][20]\t Batch [350][550]\t Training Loss 0.0266\t Accuracy 0.9941\n",
      "Epoch [11][20]\t Batch [400][550]\t Training Loss 0.0268\t Accuracy 0.9941\n",
      "Epoch [11][20]\t Batch [450][550]\t Training Loss 0.0269\t Accuracy 0.9941\n",
      "Epoch [11][20]\t Batch [500][550]\t Training Loss 0.0273\t Accuracy 0.9941\n",
      "\n",
      "Epoch [11]\t Average training loss 0.0271\t Average training accuracy 0.9941\n",
      "Epoch [11]\t Average validation loss 0.0811\t Average validation accuracy 0.9794\n",
      "\n",
      "Epoch [12][20]\t Batch [0][550]\t Training Loss 0.0162\t Accuracy 0.9900\n",
      "Epoch [12][20]\t Batch [50][550]\t Training Loss 0.0248\t Accuracy 0.9943\n",
      "Epoch [12][20]\t Batch [100][550]\t Training Loss 0.0261\t Accuracy 0.9942\n",
      "Epoch [12][20]\t Batch [150][550]\t Training Loss 0.0244\t Accuracy 0.9949\n",
      "Epoch [12][20]\t Batch [200][550]\t Training Loss 0.0236\t Accuracy 0.9950\n",
      "Epoch [12][20]\t Batch [250][550]\t Training Loss 0.0227\t Accuracy 0.9953\n",
      "Epoch [12][20]\t Batch [300][550]\t Training Loss 0.0227\t Accuracy 0.9952\n",
      "Epoch [12][20]\t Batch [350][550]\t Training Loss 0.0229\t Accuracy 0.9952\n",
      "Epoch [12][20]\t Batch [400][550]\t Training Loss 0.0231\t Accuracy 0.9952\n",
      "Epoch [12][20]\t Batch [450][550]\t Training Loss 0.0231\t Accuracy 0.9952\n",
      "Epoch [12][20]\t Batch [500][550]\t Training Loss 0.0235\t Accuracy 0.9952\n",
      "\n",
      "Epoch [12]\t Average training loss 0.0233\t Average training accuracy 0.9952\n",
      "Epoch [12]\t Average validation loss 0.0812\t Average validation accuracy 0.9784\n",
      "\n",
      "Epoch [13][20]\t Batch [0][550]\t Training Loss 0.0137\t Accuracy 1.0000\n",
      "Epoch [13][20]\t Batch [50][550]\t Training Loss 0.0215\t Accuracy 0.9951\n",
      "Epoch [13][20]\t Batch [100][550]\t Training Loss 0.0228\t Accuracy 0.9951\n",
      "Epoch [13][20]\t Batch [150][550]\t Training Loss 0.0210\t Accuracy 0.9957\n",
      "Epoch [13][20]\t Batch [200][550]\t Training Loss 0.0204\t Accuracy 0.9957\n",
      "Epoch [13][20]\t Batch [250][550]\t Training Loss 0.0195\t Accuracy 0.9961\n",
      "Epoch [13][20]\t Batch [300][550]\t Training Loss 0.0195\t Accuracy 0.9960\n",
      "Epoch [13][20]\t Batch [350][550]\t Training Loss 0.0197\t Accuracy 0.9960\n",
      "Epoch [13][20]\t Batch [400][550]\t Training Loss 0.0200\t Accuracy 0.9961\n",
      "Epoch [13][20]\t Batch [450][550]\t Training Loss 0.0199\t Accuracy 0.9960\n",
      "Epoch [13][20]\t Batch [500][550]\t Training Loss 0.0202\t Accuracy 0.9960\n",
      "\n",
      "Epoch [13]\t Average training loss 0.0200\t Average training accuracy 0.9960\n",
      "Epoch [13]\t Average validation loss 0.0814\t Average validation accuracy 0.9796\n",
      "\n",
      "Epoch [14][20]\t Batch [0][550]\t Training Loss 0.0106\t Accuracy 1.0000\n",
      "Epoch [14][20]\t Batch [50][550]\t Training Loss 0.0188\t Accuracy 0.9961\n",
      "Epoch [14][20]\t Batch [100][550]\t Training Loss 0.0199\t Accuracy 0.9962\n",
      "Epoch [14][20]\t Batch [150][550]\t Training Loss 0.0182\t Accuracy 0.9966\n",
      "Epoch [14][20]\t Batch [200][550]\t Training Loss 0.0176\t Accuracy 0.9966\n",
      "Epoch [14][20]\t Batch [250][550]\t Training Loss 0.0169\t Accuracy 0.9968\n",
      "Epoch [14][20]\t Batch [300][550]\t Training Loss 0.0169\t Accuracy 0.9968\n",
      "Epoch [14][20]\t Batch [350][550]\t Training Loss 0.0170\t Accuracy 0.9968\n",
      "Epoch [14][20]\t Batch [400][550]\t Training Loss 0.0174\t Accuracy 0.9969\n",
      "Epoch [14][20]\t Batch [450][550]\t Training Loss 0.0172\t Accuracy 0.9969\n",
      "Epoch [14][20]\t Batch [500][550]\t Training Loss 0.0174\t Accuracy 0.9968\n",
      "\n",
      "Epoch [14]\t Average training loss 0.0172\t Average training accuracy 0.9969\n",
      "Epoch [14]\t Average validation loss 0.0819\t Average validation accuracy 0.9786\n",
      "\n",
      "Epoch [15][20]\t Batch [0][550]\t Training Loss 0.0091\t Accuracy 1.0000\n",
      "Epoch [15][20]\t Batch [50][550]\t Training Loss 0.0163\t Accuracy 0.9975\n",
      "Epoch [15][20]\t Batch [100][550]\t Training Loss 0.0173\t Accuracy 0.9971\n",
      "Epoch [15][20]\t Batch [150][550]\t Training Loss 0.0158\t Accuracy 0.9974\n",
      "Epoch [15][20]\t Batch [200][550]\t Training Loss 0.0153\t Accuracy 0.9974\n",
      "Epoch [15][20]\t Batch [250][550]\t Training Loss 0.0146\t Accuracy 0.9975\n",
      "Epoch [15][20]\t Batch [300][550]\t Training Loss 0.0146\t Accuracy 0.9974\n",
      "Epoch [15][20]\t Batch [350][550]\t Training Loss 0.0147\t Accuracy 0.9975\n",
      "Epoch [15][20]\t Batch [400][550]\t Training Loss 0.0150\t Accuracy 0.9975\n",
      "Epoch [15][20]\t Batch [450][550]\t Training Loss 0.0148\t Accuracy 0.9975\n",
      "Epoch [15][20]\t Batch [500][550]\t Training Loss 0.0150\t Accuracy 0.9974\n",
      "\n",
      "Epoch [15]\t Average training loss 0.0149\t Average training accuracy 0.9975\n",
      "Epoch [15]\t Average validation loss 0.0829\t Average validation accuracy 0.9792\n",
      "\n",
      "Epoch [16][20]\t Batch [0][550]\t Training Loss 0.0075\t Accuracy 1.0000\n",
      "Epoch [16][20]\t Batch [50][550]\t Training Loss 0.0140\t Accuracy 0.9976\n",
      "Epoch [16][20]\t Batch [100][550]\t Training Loss 0.0150\t Accuracy 0.9973\n",
      "Epoch [16][20]\t Batch [150][550]\t Training Loss 0.0137\t Accuracy 0.9978\n",
      "Epoch [16][20]\t Batch [200][550]\t Training Loss 0.0133\t Accuracy 0.9979\n",
      "Epoch [16][20]\t Batch [250][550]\t Training Loss 0.0127\t Accuracy 0.9980\n",
      "Epoch [16][20]\t Batch [300][550]\t Training Loss 0.0127\t Accuracy 0.9980\n",
      "Epoch [16][20]\t Batch [350][550]\t Training Loss 0.0127\t Accuracy 0.9981\n",
      "Epoch [16][20]\t Batch [400][550]\t Training Loss 0.0131\t Accuracy 0.9981\n",
      "Epoch [16][20]\t Batch [450][550]\t Training Loss 0.0129\t Accuracy 0.9981\n",
      "Epoch [16][20]\t Batch [500][550]\t Training Loss 0.0130\t Accuracy 0.9980\n",
      "\n",
      "Epoch [16]\t Average training loss 0.0128\t Average training accuracy 0.9981\n",
      "Epoch [16]\t Average validation loss 0.0832\t Average validation accuracy 0.9790\n",
      "\n",
      "Epoch [17][20]\t Batch [0][550]\t Training Loss 0.0062\t Accuracy 1.0000\n",
      "Epoch [17][20]\t Batch [50][550]\t Training Loss 0.0122\t Accuracy 0.9980\n",
      "Epoch [17][20]\t Batch [100][550]\t Training Loss 0.0131\t Accuracy 0.9980\n",
      "Epoch [17][20]\t Batch [150][550]\t Training Loss 0.0119\t Accuracy 0.9985\n",
      "Epoch [17][20]\t Batch [200][550]\t Training Loss 0.0115\t Accuracy 0.9985\n",
      "Epoch [17][20]\t Batch [250][550]\t Training Loss 0.0110\t Accuracy 0.9986\n",
      "Epoch [17][20]\t Batch [300][550]\t Training Loss 0.0110\t Accuracy 0.9986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17][20]\t Batch [350][550]\t Training Loss 0.0111\t Accuracy 0.9986\n",
      "Epoch [17][20]\t Batch [400][550]\t Training Loss 0.0114\t Accuracy 0.9986\n",
      "Epoch [17][20]\t Batch [450][550]\t Training Loss 0.0112\t Accuracy 0.9986\n",
      "Epoch [17][20]\t Batch [500][550]\t Training Loss 0.0113\t Accuracy 0.9985\n",
      "\n",
      "Epoch [17]\t Average training loss 0.0111\t Average training accuracy 0.9985\n",
      "Epoch [17]\t Average validation loss 0.0840\t Average validation accuracy 0.9788\n",
      "\n",
      "Epoch [18][20]\t Batch [0][550]\t Training Loss 0.0052\t Accuracy 1.0000\n",
      "Epoch [18][20]\t Batch [50][550]\t Training Loss 0.0106\t Accuracy 0.9984\n",
      "Epoch [18][20]\t Batch [100][550]\t Training Loss 0.0115\t Accuracy 0.9985\n",
      "Epoch [18][20]\t Batch [150][550]\t Training Loss 0.0104\t Accuracy 0.9989\n",
      "Epoch [18][20]\t Batch [200][550]\t Training Loss 0.0101\t Accuracy 0.9989\n",
      "Epoch [18][20]\t Batch [250][550]\t Training Loss 0.0097\t Accuracy 0.9990\n",
      "Epoch [18][20]\t Batch [300][550]\t Training Loss 0.0096\t Accuracy 0.9990\n",
      "Epoch [18][20]\t Batch [350][550]\t Training Loss 0.0097\t Accuracy 0.9990\n",
      "Epoch [18][20]\t Batch [400][550]\t Training Loss 0.0100\t Accuracy 0.9989\n",
      "Epoch [18][20]\t Batch [450][550]\t Training Loss 0.0098\t Accuracy 0.9989\n",
      "Epoch [18][20]\t Batch [500][550]\t Training Loss 0.0098\t Accuracy 0.9989\n",
      "\n",
      "Epoch [18]\t Average training loss 0.0097\t Average training accuracy 0.9989\n",
      "Epoch [18]\t Average validation loss 0.0847\t Average validation accuracy 0.9792\n",
      "\n",
      "Epoch [19][20]\t Batch [0][550]\t Training Loss 0.0046\t Accuracy 1.0000\n",
      "Epoch [19][20]\t Batch [50][550]\t Training Loss 0.0091\t Accuracy 0.9992\n",
      "Epoch [19][20]\t Batch [100][550]\t Training Loss 0.0100\t Accuracy 0.9991\n",
      "Epoch [19][20]\t Batch [150][550]\t Training Loss 0.0090\t Accuracy 0.9993\n",
      "Epoch [19][20]\t Batch [200][550]\t Training Loss 0.0088\t Accuracy 0.9993\n",
      "Epoch [19][20]\t Batch [250][550]\t Training Loss 0.0084\t Accuracy 0.9994\n",
      "Epoch [19][20]\t Batch [300][550]\t Training Loss 0.0084\t Accuracy 0.9993\n",
      "Epoch [19][20]\t Batch [350][550]\t Training Loss 0.0084\t Accuracy 0.9993\n",
      "Epoch [19][20]\t Batch [400][550]\t Training Loss 0.0087\t Accuracy 0.9992\n",
      "Epoch [19][20]\t Batch [450][550]\t Training Loss 0.0085\t Accuracy 0.9993\n",
      "Epoch [19][20]\t Batch [500][550]\t Training Loss 0.0086\t Accuracy 0.9992\n",
      "\n",
      "Epoch [19]\t Average training loss 0.0085\t Average training accuracy 0.9992\n",
      "Epoch [19]\t Average validation loss 0.0853\t Average validation accuracy 0.9790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twoLayerMLP, tl_loss, tl_acc = train(twoLayerMLP, criterion, sgd, data_train, max_epoch, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "The test accuracy is 0.9776.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(twoLayerMLP, criterion, data_test, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_and_acc({'2-layer': [tl_loss, tl_acc],\n",
    "                   'relu': [relu_loss, relu_acc],\n",
    "                   'Sigmoid': [sigmoid_loss, sigmoid_acc]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}