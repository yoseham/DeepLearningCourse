{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from solver import Solver\n",
    "from visualize import plot_loss_and_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][10]\t Batch [0][550]\t Training Loss 2.5604\t Accuracy 0.0500\n",
      "Epoch [0][10]\t Batch [50][550]\t Training Loss 2.0411\t Accuracy 0.3000\n",
      "Epoch [0][10]\t Batch [100][550]\t Training Loss 1.7327\t Accuracy 0.4600\n",
      "Epoch [0][10]\t Batch [150][550]\t Training Loss 1.4797\t Accuracy 0.6500\n",
      "Epoch [0][10]\t Batch [200][550]\t Training Loss 1.0825\t Accuracy 0.8100\n",
      "Epoch [0][10]\t Batch [250][550]\t Training Loss 1.1905\t Accuracy 0.7500\n",
      "Epoch [0][10]\t Batch [300][550]\t Training Loss 1.1380\t Accuracy 0.7000\n",
      "Epoch [0][10]\t Batch [350][550]\t Training Loss 0.9905\t Accuracy 0.7700\n",
      "Epoch [0][10]\t Batch [400][550]\t Training Loss 0.9655\t Accuracy 0.8100\n",
      "Epoch [0][10]\t Batch [450][550]\t Training Loss 0.9135\t Accuracy 0.7800\n",
      "Epoch [0][10]\t Batch [500][550]\t Training Loss 0.8292\t Accuracy 0.8200\n",
      "\n",
      "Epoch [0]\t Average training loss 1.2676\t Average training accuracy 0.6719\n",
      "Epoch [0]\t Average validation loss 0.7125\t Average validation accuracy 0.8664\n",
      "\n",
      "Epoch [1][10]\t Batch [0][550]\t Training Loss 0.8007\t Accuracy 0.8300\n",
      "Epoch [1][10]\t Batch [50][550]\t Training Loss 0.9494\t Accuracy 0.7400\n",
      "Epoch [1][10]\t Batch [100][550]\t Training Loss 0.6420\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [150][550]\t Training Loss 0.7682\t Accuracy 0.7700\n",
      "Epoch [1][10]\t Batch [200][550]\t Training Loss 0.7667\t Accuracy 0.8000\n",
      "Epoch [1][10]\t Batch [250][550]\t Training Loss 0.6813\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [300][550]\t Training Loss 0.5270\t Accuracy 0.8900\n",
      "Epoch [1][10]\t Batch [350][550]\t Training Loss 0.6820\t Accuracy 0.8200\n",
      "Epoch [1][10]\t Batch [400][550]\t Training Loss 0.7545\t Accuracy 0.7900\n",
      "Epoch [1][10]\t Batch [450][550]\t Training Loss 0.6292\t Accuracy 0.8600\n",
      "Epoch [1][10]\t Batch [500][550]\t Training Loss 0.6264\t Accuracy 0.8000\n",
      "\n",
      "Epoch [1]\t Average training loss 0.6874\t Average training accuracy 0.8392\n",
      "Epoch [1]\t Average validation loss 0.5167\t Average validation accuracy 0.8912\n",
      "\n",
      "Epoch [2][10]\t Batch [0][550]\t Training Loss 0.6740\t Accuracy 0.8200\n",
      "Epoch [2][10]\t Batch [50][550]\t Training Loss 0.7648\t Accuracy 0.7800\n",
      "Epoch [2][10]\t Batch [100][550]\t Training Loss 0.5577\t Accuracy 0.8900\n",
      "Epoch [2][10]\t Batch [150][550]\t Training Loss 0.5241\t Accuracy 0.8700\n",
      "Epoch [2][10]\t Batch [200][550]\t Training Loss 0.4929\t Accuracy 0.9300\n",
      "Epoch [2][10]\t Batch [250][550]\t Training Loss 0.5857\t Accuracy 0.8600\n",
      "Epoch [2][10]\t Batch [300][550]\t Training Loss 0.4683\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [350][550]\t Training Loss 0.6260\t Accuracy 0.8200\n",
      "Epoch [2][10]\t Batch [400][550]\t Training Loss 0.4873\t Accuracy 0.8800\n",
      "Epoch [2][10]\t Batch [450][550]\t Training Loss 0.5020\t Accuracy 0.8700\n",
      "Epoch [2][10]\t Batch [500][550]\t Training Loss 0.4896\t Accuracy 0.8900\n",
      "\n",
      "Epoch [2]\t Average training loss 0.5684\t Average training accuracy 0.8590\n",
      "Epoch [2]\t Average validation loss 0.4419\t Average validation accuracy 0.8990\n",
      "\n",
      "Epoch [3][10]\t Batch [0][550]\t Training Loss 0.5909\t Accuracy 0.8200\n",
      "Epoch [3][10]\t Batch [50][550]\t Training Loss 0.5201\t Accuracy 0.8700\n",
      "Epoch [3][10]\t Batch [100][550]\t Training Loss 0.5451\t Accuracy 0.8500\n",
      "Epoch [3][10]\t Batch [150][550]\t Training Loss 0.5681\t Accuracy 0.8200\n",
      "Epoch [3][10]\t Batch [200][550]\t Training Loss 0.5564\t Accuracy 0.8500\n",
      "Epoch [3][10]\t Batch [250][550]\t Training Loss 0.4955\t Accuracy 0.8600\n",
      "Epoch [3][10]\t Batch [300][550]\t Training Loss 0.6166\t Accuracy 0.8400\n",
      "Epoch [3][10]\t Batch [350][550]\t Training Loss 0.5198\t Accuracy 0.8400\n",
      "Epoch [3][10]\t Batch [400][550]\t Training Loss 0.4178\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [450][550]\t Training Loss 0.7179\t Accuracy 0.8300\n",
      "Epoch [3][10]\t Batch [500][550]\t Training Loss 0.5507\t Accuracy 0.8500\n",
      "\n",
      "Epoch [3]\t Average training loss 0.5121\t Average training accuracy 0.8687\n",
      "Epoch [3]\t Average validation loss 0.4016\t Average validation accuracy 0.9060\n",
      "\n",
      "Epoch [4][10]\t Batch [0][550]\t Training Loss 0.5363\t Accuracy 0.8500\n",
      "Epoch [4][10]\t Batch [50][550]\t Training Loss 0.4578\t Accuracy 0.8800\n",
      "Epoch [4][10]\t Batch [100][550]\t Training Loss 0.5933\t Accuracy 0.8500\n",
      "Epoch [4][10]\t Batch [150][550]\t Training Loss 0.3837\t Accuracy 0.8900\n",
      "Epoch [4][10]\t Batch [200][550]\t Training Loss 0.3805\t Accuracy 0.9100\n",
      "Epoch [4][10]\t Batch [250][550]\t Training Loss 0.4201\t Accuracy 0.9200\n",
      "Epoch [4][10]\t Batch [300][550]\t Training Loss 0.5005\t Accuracy 0.8900\n",
      "Epoch [4][10]\t Batch [350][550]\t Training Loss 0.4591\t Accuracy 0.8800\n",
      "Epoch [4][10]\t Batch [400][550]\t Training Loss 0.5081\t Accuracy 0.8400\n",
      "Epoch [4][10]\t Batch [450][550]\t Training Loss 0.4460\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [500][550]\t Training Loss 0.4506\t Accuracy 0.9100\n",
      "\n",
      "Epoch [4]\t Average training loss 0.4780\t Average training accuracy 0.8747\n",
      "Epoch [4]\t Average validation loss 0.3756\t Average validation accuracy 0.9086\n",
      "\n",
      "Epoch [5][10]\t Batch [0][550]\t Training Loss 0.4438\t Accuracy 0.8500\n",
      "Epoch [5][10]\t Batch [50][550]\t Training Loss 0.4364\t Accuracy 0.8600\n",
      "Epoch [5][10]\t Batch [100][550]\t Training Loss 0.4497\t Accuracy 0.8800\n",
      "Epoch [5][10]\t Batch [150][550]\t Training Loss 0.4005\t Accuracy 0.9200\n",
      "Epoch [5][10]\t Batch [200][550]\t Training Loss 0.4701\t Accuracy 0.8600\n",
      "Epoch [5][10]\t Batch [250][550]\t Training Loss 0.4156\t Accuracy 0.9100\n",
      "Epoch [5][10]\t Batch [300][550]\t Training Loss 0.5481\t Accuracy 0.8700\n",
      "Epoch [5][10]\t Batch [350][550]\t Training Loss 0.5037\t Accuracy 0.8800\n",
      "Epoch [5][10]\t Batch [400][550]\t Training Loss 0.5568\t Accuracy 0.8200\n",
      "Epoch [5][10]\t Batch [450][550]\t Training Loss 0.4680\t Accuracy 0.8700\n",
      "Epoch [5][10]\t Batch [500][550]\t Training Loss 0.4082\t Accuracy 0.8800\n",
      "\n",
      "Epoch [5]\t Average training loss 0.4546\t Average training accuracy 0.8794\n",
      "Epoch [5]\t Average validation loss 0.3575\t Average validation accuracy 0.9116\n",
      "\n",
      "Epoch [6][10]\t Batch [0][550]\t Training Loss 0.5784\t Accuracy 0.8300\n",
      "Epoch [6][10]\t Batch [50][550]\t Training Loss 0.4555\t Accuracy 0.8900\n",
      "Epoch [6][10]\t Batch [100][550]\t Training Loss 0.3430\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [150][550]\t Training Loss 0.5687\t Accuracy 0.8900\n",
      "Epoch [6][10]\t Batch [200][550]\t Training Loss 0.4078\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [250][550]\t Training Loss 0.3273\t Accuracy 0.9200\n",
      "Epoch [6][10]\t Batch [300][550]\t Training Loss 0.3988\t Accuracy 0.8700\n",
      "Epoch [6][10]\t Batch [350][550]\t Training Loss 0.3389\t Accuracy 0.9200\n",
      "Epoch [6][10]\t Batch [400][550]\t Training Loss 0.5135\t Accuracy 0.8300\n",
      "Epoch [6][10]\t Batch [450][550]\t Training Loss 0.5546\t Accuracy 0.8200\n",
      "Epoch [6][10]\t Batch [500][550]\t Training Loss 0.3097\t Accuracy 0.9700\n",
      "\n",
      "Epoch [6]\t Average training loss 0.4373\t Average training accuracy 0.8829\n",
      "Epoch [6]\t Average validation loss 0.3440\t Average validation accuracy 0.9136\n",
      "\n",
      "Epoch [7][10]\t Batch [0][550]\t Training Loss 0.5039\t Accuracy 0.8500\n",
      "Epoch [7][10]\t Batch [50][550]\t Training Loss 0.4539\t Accuracy 0.8900\n",
      "Epoch [7][10]\t Batch [100][550]\t Training Loss 0.4238\t Accuracy 0.8900\n",
      "Epoch [7][10]\t Batch [150][550]\t Training Loss 0.3956\t Accuracy 0.9200\n",
      "Epoch [7][10]\t Batch [200][550]\t Training Loss 0.3922\t Accuracy 0.8700\n",
      "Epoch [7][10]\t Batch [250][550]\t Training Loss 0.3966\t Accuracy 0.8300\n",
      "Epoch [7][10]\t Batch [300][550]\t Training Loss 0.4460\t Accuracy 0.8600\n",
      "Epoch [7][10]\t Batch [350][550]\t Training Loss 0.4577\t Accuracy 0.8500\n",
      "Epoch [7][10]\t Batch [400][550]\t Training Loss 0.4169\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [450][550]\t Training Loss 0.3681\t Accuracy 0.9300\n",
      "Epoch [7][10]\t Batch [500][550]\t Training Loss 0.5442\t Accuracy 0.8300\n",
      "\n",
      "Epoch [7]\t Average training loss 0.4237\t Average training accuracy 0.8857\n",
      "Epoch [7]\t Average validation loss 0.3336\t Average validation accuracy 0.9152\n",
      "\n",
      "Epoch [8][10]\t Batch [0][550]\t Training Loss 0.4539\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [50][550]\t Training Loss 0.4483\t Accuracy 0.8600\n",
      "Epoch [8][10]\t Batch [100][550]\t Training Loss 0.5522\t Accuracy 0.8300\n",
      "Epoch [8][10]\t Batch [150][550]\t Training Loss 0.3570\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [200][550]\t Training Loss 0.4740\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [250][550]\t Training Loss 0.3610\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [300][550]\t Training Loss 0.3383\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [350][550]\t Training Loss 0.4093\t Accuracy 0.8300\n",
      "Epoch [8][10]\t Batch [400][550]\t Training Loss 0.3731\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [450][550]\t Training Loss 0.4682\t Accuracy 0.8800\n",
      "Epoch [8][10]\t Batch [500][550]\t Training Loss 0.3067\t Accuracy 0.9100\n",
      "\n",
      "Epoch [8]\t Average training loss 0.4128\t Average training accuracy 0.8879\n",
      "Epoch [8]\t Average validation loss 0.3251\t Average validation accuracy 0.9168\n",
      "\n",
      "Epoch [9][10]\t Batch [0][550]\t Training Loss 0.3346\t Accuracy 0.9100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9][10]\t Batch [50][550]\t Training Loss 0.3598\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [100][550]\t Training Loss 0.3013\t Accuracy 0.9400\n",
      "Epoch [9][10]\t Batch [150][550]\t Training Loss 0.3768\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [200][550]\t Training Loss 0.3453\t Accuracy 0.9100\n",
      "Epoch [9][10]\t Batch [250][550]\t Training Loss 0.3652\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [300][550]\t Training Loss 0.5387\t Accuracy 0.8500\n",
      "Epoch [9][10]\t Batch [350][550]\t Training Loss 0.4102\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [400][550]\t Training Loss 0.3020\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [450][550]\t Training Loss 0.3696\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [500][550]\t Training Loss 0.3250\t Accuracy 0.9400\n",
      "\n",
      "Epoch [9]\t Average training loss 0.4038\t Average training accuracy 0.8899\n",
      "Epoch [9]\t Average validation loss 0.3178\t Average validation accuracy 0.9182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train without momentum\n",
    "cfg = {\n",
    "    'data_root': 'data',\n",
    "    'max_epoch': 10,\n",
    "    'batch_size': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'momentum': 0,\n",
    "    'display_freq': 50,\n",
    "}\n",
    "\n",
    "runner = Solver(cfg)\n",
    "loss1, acc1 = runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy 0.8997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = runner.test()\n",
    "print('Final test accuracy {:.4f}\\n'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][10]\t Batch [0][550]\t Training Loss 2.4708\t Accuracy 0.0900\n",
      "Epoch [0][10]\t Batch [50][550]\t Training Loss 0.7677\t Accuracy 0.8300\n",
      "Epoch [0][10]\t Batch [100][550]\t Training Loss 0.6853\t Accuracy 0.8400\n",
      "Epoch [0][10]\t Batch [150][550]\t Training Loss 0.5186\t Accuracy 0.8600\n",
      "Epoch [0][10]\t Batch [200][550]\t Training Loss 0.5016\t Accuracy 0.8800\n",
      "Epoch [0][10]\t Batch [250][550]\t Training Loss 0.6192\t Accuracy 0.8600\n",
      "Epoch [0][10]\t Batch [300][550]\t Training Loss 0.5146\t Accuracy 0.8300\n",
      "Epoch [0][10]\t Batch [350][550]\t Training Loss 0.4605\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [400][550]\t Training Loss 0.3588\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [450][550]\t Training Loss 0.4505\t Accuracy 0.8900\n",
      "Epoch [0][10]\t Batch [500][550]\t Training Loss 0.4504\t Accuracy 0.8800\n",
      "\n",
      "Epoch [0]\t Average training loss 0.5845\t Average training accuracy 0.8403\n",
      "Epoch [0]\t Average validation loss 0.3194\t Average validation accuracy 0.9156\n",
      "\n",
      "Epoch [1][10]\t Batch [0][550]\t Training Loss 0.5071\t Accuracy 0.8600\n",
      "Epoch [1][10]\t Batch [50][550]\t Training Loss 0.4011\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [100][550]\t Training Loss 0.5727\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [150][550]\t Training Loss 0.4338\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [200][550]\t Training Loss 0.3522\t Accuracy 0.9100\n",
      "Epoch [1][10]\t Batch [250][550]\t Training Loss 0.5165\t Accuracy 0.8700\n",
      "Epoch [1][10]\t Batch [300][550]\t Training Loss 0.3210\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [350][550]\t Training Loss 0.2960\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [400][550]\t Training Loss 0.4646\t Accuracy 0.8600\n",
      "Epoch [1][10]\t Batch [450][550]\t Training Loss 0.3018\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [500][550]\t Training Loss 0.2228\t Accuracy 0.9500\n",
      "\n",
      "Epoch [1]\t Average training loss 0.3796\t Average training accuracy 0.8940\n",
      "Epoch [1]\t Average validation loss 0.2825\t Average validation accuracy 0.9252\n",
      "\n",
      "Epoch [2][10]\t Batch [0][550]\t Training Loss 0.2072\t Accuracy 0.9300\n",
      "Epoch [2][10]\t Batch [50][550]\t Training Loss 0.5410\t Accuracy 0.8600\n",
      "Epoch [2][10]\t Batch [100][550]\t Training Loss 0.2450\t Accuracy 0.9600\n",
      "Epoch [2][10]\t Batch [150][550]\t Training Loss 0.3873\t Accuracy 0.9300\n",
      "Epoch [2][10]\t Batch [200][550]\t Training Loss 0.4287\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [250][550]\t Training Loss 0.3019\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [300][550]\t Training Loss 0.2653\t Accuracy 0.9300\n",
      "Epoch [2][10]\t Batch [350][550]\t Training Loss 0.2475\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [400][550]\t Training Loss 0.5181\t Accuracy 0.8700\n",
      "Epoch [2][10]\t Batch [450][550]\t Training Loss 0.3374\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [500][550]\t Training Loss 0.3577\t Accuracy 0.9200\n",
      "\n",
      "Epoch [2]\t Average training loss 0.3504\t Average training accuracy 0.9015\n",
      "Epoch [2]\t Average validation loss 0.2693\t Average validation accuracy 0.9286\n",
      "\n",
      "Epoch [3][10]\t Batch [0][550]\t Training Loss 0.2706\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [50][550]\t Training Loss 0.3669\t Accuracy 0.9100\n",
      "Epoch [3][10]\t Batch [100][550]\t Training Loss 0.2144\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [150][550]\t Training Loss 0.4192\t Accuracy 0.8500\n",
      "Epoch [3][10]\t Batch [200][550]\t Training Loss 0.1873\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [250][550]\t Training Loss 0.4078\t Accuracy 0.8900\n",
      "Epoch [3][10]\t Batch [300][550]\t Training Loss 0.3532\t Accuracy 0.9100\n",
      "Epoch [3][10]\t Batch [350][550]\t Training Loss 0.3118\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [400][550]\t Training Loss 0.2304\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [450][550]\t Training Loss 0.2231\t Accuracy 0.9600\n",
      "Epoch [3][10]\t Batch [500][550]\t Training Loss 0.2673\t Accuracy 0.9200\n",
      "\n",
      "Epoch [3]\t Average training loss 0.3351\t Average training accuracy 0.9063\n",
      "Epoch [3]\t Average validation loss 0.2602\t Average validation accuracy 0.9308\n",
      "\n",
      "Epoch [4][10]\t Batch [0][550]\t Training Loss 0.4021\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [50][550]\t Training Loss 0.3214\t Accuracy 0.9300\n",
      "Epoch [4][10]\t Batch [100][550]\t Training Loss 0.5772\t Accuracy 0.8100\n",
      "Epoch [4][10]\t Batch [150][550]\t Training Loss 0.2262\t Accuracy 0.9400\n",
      "Epoch [4][10]\t Batch [200][550]\t Training Loss 0.2699\t Accuracy 0.8900\n",
      "Epoch [4][10]\t Batch [250][550]\t Training Loss 0.2158\t Accuracy 0.9300\n",
      "Epoch [4][10]\t Batch [300][550]\t Training Loss 0.4857\t Accuracy 0.8900\n",
      "Epoch [4][10]\t Batch [350][550]\t Training Loss 0.2673\t Accuracy 0.9200\n",
      "Epoch [4][10]\t Batch [400][550]\t Training Loss 0.3801\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [450][550]\t Training Loss 0.6581\t Accuracy 0.8500\n",
      "Epoch [4][10]\t Batch [500][550]\t Training Loss 0.3722\t Accuracy 0.8800\n",
      "\n",
      "Epoch [4]\t Average training loss 0.3249\t Average training accuracy 0.9086\n",
      "Epoch [4]\t Average validation loss 0.2568\t Average validation accuracy 0.9296\n",
      "\n",
      "Epoch [5][10]\t Batch [0][550]\t Training Loss 0.2732\t Accuracy 0.9200\n",
      "Epoch [5][10]\t Batch [50][550]\t Training Loss 0.4345\t Accuracy 0.9100\n",
      "Epoch [5][10]\t Batch [100][550]\t Training Loss 0.3347\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [150][550]\t Training Loss 0.3493\t Accuracy 0.8800\n",
      "Epoch [5][10]\t Batch [200][550]\t Training Loss 0.2995\t Accuracy 0.9500\n",
      "Epoch [5][10]\t Batch [250][550]\t Training Loss 0.5206\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [300][550]\t Training Loss 0.3069\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [350][550]\t Training Loss 0.2799\t Accuracy 0.9200\n",
      "Epoch [5][10]\t Batch [400][550]\t Training Loss 0.5870\t Accuracy 0.9100\n",
      "Epoch [5][10]\t Batch [450][550]\t Training Loss 0.1397\t Accuracy 0.9700\n",
      "Epoch [5][10]\t Batch [500][550]\t Training Loss 0.3807\t Accuracy 0.8700\n",
      "\n",
      "Epoch [5]\t Average training loss 0.3181\t Average training accuracy 0.9104\n",
      "Epoch [5]\t Average validation loss 0.2521\t Average validation accuracy 0.9308\n",
      "\n",
      "Epoch [6][10]\t Batch [0][550]\t Training Loss 0.3693\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [50][550]\t Training Loss 0.2293\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [100][550]\t Training Loss 0.4334\t Accuracy 0.8800\n",
      "Epoch [6][10]\t Batch [150][550]\t Training Loss 0.2528\t Accuracy 0.9400\n",
      "Epoch [6][10]\t Batch [200][550]\t Training Loss 0.2908\t Accuracy 0.9300\n",
      "Epoch [6][10]\t Batch [250][550]\t Training Loss 0.2858\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [300][550]\t Training Loss 0.3015\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [350][550]\t Training Loss 0.3302\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [400][550]\t Training Loss 0.3781\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [450][550]\t Training Loss 0.3804\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [500][550]\t Training Loss 0.2067\t Accuracy 0.9200\n",
      "\n",
      "Epoch [6]\t Average training loss 0.3126\t Average training accuracy 0.9124\n",
      "Epoch [6]\t Average validation loss 0.2475\t Average validation accuracy 0.9340\n",
      "\n",
      "Epoch [7][10]\t Batch [0][550]\t Training Loss 0.2436\t Accuracy 0.9300\n",
      "Epoch [7][10]\t Batch [50][550]\t Training Loss 0.3030\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [100][550]\t Training Loss 0.2121\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [150][550]\t Training Loss 0.2999\t Accuracy 0.9100\n",
      "Epoch [7][10]\t Batch [200][550]\t Training Loss 0.3254\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [250][550]\t Training Loss 0.3678\t Accuracy 0.8800\n",
      "Epoch [7][10]\t Batch [300][550]\t Training Loss 0.2616\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [350][550]\t Training Loss 0.3000\t Accuracy 0.9200\n",
      "Epoch [7][10]\t Batch [400][550]\t Training Loss 0.1641\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [450][550]\t Training Loss 0.2729\t Accuracy 0.9200\n",
      "Epoch [7][10]\t Batch [500][550]\t Training Loss 0.3914\t Accuracy 0.8900\n",
      "\n",
      "Epoch [7]\t Average training loss 0.3083\t Average training accuracy 0.9132\n",
      "Epoch [7]\t Average validation loss 0.2458\t Average validation accuracy 0.9348\n",
      "\n",
      "Epoch [8][10]\t Batch [0][550]\t Training Loss 0.4089\t Accuracy 0.8400\n",
      "Epoch [8][10]\t Batch [50][550]\t Training Loss 0.3278\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [100][550]\t Training Loss 0.3728\t Accuracy 0.8700\n",
      "Epoch [8][10]\t Batch [150][550]\t Training Loss 0.3388\t Accuracy 0.9100\n",
      "Epoch [8][10]\t Batch [200][550]\t Training Loss 0.1973\t Accuracy 0.9600\n",
      "Epoch [8][10]\t Batch [250][550]\t Training Loss 0.1916\t Accuracy 0.9400\n",
      "Epoch [8][10]\t Batch [300][550]\t Training Loss 0.3649\t Accuracy 0.9300\n",
      "Epoch [8][10]\t Batch [350][550]\t Training Loss 0.2544\t Accuracy 0.9300\n",
      "Epoch [8][10]\t Batch [400][550]\t Training Loss 0.3714\t Accuracy 0.8800\n",
      "Epoch [8][10]\t Batch [450][550]\t Training Loss 0.3053\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [500][550]\t Training Loss 0.2142\t Accuracy 0.9500\n",
      "\n",
      "Epoch [8]\t Average training loss 0.3043\t Average training accuracy 0.9151\n",
      "Epoch [8]\t Average validation loss 0.2450\t Average validation accuracy 0.9356\n",
      "\n",
      "Epoch [9][10]\t Batch [0][550]\t Training Loss 0.2418\t Accuracy 0.9100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9][10]\t Batch [50][550]\t Training Loss 0.3256\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [100][550]\t Training Loss 0.3698\t Accuracy 0.8900\n",
      "Epoch [9][10]\t Batch [150][550]\t Training Loss 0.2077\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [200][550]\t Training Loss 0.2043\t Accuracy 0.9400\n",
      "Epoch [9][10]\t Batch [250][550]\t Training Loss 0.2886\t Accuracy 0.9300\n",
      "Epoch [9][10]\t Batch [300][550]\t Training Loss 0.5007\t Accuracy 0.8500\n",
      "Epoch [9][10]\t Batch [350][550]\t Training Loss 0.2290\t Accuracy 0.8900\n",
      "Epoch [9][10]\t Batch [400][550]\t Training Loss 0.3885\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [450][550]\t Training Loss 0.4523\t Accuracy 0.8600\n",
      "Epoch [9][10]\t Batch [500][550]\t Training Loss 0.3192\t Accuracy 0.9200\n",
      "\n",
      "Epoch [9]\t Average training loss 0.3014\t Average training accuracy 0.9158\n",
      "Epoch [9]\t Average validation loss 0.2422\t Average validation accuracy 0.9348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train with momentum\n",
    "cfg = {\n",
    "    'data_root': 'data',\n",
    "    'max_epoch': 10,\n",
    "    'batch_size': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'momentum': 0.9,\n",
    "    'display_freq': 50,\n",
    "}\n",
    "\n",
    "runner = Solver(cfg)\n",
    "loss2, acc2 = runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy 0.9208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = runner.test()\n",
    "print('Final test accuracy {:.4f}\\n'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_and_acc({\n",
    "    \"momentum=0\": [loss1, acc1],\n",
    "    \"momentum=0.9\": [loss2, acc2]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'data_root': 'data',\n",
    "    'max_epoch': 10,\n",
    "    'batch_size': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'momentum': 0.9,\n",
    "    'display_freq': 50,\n",
    "}\n",
    "learning_rates = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "accuracys = []\n",
    "for lr in learning_rates:\n",
    "    cfg['learning_rate'] = lr\n",
    "    runner = Solver(cfg)\n",
    "    runner.train()\n",
    "    test_loss, test_acc = runner.test()\n",
    "    accuracys.append(test_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracys"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'data_root': 'data',\n",
    "    'max_epoch': 10,\n",
    "    'batch_size': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'momentum': 0.9,\n",
    "    'display_freq': 50,\n",
    "}\n",
    "batch_sizes = [1, 20, 50, 100, 200]\n",
    "accuracys = []\n",
    "for bz in batch_sizes:\n",
    "    cfg['batch_size'] = bz\n",
    "    runner = Solver(cfg)\n",
    "    runner.train()\n",
    "    test_loss, test_acc = runner.test()\n",
    "    accuracys.append(test_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracys"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'data_root': 'data',\n",
    "    'max_epoch': 30,\n",
    "    'batch_size': 200,\n",
    "    'learning_rate': 0.01,\n",
    "    'momentum': 0.9,\n",
    "    'display_freq': 50,\n",
    "}\n",
    "runner = Solver(cfg)\n",
    "loss3, acc3 = runner.train()\n",
    "test_loss, test_acc = runner.test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_and_acc({\n",
    "    \"batch_size=200\": [loss3, acc3],\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][10]\t Batch [0][550]\t Training Loss 2.5657\t Accuracy 0.1200\n",
      "Epoch [0][10]\t Batch [50][550]\t Training Loss 2.0815\t Accuracy 0.2800\n",
      "Epoch [0][10]\t Batch [100][550]\t Training Loss 1.7806\t Accuracy 0.4200\n",
      "Epoch [0][10]\t Batch [150][550]\t Training Loss 1.4785\t Accuracy 0.5700\n",
      "Epoch [0][10]\t Batch [200][550]\t Training Loss 1.3480\t Accuracy 0.6200\n",
      "Epoch [0][10]\t Batch [250][550]\t Training Loss 1.1139\t Accuracy 0.7500\n",
      "Epoch [0][10]\t Batch [300][550]\t Training Loss 0.9820\t Accuracy 0.7800\n",
      "Epoch [0][10]\t Batch [350][550]\t Training Loss 0.9715\t Accuracy 0.7700\n",
      "Epoch [0][10]\t Batch [400][550]\t Training Loss 0.9266\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [450][550]\t Training Loss 0.9469\t Accuracy 0.8200\n",
      "Epoch [0][10]\t Batch [500][550]\t Training Loss 0.7970\t Accuracy 0.8300\n",
      "\n",
      "Epoch [0]\t Average training loss 1.2855\t Average training accuracy 0.6595\n",
      "Epoch [0]\t Average validation loss 0.7195\t Average validation accuracy 0.8596\n",
      "\n",
      "Epoch [1][10]\t Batch [0][550]\t Training Loss 0.7819\t Accuracy 0.8100\n",
      "Epoch [1][10]\t Batch [50][550]\t Training Loss 0.8676\t Accuracy 0.7700\n",
      "Epoch [1][10]\t Batch [100][550]\t Training Loss 0.7183\t Accuracy 0.8700\n",
      "Epoch [1][10]\t Batch [150][550]\t Training Loss 0.7271\t Accuracy 0.7900\n",
      "Epoch [1][10]\t Batch [200][550]\t Training Loss 0.6664\t Accuracy 0.8300\n",
      "Epoch [1][10]\t Batch [250][550]\t Training Loss 0.7240\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [300][550]\t Training Loss 0.6894\t Accuracy 0.8100\n",
      "Epoch [1][10]\t Batch [350][550]\t Training Loss 0.6691\t Accuracy 0.8300\n",
      "Epoch [1][10]\t Batch [400][550]\t Training Loss 0.7605\t Accuracy 0.7700\n",
      "Epoch [1][10]\t Batch [450][550]\t Training Loss 0.5853\t Accuracy 0.9100\n",
      "Epoch [1][10]\t Batch [500][550]\t Training Loss 0.5498\t Accuracy 0.8800\n",
      "\n",
      "Epoch [1]\t Average training loss 0.6928\t Average training accuracy 0.8380\n",
      "Epoch [1]\t Average validation loss 0.5200\t Average validation accuracy 0.8910\n",
      "\n",
      "Epoch [2][10]\t Batch [0][550]\t Training Loss 0.6275\t Accuracy 0.8600\n",
      "Epoch [2][10]\t Batch [50][550]\t Training Loss 0.5065\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [100][550]\t Training Loss 0.6112\t Accuracy 0.8300\n",
      "Epoch [2][10]\t Batch [150][550]\t Training Loss 0.6998\t Accuracy 0.8200\n",
      "Epoch [2][10]\t Batch [200][550]\t Training Loss 0.5982\t Accuracy 0.8500\n",
      "Epoch [2][10]\t Batch [250][550]\t Training Loss 0.5919\t Accuracy 0.8600\n",
      "Epoch [2][10]\t Batch [300][550]\t Training Loss 0.4564\t Accuracy 0.9100\n",
      "Epoch [2][10]\t Batch [350][550]\t Training Loss 0.5933\t Accuracy 0.8400\n",
      "Epoch [2][10]\t Batch [400][550]\t Training Loss 0.6526\t Accuracy 0.8300\n",
      "Epoch [2][10]\t Batch [450][550]\t Training Loss 0.4576\t Accuracy 0.8800\n",
      "Epoch [2][10]\t Batch [500][550]\t Training Loss 0.6494\t Accuracy 0.8100\n",
      "\n",
      "Epoch [2]\t Average training loss 0.5718\t Average training accuracy 0.8574\n",
      "Epoch [2]\t Average validation loss 0.4442\t Average validation accuracy 0.9014\n",
      "\n",
      "Epoch [3][10]\t Batch [0][550]\t Training Loss 0.6359\t Accuracy 0.8500\n",
      "Epoch [3][10]\t Batch [50][550]\t Training Loss 0.4734\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [100][550]\t Training Loss 0.4137\t Accuracy 0.9100\n",
      "Epoch [3][10]\t Batch [150][550]\t Training Loss 0.5378\t Accuracy 0.8800\n",
      "Epoch [3][10]\t Batch [200][550]\t Training Loss 0.5046\t Accuracy 0.8700\n",
      "Epoch [3][10]\t Batch [250][550]\t Training Loss 0.4926\t Accuracy 0.8900\n",
      "Epoch [3][10]\t Batch [300][550]\t Training Loss 0.4651\t Accuracy 0.8800\n",
      "Epoch [3][10]\t Batch [350][550]\t Training Loss 0.5290\t Accuracy 0.8600\n",
      "Epoch [3][10]\t Batch [400][550]\t Training Loss 0.5297\t Accuracy 0.8700\n",
      "Epoch [3][10]\t Batch [450][550]\t Training Loss 0.4944\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [500][550]\t Training Loss 0.5831\t Accuracy 0.8300\n",
      "\n",
      "Epoch [3]\t Average training loss 0.5145\t Average training accuracy 0.8678\n",
      "Epoch [3]\t Average validation loss 0.4027\t Average validation accuracy 0.9056\n",
      "\n",
      "Epoch [4][10]\t Batch [0][550]\t Training Loss 0.5918\t Accuracy 0.8300\n",
      "Epoch [4][10]\t Batch [50][550]\t Training Loss 0.4650\t Accuracy 0.8900\n",
      "Epoch [4][10]\t Batch [100][550]\t Training Loss 0.6240\t Accuracy 0.7900\n",
      "Epoch [4][10]\t Batch [150][550]\t Training Loss 0.5628\t Accuracy 0.8600\n",
      "Epoch [4][10]\t Batch [200][550]\t Training Loss 0.4386\t Accuracy 0.8900\n",
      "Epoch [4][10]\t Batch [250][550]\t Training Loss 0.5029\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [300][550]\t Training Loss 0.5158\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [350][550]\t Training Loss 0.4813\t Accuracy 0.8400\n",
      "Epoch [4][10]\t Batch [400][550]\t Training Loss 0.6037\t Accuracy 0.8300\n",
      "Epoch [4][10]\t Batch [450][550]\t Training Loss 0.5327\t Accuracy 0.8600\n",
      "Epoch [4][10]\t Batch [500][550]\t Training Loss 0.5041\t Accuracy 0.8400\n",
      "\n",
      "Epoch [4]\t Average training loss 0.4796\t Average training accuracy 0.8742\n",
      "Epoch [4]\t Average validation loss 0.3766\t Average validation accuracy 0.9072\n",
      "\n",
      "Epoch [5][10]\t Batch [0][550]\t Training Loss 0.5004\t Accuracy 0.8300\n",
      "Epoch [5][10]\t Batch [50][550]\t Training Loss 0.3771\t Accuracy 0.9300\n",
      "Epoch [5][10]\t Batch [100][550]\t Training Loss 0.3413\t Accuracy 0.9400\n",
      "Epoch [5][10]\t Batch [150][550]\t Training Loss 0.4067\t Accuracy 0.9200\n",
      "Epoch [5][10]\t Batch [200][550]\t Training Loss 0.4665\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [250][550]\t Training Loss 0.4636\t Accuracy 0.8700\n",
      "Epoch [5][10]\t Batch [300][550]\t Training Loss 0.6191\t Accuracy 0.8700\n",
      "Epoch [5][10]\t Batch [350][550]\t Training Loss 0.5993\t Accuracy 0.8700\n",
      "Epoch [5][10]\t Batch [400][550]\t Training Loss 0.5749\t Accuracy 0.8200\n",
      "Epoch [5][10]\t Batch [450][550]\t Training Loss 0.5287\t Accuracy 0.8400\n",
      "Epoch [5][10]\t Batch [500][550]\t Training Loss 0.2806\t Accuracy 0.9100\n",
      "\n",
      "Epoch [5]\t Average training loss 0.4557\t Average training accuracy 0.8793\n",
      "Epoch [5]\t Average validation loss 0.3579\t Average validation accuracy 0.9106\n",
      "\n",
      "Epoch [6][10]\t Batch [0][550]\t Training Loss 0.3725\t Accuracy 0.9200\n",
      "Epoch [6][10]\t Batch [50][550]\t Training Loss 0.2811\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [100][550]\t Training Loss 0.5137\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [150][550]\t Training Loss 0.5160\t Accuracy 0.8400\n",
      "Epoch [6][10]\t Batch [200][550]\t Training Loss 0.3864\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [250][550]\t Training Loss 0.4568\t Accuracy 0.8700\n",
      "Epoch [6][10]\t Batch [300][550]\t Training Loss 0.3792\t Accuracy 0.8900\n",
      "Epoch [6][10]\t Batch [350][550]\t Training Loss 0.3554\t Accuracy 0.9300\n",
      "Epoch [6][10]\t Batch [400][550]\t Training Loss 0.4858\t Accuracy 0.8500\n",
      "Epoch [6][10]\t Batch [450][550]\t Training Loss 0.5820\t Accuracy 0.8200\n",
      "Epoch [6][10]\t Batch [500][550]\t Training Loss 0.3671\t Accuracy 0.9200\n",
      "\n",
      "Epoch [6]\t Average training loss 0.4380\t Average training accuracy 0.8825\n",
      "Epoch [6]\t Average validation loss 0.3443\t Average validation accuracy 0.9128\n",
      "\n",
      "Epoch [7][10]\t Batch [0][550]\t Training Loss 0.4481\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [50][550]\t Training Loss 0.4933\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [100][550]\t Training Loss 0.3953\t Accuracy 0.8900\n",
      "Epoch [7][10]\t Batch [150][550]\t Training Loss 0.4090\t Accuracy 0.9200\n",
      "Epoch [7][10]\t Batch [200][550]\t Training Loss 0.5877\t Accuracy 0.8600\n",
      "Epoch [7][10]\t Batch [250][550]\t Training Loss 0.3533\t Accuracy 0.9300\n",
      "Epoch [7][10]\t Batch [300][550]\t Training Loss 0.3028\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [350][550]\t Training Loss 0.3837\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [400][550]\t Training Loss 0.4886\t Accuracy 0.8500\n",
      "Epoch [7][10]\t Batch [450][550]\t Training Loss 0.3234\t Accuracy 0.9200\n",
      "Epoch [7][10]\t Batch [500][550]\t Training Loss 0.3388\t Accuracy 0.9000\n",
      "\n",
      "Epoch [7]\t Average training loss 0.4242\t Average training accuracy 0.8851\n",
      "Epoch [7]\t Average validation loss 0.3332\t Average validation accuracy 0.9148\n",
      "\n",
      "Epoch [8][10]\t Batch [0][550]\t Training Loss 0.4708\t Accuracy 0.8500\n",
      "Epoch [8][10]\t Batch [50][550]\t Training Loss 0.3828\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [100][550]\t Training Loss 0.5207\t Accuracy 0.8300\n",
      "Epoch [8][10]\t Batch [150][550]\t Training Loss 0.3456\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [200][550]\t Training Loss 0.3196\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [250][550]\t Training Loss 0.3404\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [300][550]\t Training Loss 0.3093\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [350][550]\t Training Loss 0.2641\t Accuracy 0.9300\n",
      "Epoch [8][10]\t Batch [400][550]\t Training Loss 0.3965\t Accuracy 0.8700\n",
      "Epoch [8][10]\t Batch [450][550]\t Training Loss 0.4070\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [500][550]\t Training Loss 0.5322\t Accuracy 0.8500\n",
      "\n",
      "Epoch [8]\t Average training loss 0.4131\t Average training accuracy 0.8874\n",
      "Epoch [8]\t Average validation loss 0.3244\t Average validation accuracy 0.9162\n",
      "\n",
      "Epoch [9][10]\t Batch [0][550]\t Training Loss 0.5404\t Accuracy 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9][10]\t Batch [50][550]\t Training Loss 0.3524\t Accuracy 0.9300\n",
      "Epoch [9][10]\t Batch [100][550]\t Training Loss 0.4041\t Accuracy 0.8800\n",
      "Epoch [9][10]\t Batch [150][550]\t Training Loss 0.3760\t Accuracy 0.8800\n",
      "Epoch [9][10]\t Batch [200][550]\t Training Loss 0.2792\t Accuracy 0.9300\n",
      "Epoch [9][10]\t Batch [250][550]\t Training Loss 0.3408\t Accuracy 0.9100\n",
      "Epoch [9][10]\t Batch [300][550]\t Training Loss 0.3335\t Accuracy 0.9100\n",
      "Epoch [9][10]\t Batch [350][550]\t Training Loss 0.2772\t Accuracy 0.9700\n",
      "Epoch [9][10]\t Batch [400][550]\t Training Loss 0.4063\t Accuracy 0.8500\n",
      "Epoch [9][10]\t Batch [450][550]\t Training Loss 0.3447\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [500][550]\t Training Loss 0.4128\t Accuracy 0.8800\n",
      "\n",
      "Epoch [9]\t Average training loss 0.4038\t Average training accuracy 0.8896\n",
      "Epoch [9]\t Average validation loss 0.3173\t Average validation accuracy 0.9186\n",
      "\n",
      "Epoch [0][10]\t Batch [0][550]\t Training Loss 2.5648\t Accuracy 0.0400\n",
      "Epoch [0][10]\t Batch [50][550]\t Training Loss 1.2644\t Accuracy 0.7100\n",
      "Epoch [0][10]\t Batch [100][550]\t Training Loss 0.8026\t Accuracy 0.8100\n",
      "Epoch [0][10]\t Batch [150][550]\t Training Loss 0.7471\t Accuracy 0.8300\n",
      "Epoch [0][10]\t Batch [200][550]\t Training Loss 0.6447\t Accuracy 0.8200\n",
      "Epoch [0][10]\t Batch [250][550]\t Training Loss 0.5059\t Accuracy 0.8800\n",
      "Epoch [0][10]\t Batch [300][550]\t Training Loss 0.6911\t Accuracy 0.8300\n",
      "Epoch [0][10]\t Batch [350][550]\t Training Loss 0.5160\t Accuracy 0.8800\n",
      "Epoch [0][10]\t Batch [400][550]\t Training Loss 0.5677\t Accuracy 0.8300\n",
      "Epoch [0][10]\t Batch [450][550]\t Training Loss 0.6645\t Accuracy 0.7900\n",
      "Epoch [0][10]\t Batch [500][550]\t Training Loss 0.5097\t Accuracy 0.8500\n",
      "\n",
      "Epoch [0]\t Average training loss 0.7325\t Average training accuracy 0.8040\n",
      "Epoch [0]\t Average validation loss 0.3819\t Average validation accuracy 0.9046\n",
      "\n",
      "Epoch [1][10]\t Batch [0][550]\t Training Loss 0.4358\t Accuracy 0.9200\n",
      "Epoch [1][10]\t Batch [50][550]\t Training Loss 0.3748\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [100][550]\t Training Loss 0.3883\t Accuracy 0.9100\n",
      "Epoch [1][10]\t Batch [150][550]\t Training Loss 0.4239\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [200][550]\t Training Loss 0.6015\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [250][550]\t Training Loss 0.3111\t Accuracy 0.9300\n",
      "Epoch [1][10]\t Batch [300][550]\t Training Loss 0.5653\t Accuracy 0.8000\n",
      "Epoch [1][10]\t Batch [350][550]\t Training Loss 0.2762\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [400][550]\t Training Loss 0.3626\t Accuracy 0.8900\n",
      "Epoch [1][10]\t Batch [450][550]\t Training Loss 0.4174\t Accuracy 0.9100\n",
      "Epoch [1][10]\t Batch [500][550]\t Training Loss 0.4483\t Accuracy 0.8600\n",
      "\n",
      "Epoch [1]\t Average training loss 0.4334\t Average training accuracy 0.8824\n",
      "Epoch [1]\t Average validation loss 0.3225\t Average validation accuracy 0.9128\n",
      "\n",
      "Epoch [2][10]\t Batch [0][550]\t Training Loss 0.4164\t Accuracy 0.8900\n",
      "Epoch [2][10]\t Batch [50][550]\t Training Loss 0.3365\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [100][550]\t Training Loss 0.4050\t Accuracy 0.8900\n",
      "Epoch [2][10]\t Batch [150][550]\t Training Loss 0.4970\t Accuracy 0.8600\n",
      "Epoch [2][10]\t Batch [200][550]\t Training Loss 0.3713\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [250][550]\t Training Loss 0.5354\t Accuracy 0.8200\n",
      "Epoch [2][10]\t Batch [300][550]\t Training Loss 0.2050\t Accuracy 0.9400\n",
      "Epoch [2][10]\t Batch [350][550]\t Training Loss 0.2902\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [400][550]\t Training Loss 0.3850\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [450][550]\t Training Loss 0.4171\t Accuracy 0.8900\n",
      "Epoch [2][10]\t Batch [500][550]\t Training Loss 0.4038\t Accuracy 0.8800\n",
      "\n",
      "Epoch [2]\t Average training loss 0.3900\t Average training accuracy 0.8914\n",
      "Epoch [2]\t Average validation loss 0.2988\t Average validation accuracy 0.9186\n",
      "\n",
      "Epoch [3][10]\t Batch [0][550]\t Training Loss 0.5073\t Accuracy 0.8700\n",
      "Epoch [3][10]\t Batch [50][550]\t Training Loss 0.3032\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [100][550]\t Training Loss 0.3900\t Accuracy 0.9100\n",
      "Epoch [3][10]\t Batch [150][550]\t Training Loss 0.2913\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [200][550]\t Training Loss 0.2569\t Accuracy 0.9300\n",
      "Epoch [3][10]\t Batch [250][550]\t Training Loss 0.2116\t Accuracy 0.9600\n",
      "Epoch [3][10]\t Batch [300][550]\t Training Loss 0.3018\t Accuracy 0.8900\n",
      "Epoch [3][10]\t Batch [350][550]\t Training Loss 0.3834\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [400][550]\t Training Loss 0.3741\t Accuracy 0.8900\n",
      "Epoch [3][10]\t Batch [450][550]\t Training Loss 0.4670\t Accuracy 0.8500\n",
      "Epoch [3][10]\t Batch [500][550]\t Training Loss 0.3253\t Accuracy 0.9200\n",
      "\n",
      "Epoch [3]\t Average training loss 0.3679\t Average training accuracy 0.8977\n",
      "Epoch [3]\t Average validation loss 0.2856\t Average validation accuracy 0.9218\n",
      "\n",
      "Epoch [4][10]\t Batch [0][550]\t Training Loss 0.3058\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [50][550]\t Training Loss 0.2672\t Accuracy 0.9200\n",
      "Epoch [4][10]\t Batch [100][550]\t Training Loss 0.3658\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [150][550]\t Training Loss 0.4035\t Accuracy 0.9100\n",
      "Epoch [4][10]\t Batch [200][550]\t Training Loss 0.2583\t Accuracy 0.9700\n",
      "Epoch [4][10]\t Batch [250][550]\t Training Loss 0.5282\t Accuracy 0.8500\n",
      "Epoch [4][10]\t Batch [300][550]\t Training Loss 0.4829\t Accuracy 0.8400\n",
      "Epoch [4][10]\t Batch [350][550]\t Training Loss 0.3488\t Accuracy 0.9200\n",
      "Epoch [4][10]\t Batch [400][550]\t Training Loss 0.4262\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [450][550]\t Training Loss 0.4140\t Accuracy 0.8900\n",
      "Epoch [4][10]\t Batch [500][550]\t Training Loss 0.3222\t Accuracy 0.8800\n",
      "\n",
      "Epoch [4]\t Average training loss 0.3540\t Average training accuracy 0.9010\n",
      "Epoch [4]\t Average validation loss 0.2760\t Average validation accuracy 0.9252\n",
      "\n",
      "Epoch [5][10]\t Batch [0][550]\t Training Loss 0.2579\t Accuracy 0.9400\n",
      "Epoch [5][10]\t Batch [50][550]\t Training Loss 0.3853\t Accuracy 0.9400\n",
      "Epoch [5][10]\t Batch [100][550]\t Training Loss 0.3493\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [150][550]\t Training Loss 0.3618\t Accuracy 0.8500\n",
      "Epoch [5][10]\t Batch [200][550]\t Training Loss 0.2810\t Accuracy 0.9300\n",
      "Epoch [5][10]\t Batch [250][550]\t Training Loss 0.2963\t Accuracy 0.9100\n",
      "Epoch [5][10]\t Batch [300][550]\t Training Loss 0.3070\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [350][550]\t Training Loss 0.3310\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [400][550]\t Training Loss 0.3884\t Accuracy 0.8700\n",
      "Epoch [5][10]\t Batch [450][550]\t Training Loss 0.2752\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [500][550]\t Training Loss 0.4753\t Accuracy 0.8800\n",
      "\n",
      "Epoch [5]\t Average training loss 0.3440\t Average training accuracy 0.9037\n",
      "Epoch [5]\t Average validation loss 0.2700\t Average validation accuracy 0.9282\n",
      "\n",
      "Epoch [6][10]\t Batch [0][550]\t Training Loss 0.3229\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [50][550]\t Training Loss 0.3307\t Accuracy 0.9300\n",
      "Epoch [6][10]\t Batch [100][550]\t Training Loss 0.2748\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [150][550]\t Training Loss 0.3433\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [200][550]\t Training Loss 0.3261\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [250][550]\t Training Loss 0.4207\t Accuracy 0.8600\n",
      "Epoch [6][10]\t Batch [300][550]\t Training Loss 0.3239\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [350][550]\t Training Loss 0.3429\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [400][550]\t Training Loss 0.3599\t Accuracy 0.8900\n",
      "Epoch [6][10]\t Batch [450][550]\t Training Loss 0.2164\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [500][550]\t Training Loss 0.2455\t Accuracy 0.9200\n",
      "\n",
      "Epoch [6]\t Average training loss 0.3366\t Average training accuracy 0.9059\n",
      "Epoch [6]\t Average validation loss 0.2650\t Average validation accuracy 0.9290\n",
      "\n",
      "Epoch [7][10]\t Batch [0][550]\t Training Loss 0.3144\t Accuracy 0.8900\n",
      "Epoch [7][10]\t Batch [50][550]\t Training Loss 0.3601\t Accuracy 0.8900\n",
      "Epoch [7][10]\t Batch [100][550]\t Training Loss 0.3214\t Accuracy 0.8600\n",
      "Epoch [7][10]\t Batch [150][550]\t Training Loss 0.3502\t Accuracy 0.9100\n",
      "Epoch [7][10]\t Batch [200][550]\t Training Loss 0.3494\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [250][550]\t Training Loss 0.3078\t Accuracy 0.9300\n",
      "Epoch [7][10]\t Batch [300][550]\t Training Loss 0.2680\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [350][550]\t Training Loss 0.2410\t Accuracy 0.9100\n",
      "Epoch [7][10]\t Batch [400][550]\t Training Loss 0.1886\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [450][550]\t Training Loss 0.4208\t Accuracy 0.8900\n",
      "Epoch [7][10]\t Batch [500][550]\t Training Loss 0.4260\t Accuracy 0.8600\n",
      "\n",
      "Epoch [7]\t Average training loss 0.3304\t Average training accuracy 0.9072\n",
      "Epoch [7]\t Average validation loss 0.2606\t Average validation accuracy 0.9314\n",
      "\n",
      "Epoch [8][10]\t Batch [0][550]\t Training Loss 0.3752\t Accuracy 0.9100\n",
      "Epoch [8][10]\t Batch [50][550]\t Training Loss 0.3247\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [100][550]\t Training Loss 0.2661\t Accuracy 0.9100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8][10]\t Batch [150][550]\t Training Loss 0.2820\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [200][550]\t Training Loss 0.3796\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [250][550]\t Training Loss 0.3377\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [300][550]\t Training Loss 0.2970\t Accuracy 0.9100\n",
      "Epoch [8][10]\t Batch [350][550]\t Training Loss 0.2018\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [400][550]\t Training Loss 0.3032\t Accuracy 0.9300\n",
      "Epoch [8][10]\t Batch [450][550]\t Training Loss 0.3729\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [500][550]\t Training Loss 0.4359\t Accuracy 0.8400\n",
      "\n",
      "Epoch [8]\t Average training loss 0.3256\t Average training accuracy 0.9088\n",
      "Epoch [8]\t Average validation loss 0.2582\t Average validation accuracy 0.9308\n",
      "\n",
      "Epoch [9][10]\t Batch [0][550]\t Training Loss 0.3392\t Accuracy 0.9100\n",
      "Epoch [9][10]\t Batch [50][550]\t Training Loss 0.3693\t Accuracy 0.9100\n",
      "Epoch [9][10]\t Batch [100][550]\t Training Loss 0.2796\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [150][550]\t Training Loss 0.3785\t Accuracy 0.9100\n",
      "Epoch [9][10]\t Batch [200][550]\t Training Loss 0.4193\t Accuracy 0.8600\n",
      "Epoch [9][10]\t Batch [250][550]\t Training Loss 0.3659\t Accuracy 0.9100\n",
      "Epoch [9][10]\t Batch [300][550]\t Training Loss 0.2674\t Accuracy 0.9400\n",
      "Epoch [9][10]\t Batch [350][550]\t Training Loss 0.3531\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [400][550]\t Training Loss 0.2278\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [450][550]\t Training Loss 0.1740\t Accuracy 0.9700\n",
      "Epoch [9][10]\t Batch [500][550]\t Training Loss 0.2607\t Accuracy 0.9100\n",
      "\n",
      "Epoch [9]\t Average training loss 0.3214\t Average training accuracy 0.9098\n",
      "Epoch [9]\t Average validation loss 0.2550\t Average validation accuracy 0.9316\n",
      "\n",
      "Epoch [0][10]\t Batch [0][550]\t Training Loss 2.4834\t Accuracy 0.1600\n",
      "Epoch [0][10]\t Batch [50][550]\t Training Loss 0.8148\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [100][550]\t Training Loss 0.6459\t Accuracy 0.8300\n",
      "Epoch [0][10]\t Batch [150][550]\t Training Loss 0.6284\t Accuracy 0.8200\n",
      "Epoch [0][10]\t Batch [200][550]\t Training Loss 0.4415\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [250][550]\t Training Loss 0.3588\t Accuracy 0.9200\n",
      "Epoch [0][10]\t Batch [300][550]\t Training Loss 0.5387\t Accuracy 0.8900\n",
      "Epoch [0][10]\t Batch [350][550]\t Training Loss 0.6078\t Accuracy 0.8300\n",
      "Epoch [0][10]\t Batch [400][550]\t Training Loss 0.3320\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [450][550]\t Training Loss 0.2276\t Accuracy 0.9700\n",
      "Epoch [0][10]\t Batch [500][550]\t Training Loss 0.5503\t Accuracy 0.8500\n",
      "\n",
      "Epoch [0]\t Average training loss 0.5820\t Average training accuracy 0.8420\n",
      "Epoch [0]\t Average validation loss 0.3193\t Average validation accuracy 0.9178\n",
      "\n",
      "Epoch [1][10]\t Batch [0][550]\t Training Loss 0.4007\t Accuracy 0.9200\n",
      "Epoch [1][10]\t Batch [50][550]\t Training Loss 0.3441\t Accuracy 0.9200\n",
      "Epoch [1][10]\t Batch [100][550]\t Training Loss 0.4189\t Accuracy 0.8600\n",
      "Epoch [1][10]\t Batch [150][550]\t Training Loss 0.3219\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [200][550]\t Training Loss 0.4839\t Accuracy 0.8300\n",
      "Epoch [1][10]\t Batch [250][550]\t Training Loss 0.4120\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [300][550]\t Training Loss 0.4597\t Accuracy 0.8600\n",
      "Epoch [1][10]\t Batch [350][550]\t Training Loss 0.2982\t Accuracy 0.9200\n",
      "Epoch [1][10]\t Batch [400][550]\t Training Loss 0.3471\t Accuracy 0.8700\n",
      "Epoch [1][10]\t Batch [450][550]\t Training Loss 0.3159\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [500][550]\t Training Loss 0.3756\t Accuracy 0.8800\n",
      "\n",
      "Epoch [1]\t Average training loss 0.3784\t Average training accuracy 0.8945\n",
      "Epoch [1]\t Average validation loss 0.2832\t Average validation accuracy 0.9256\n",
      "\n",
      "Epoch [2][10]\t Batch [0][550]\t Training Loss 0.3960\t Accuracy 0.8900\n",
      "Epoch [2][10]\t Batch [50][550]\t Training Loss 0.2557\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [100][550]\t Training Loss 0.3110\t Accuracy 0.8800\n",
      "Epoch [2][10]\t Batch [150][550]\t Training Loss 0.3164\t Accuracy 0.9100\n",
      "Epoch [2][10]\t Batch [200][550]\t Training Loss 0.3928\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [250][550]\t Training Loss 0.3211\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [300][550]\t Training Loss 0.2660\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [350][550]\t Training Loss 0.5170\t Accuracy 0.8600\n",
      "Epoch [2][10]\t Batch [400][550]\t Training Loss 0.3250\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [450][550]\t Training Loss 0.3409\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [500][550]\t Training Loss 0.3432\t Accuracy 0.9200\n",
      "\n",
      "Epoch [2]\t Average training loss 0.3487\t Average training accuracy 0.9022\n",
      "Epoch [2]\t Average validation loss 0.2684\t Average validation accuracy 0.9276\n",
      "\n",
      "Epoch [3][10]\t Batch [0][550]\t Training Loss 0.2611\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [50][550]\t Training Loss 0.2362\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [100][550]\t Training Loss 0.3107\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [150][550]\t Training Loss 0.4399\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [200][550]\t Training Loss 0.4522\t Accuracy 0.8700\n",
      "Epoch [3][10]\t Batch [250][550]\t Training Loss 0.2946\t Accuracy 0.8800\n",
      "Epoch [3][10]\t Batch [300][550]\t Training Loss 0.3131\t Accuracy 0.8900\n",
      "Epoch [3][10]\t Batch [350][550]\t Training Loss 0.3971\t Accuracy 0.8700\n",
      "Epoch [3][10]\t Batch [400][550]\t Training Loss 0.3583\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [450][550]\t Training Loss 0.3164\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [500][550]\t Training Loss 0.2614\t Accuracy 0.9300\n",
      "\n",
      "Epoch [3]\t Average training loss 0.3337\t Average training accuracy 0.9064\n",
      "Epoch [3]\t Average validation loss 0.2601\t Average validation accuracy 0.9306\n",
      "\n",
      "Epoch [4][10]\t Batch [0][550]\t Training Loss 0.2977\t Accuracy 0.8900\n",
      "Epoch [4][10]\t Batch [50][550]\t Training Loss 0.2364\t Accuracy 0.9200\n",
      "Epoch [4][10]\t Batch [100][550]\t Training Loss 0.2420\t Accuracy 0.9300\n",
      "Epoch [4][10]\t Batch [150][550]\t Training Loss 0.3501\t Accuracy 0.9200\n",
      "Epoch [4][10]\t Batch [200][550]\t Training Loss 0.5146\t Accuracy 0.8600\n",
      "Epoch [4][10]\t Batch [250][550]\t Training Loss 0.3415\t Accuracy 0.8800\n",
      "Epoch [4][10]\t Batch [300][550]\t Training Loss 0.3210\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [350][550]\t Training Loss 0.4104\t Accuracy 0.8500\n",
      "Epoch [4][10]\t Batch [400][550]\t Training Loss 0.3014\t Accuracy 0.9400\n",
      "Epoch [4][10]\t Batch [450][550]\t Training Loss 0.3239\t Accuracy 0.8800\n",
      "Epoch [4][10]\t Batch [500][550]\t Training Loss 0.2841\t Accuracy 0.9000\n",
      "\n",
      "Epoch [4]\t Average training loss 0.3238\t Average training accuracy 0.9095\n",
      "Epoch [4]\t Average validation loss 0.2533\t Average validation accuracy 0.9328\n",
      "\n",
      "Epoch [5][10]\t Batch [0][550]\t Training Loss 0.2850\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [50][550]\t Training Loss 0.2155\t Accuracy 0.9400\n",
      "Epoch [5][10]\t Batch [100][550]\t Training Loss 0.2326\t Accuracy 0.9600\n",
      "Epoch [5][10]\t Batch [150][550]\t Training Loss 0.3576\t Accuracy 0.8700\n",
      "Epoch [5][10]\t Batch [200][550]\t Training Loss 0.2694\t Accuracy 0.9600\n",
      "Epoch [5][10]\t Batch [250][550]\t Training Loss 0.3965\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [300][550]\t Training Loss 0.3347\t Accuracy 0.8800\n",
      "Epoch [5][10]\t Batch [350][550]\t Training Loss 0.5165\t Accuracy 0.8300\n",
      "Epoch [5][10]\t Batch [400][550]\t Training Loss 0.3813\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [450][550]\t Training Loss 0.4087\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [500][550]\t Training Loss 0.1374\t Accuracy 0.9700\n",
      "\n",
      "Epoch [5]\t Average training loss 0.3167\t Average training accuracy 0.9119\n",
      "Epoch [5]\t Average validation loss 0.2488\t Average validation accuracy 0.9324\n",
      "\n",
      "Epoch [6][10]\t Batch [0][550]\t Training Loss 0.2147\t Accuracy 0.9300\n",
      "Epoch [6][10]\t Batch [50][550]\t Training Loss 0.2976\t Accuracy 0.8900\n",
      "Epoch [6][10]\t Batch [100][550]\t Training Loss 0.2651\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [150][550]\t Training Loss 0.3776\t Accuracy 0.8800\n",
      "Epoch [6][10]\t Batch [200][550]\t Training Loss 0.4673\t Accuracy 0.8900\n",
      "Epoch [6][10]\t Batch [250][550]\t Training Loss 0.3244\t Accuracy 0.8900\n",
      "Epoch [6][10]\t Batch [300][550]\t Training Loss 0.3785\t Accuracy 0.8900\n",
      "Epoch [6][10]\t Batch [350][550]\t Training Loss 0.1407\t Accuracy 0.9800\n",
      "Epoch [6][10]\t Batch [400][550]\t Training Loss 0.2741\t Accuracy 0.9300\n",
      "Epoch [6][10]\t Batch [450][550]\t Training Loss 0.1804\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [500][550]\t Training Loss 0.3264\t Accuracy 0.9000\n",
      "\n",
      "Epoch [6]\t Average training loss 0.3113\t Average training accuracy 0.9135\n",
      "Epoch [6]\t Average validation loss 0.2475\t Average validation accuracy 0.9328\n",
      "\n",
      "Epoch [7][10]\t Batch [0][550]\t Training Loss 0.3672\t Accuracy 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7][10]\t Batch [50][550]\t Training Loss 0.3738\t Accuracy 0.8900\n",
      "Epoch [7][10]\t Batch [100][550]\t Training Loss 0.3106\t Accuracy 0.9100\n",
      "Epoch [7][10]\t Batch [150][550]\t Training Loss 0.3806\t Accuracy 0.8800\n",
      "Epoch [7][10]\t Batch [200][550]\t Training Loss 0.3097\t Accuracy 0.9300\n",
      "Epoch [7][10]\t Batch [250][550]\t Training Loss 0.2926\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [300][550]\t Training Loss 0.2029\t Accuracy 0.9700\n",
      "Epoch [7][10]\t Batch [350][550]\t Training Loss 0.3108\t Accuracy 0.9200\n",
      "Epoch [7][10]\t Batch [400][550]\t Training Loss 0.1947\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [450][550]\t Training Loss 0.3405\t Accuracy 0.8900\n",
      "Epoch [7][10]\t Batch [500][550]\t Training Loss 0.2532\t Accuracy 0.9100\n",
      "\n",
      "Epoch [7]\t Average training loss 0.3069\t Average training accuracy 0.9150\n",
      "Epoch [7]\t Average validation loss 0.2444\t Average validation accuracy 0.9348\n",
      "\n",
      "Epoch [8][10]\t Batch [0][550]\t Training Loss 0.2251\t Accuracy 0.9400\n",
      "Epoch [8][10]\t Batch [50][550]\t Training Loss 0.2458\t Accuracy 0.9600\n",
      "Epoch [8][10]\t Batch [100][550]\t Training Loss 0.0827\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [150][550]\t Training Loss 0.2661\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [200][550]\t Training Loss 0.3564\t Accuracy 0.8700\n",
      "Epoch [8][10]\t Batch [250][550]\t Training Loss 0.3250\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [300][550]\t Training Loss 0.1918\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [350][550]\t Training Loss 0.2377\t Accuracy 0.9300\n",
      "Epoch [8][10]\t Batch [400][550]\t Training Loss 0.4459\t Accuracy 0.9100\n",
      "Epoch [8][10]\t Batch [450][550]\t Training Loss 0.2337\t Accuracy 0.9400\n",
      "Epoch [8][10]\t Batch [500][550]\t Training Loss 0.1888\t Accuracy 0.9400\n",
      "\n",
      "Epoch [8]\t Average training loss 0.3036\t Average training accuracy 0.9158\n",
      "Epoch [8]\t Average validation loss 0.2424\t Average validation accuracy 0.9346\n",
      "\n",
      "Epoch [9][10]\t Batch [0][550]\t Training Loss 0.2449\t Accuracy 0.9600\n",
      "Epoch [9][10]\t Batch [50][550]\t Training Loss 0.3449\t Accuracy 0.8900\n",
      "Epoch [9][10]\t Batch [100][550]\t Training Loss 0.2432\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [150][550]\t Training Loss 0.2953\t Accuracy 0.9100\n",
      "Epoch [9][10]\t Batch [200][550]\t Training Loss 0.4592\t Accuracy 0.8600\n",
      "Epoch [9][10]\t Batch [250][550]\t Training Loss 0.3834\t Accuracy 0.8800\n",
      "Epoch [9][10]\t Batch [300][550]\t Training Loss 0.1826\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [350][550]\t Training Loss 0.2259\t Accuracy 0.9600\n",
      "Epoch [9][10]\t Batch [400][550]\t Training Loss 0.3200\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [450][550]\t Training Loss 0.2997\t Accuracy 0.9400\n",
      "Epoch [9][10]\t Batch [500][550]\t Training Loss 0.3334\t Accuracy 0.9200\n",
      "\n",
      "Epoch [9]\t Average training loss 0.3005\t Average training accuracy 0.9165\n",
      "Epoch [9]\t Average validation loss 0.2405\t Average validation accuracy 0.9366\n",
      "\n",
      "Epoch [0][10]\t Batch [0][550]\t Training Loss 2.4393\t Accuracy 0.1400\n",
      "Epoch [0][10]\t Batch [50][550]\t Training Loss 0.5521\t Accuracy 0.8200\n",
      "Epoch [0][10]\t Batch [100][550]\t Training Loss 0.4850\t Accuracy 0.8100\n",
      "Epoch [0][10]\t Batch [150][550]\t Training Loss 0.2633\t Accuracy 0.9300\n",
      "Epoch [0][10]\t Batch [200][550]\t Training Loss 0.4330\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [250][550]\t Training Loss 0.1894\t Accuracy 0.9600\n",
      "Epoch [0][10]\t Batch [300][550]\t Training Loss 0.3341\t Accuracy 0.8800\n",
      "Epoch [0][10]\t Batch [350][550]\t Training Loss 0.2997\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [400][550]\t Training Loss 0.5169\t Accuracy 0.8900\n",
      "Epoch [0][10]\t Batch [450][550]\t Training Loss 0.3172\t Accuracy 0.9300\n",
      "Epoch [0][10]\t Batch [500][550]\t Training Loss 0.3169\t Accuracy 0.9200\n",
      "\n",
      "Epoch [0]\t Average training loss 0.4139\t Average training accuracy 0.8801\n",
      "Epoch [0]\t Average validation loss 0.2610\t Average validation accuracy 0.9252\n",
      "\n",
      "Epoch [1][10]\t Batch [0][550]\t Training Loss 0.2005\t Accuracy 0.9600\n",
      "Epoch [1][10]\t Batch [50][550]\t Training Loss 0.3569\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [100][550]\t Training Loss 0.5508\t Accuracy 0.9100\n",
      "Epoch [1][10]\t Batch [150][550]\t Training Loss 0.2205\t Accuracy 0.9300\n",
      "Epoch [1][10]\t Batch [200][550]\t Training Loss 0.2825\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [250][550]\t Training Loss 0.3322\t Accuracy 0.9100\n",
      "Epoch [1][10]\t Batch [300][550]\t Training Loss 0.2580\t Accuracy 0.9100\n",
      "Epoch [1][10]\t Batch [350][550]\t Training Loss 0.2269\t Accuracy 0.9200\n",
      "Epoch [1][10]\t Batch [400][550]\t Training Loss 0.5183\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [450][550]\t Training Loss 0.4113\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [500][550]\t Training Loss 0.3971\t Accuracy 0.9000\n",
      "\n",
      "Epoch [1]\t Average training loss 0.3191\t Average training accuracy 0.9095\n",
      "Epoch [1]\t Average validation loss 0.2486\t Average validation accuracy 0.9324\n",
      "\n",
      "Epoch [2][10]\t Batch [0][550]\t Training Loss 0.1902\t Accuracy 0.9600\n",
      "Epoch [2][10]\t Batch [50][550]\t Training Loss 0.2729\t Accuracy 0.9100\n",
      "Epoch [2][10]\t Batch [100][550]\t Training Loss 0.1545\t Accuracy 0.9600\n",
      "Epoch [2][10]\t Batch [150][550]\t Training Loss 0.3389\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [200][550]\t Training Loss 0.1971\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [250][550]\t Training Loss 0.3019\t Accuracy 0.9300\n",
      "Epoch [2][10]\t Batch [300][550]\t Training Loss 0.3120\t Accuracy 0.9400\n",
      "Epoch [2][10]\t Batch [350][550]\t Training Loss 0.3239\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [400][550]\t Training Loss 0.2992\t Accuracy 0.9400\n",
      "Epoch [2][10]\t Batch [450][550]\t Training Loss 0.3793\t Accuracy 0.8600\n",
      "Epoch [2][10]\t Batch [500][550]\t Training Loss 0.3501\t Accuracy 0.8800\n",
      "\n",
      "Epoch [2]\t Average training loss 0.3045\t Average training accuracy 0.9148\n",
      "Epoch [2]\t Average validation loss 0.2390\t Average validation accuracy 0.9350\n",
      "\n",
      "Epoch [3][10]\t Batch [0][550]\t Training Loss 0.3592\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [50][550]\t Training Loss 0.3588\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [100][550]\t Training Loss 0.3250\t Accuracy 0.8900\n",
      "Epoch [3][10]\t Batch [150][550]\t Training Loss 0.2469\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [200][550]\t Training Loss 0.3257\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [250][550]\t Training Loss 0.3167\t Accuracy 0.9300\n",
      "Epoch [3][10]\t Batch [300][550]\t Training Loss 0.2958\t Accuracy 0.8700\n",
      "Epoch [3][10]\t Batch [350][550]\t Training Loss 0.2872\t Accuracy 0.9300\n",
      "Epoch [3][10]\t Batch [400][550]\t Training Loss 0.4298\t Accuracy 0.8700\n",
      "Epoch [3][10]\t Batch [450][550]\t Training Loss 0.2015\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [500][550]\t Training Loss 0.4287\t Accuracy 0.8900\n",
      "\n",
      "Epoch [3]\t Average training loss 0.2972\t Average training accuracy 0.9171\n",
      "Epoch [3]\t Average validation loss 0.2345\t Average validation accuracy 0.9360\n",
      "\n",
      "Epoch [4][10]\t Batch [0][550]\t Training Loss 0.1684\t Accuracy 0.9400\n",
      "Epoch [4][10]\t Batch [50][550]\t Training Loss 0.2864\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [100][550]\t Training Loss 0.3069\t Accuracy 0.8900\n",
      "Epoch [4][10]\t Batch [150][550]\t Training Loss 0.2608\t Accuracy 0.9200\n",
      "Epoch [4][10]\t Batch [200][550]\t Training Loss 0.2285\t Accuracy 0.9200\n",
      "Epoch [4][10]\t Batch [250][550]\t Training Loss 0.4059\t Accuracy 0.9100\n",
      "Epoch [4][10]\t Batch [300][550]\t Training Loss 0.3945\t Accuracy 0.9200\n",
      "Epoch [4][10]\t Batch [350][550]\t Training Loss 0.2289\t Accuracy 0.9200\n",
      "Epoch [4][10]\t Batch [400][550]\t Training Loss 0.2564\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [450][550]\t Training Loss 0.2590\t Accuracy 0.9300\n",
      "Epoch [4][10]\t Batch [500][550]\t Training Loss 0.2414\t Accuracy 0.9400\n",
      "\n",
      "Epoch [4]\t Average training loss 0.2911\t Average training accuracy 0.9195\n",
      "Epoch [4]\t Average validation loss 0.2333\t Average validation accuracy 0.9380\n",
      "\n",
      "Epoch [5][10]\t Batch [0][550]\t Training Loss 0.2747\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [50][550]\t Training Loss 0.5394\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [100][550]\t Training Loss 0.5586\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [150][550]\t Training Loss 0.2540\t Accuracy 0.9100\n",
      "Epoch [5][10]\t Batch [200][550]\t Training Loss 0.1458\t Accuracy 0.9500\n",
      "Epoch [5][10]\t Batch [250][550]\t Training Loss 0.2165\t Accuracy 0.9600\n",
      "Epoch [5][10]\t Batch [300][550]\t Training Loss 0.3200\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [350][550]\t Training Loss 0.2549\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [400][550]\t Training Loss 0.3290\t Accuracy 0.8700\n",
      "Epoch [5][10]\t Batch [450][550]\t Training Loss 0.3123\t Accuracy 0.9400\n",
      "Epoch [5][10]\t Batch [500][550]\t Training Loss 0.1788\t Accuracy 0.9500\n",
      "\n",
      "Epoch [5]\t Average training loss 0.2870\t Average training accuracy 0.9202\n",
      "Epoch [5]\t Average validation loss 0.2402\t Average validation accuracy 0.9326\n",
      "\n",
      "Epoch [6][10]\t Batch [0][550]\t Training Loss 0.2494\t Accuracy 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6][10]\t Batch [50][550]\t Training Loss 0.2172\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [100][550]\t Training Loss 0.1979\t Accuracy 0.9600\n",
      "Epoch [6][10]\t Batch [150][550]\t Training Loss 0.3863\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [200][550]\t Training Loss 0.2950\t Accuracy 0.9300\n",
      "Epoch [6][10]\t Batch [250][550]\t Training Loss 0.5166\t Accuracy 0.8900\n",
      "Epoch [6][10]\t Batch [300][550]\t Training Loss 0.2809\t Accuracy 0.8800\n",
      "Epoch [6][10]\t Batch [350][550]\t Training Loss 0.3641\t Accuracy 0.9300\n",
      "Epoch [6][10]\t Batch [400][550]\t Training Loss 0.1578\t Accuracy 0.9400\n",
      "Epoch [6][10]\t Batch [450][550]\t Training Loss 0.1974\t Accuracy 0.9200\n",
      "Epoch [6][10]\t Batch [500][550]\t Training Loss 0.2372\t Accuracy 0.9300\n",
      "\n",
      "Epoch [6]\t Average training loss 0.2826\t Average training accuracy 0.9219\n",
      "Epoch [6]\t Average validation loss 0.2298\t Average validation accuracy 0.9376\n",
      "\n",
      "Epoch [7][10]\t Batch [0][550]\t Training Loss 0.3139\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [50][550]\t Training Loss 0.1874\t Accuracy 0.9200\n",
      "Epoch [7][10]\t Batch [100][550]\t Training Loss 0.4217\t Accuracy 0.8600\n",
      "Epoch [7][10]\t Batch [150][550]\t Training Loss 0.1593\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [200][550]\t Training Loss 0.3610\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [250][550]\t Training Loss 0.2227\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [300][550]\t Training Loss 0.2833\t Accuracy 0.9200\n",
      "Epoch [7][10]\t Batch [350][550]\t Training Loss 0.2224\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [400][550]\t Training Loss 0.2156\t Accuracy 0.9100\n",
      "Epoch [7][10]\t Batch [450][550]\t Training Loss 0.3176\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [500][550]\t Training Loss 0.2193\t Accuracy 0.9300\n",
      "\n",
      "Epoch [7]\t Average training loss 0.2805\t Average training accuracy 0.9223\n",
      "Epoch [7]\t Average validation loss 0.2359\t Average validation accuracy 0.9352\n",
      "\n",
      "Epoch [8][10]\t Batch [0][550]\t Training Loss 0.3382\t Accuracy 0.9100\n",
      "Epoch [8][10]\t Batch [50][550]\t Training Loss 0.2334\t Accuracy 0.9300\n",
      "Epoch [8][10]\t Batch [100][550]\t Training Loss 0.4895\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [150][550]\t Training Loss 0.3529\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [200][550]\t Training Loss 0.3787\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [250][550]\t Training Loss 0.3385\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [300][550]\t Training Loss 0.4305\t Accuracy 0.8400\n",
      "Epoch [8][10]\t Batch [350][550]\t Training Loss 0.4879\t Accuracy 0.8700\n",
      "Epoch [8][10]\t Batch [400][550]\t Training Loss 0.3274\t Accuracy 0.8800\n",
      "Epoch [8][10]\t Batch [450][550]\t Training Loss 0.3043\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [500][550]\t Training Loss 0.2436\t Accuracy 0.9100\n",
      "\n",
      "Epoch [8]\t Average training loss 0.2791\t Average training accuracy 0.9227\n",
      "Epoch [8]\t Average validation loss 0.2316\t Average validation accuracy 0.9396\n",
      "\n",
      "Epoch [9][10]\t Batch [0][550]\t Training Loss 0.1544\t Accuracy 0.9700\n",
      "Epoch [9][10]\t Batch [50][550]\t Training Loss 0.3693\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [100][550]\t Training Loss 0.3535\t Accuracy 0.9100\n",
      "Epoch [9][10]\t Batch [150][550]\t Training Loss 0.2615\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [200][550]\t Training Loss 0.5300\t Accuracy 0.8500\n",
      "Epoch [9][10]\t Batch [250][550]\t Training Loss 0.1276\t Accuracy 0.9700\n",
      "Epoch [9][10]\t Batch [300][550]\t Training Loss 0.2459\t Accuracy 0.9600\n",
      "Epoch [9][10]\t Batch [350][550]\t Training Loss 0.2108\t Accuracy 0.9400\n",
      "Epoch [9][10]\t Batch [400][550]\t Training Loss 0.2736\t Accuracy 0.8900\n",
      "Epoch [9][10]\t Batch [450][550]\t Training Loss 0.2029\t Accuracy 0.9300\n",
      "Epoch [9][10]\t Batch [500][550]\t Training Loss 0.2194\t Accuracy 0.9500\n",
      "\n",
      "Epoch [9]\t Average training loss 0.2769\t Average training accuracy 0.9238\n",
      "Epoch [9]\t Average validation loss 0.2297\t Average validation accuracy 0.9380\n",
      "\n",
      "Epoch [0][10]\t Batch [0][550]\t Training Loss 2.5025\t Accuracy 0.0700\n",
      "Epoch [0][10]\t Batch [50][550]\t Training Loss 0.4876\t Accuracy 0.8800\n",
      "Epoch [0][10]\t Batch [100][550]\t Training Loss 0.3109\t Accuracy 0.8800\n",
      "Epoch [0][10]\t Batch [150][550]\t Training Loss 0.2723\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [200][550]\t Training Loss 0.3625\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [250][550]\t Training Loss 0.2524\t Accuracy 0.9300\n",
      "Epoch [0][10]\t Batch [300][550]\t Training Loss 0.3853\t Accuracy 0.9100\n",
      "Epoch [0][10]\t Batch [350][550]\t Training Loss 0.2403\t Accuracy 0.9400\n",
      "Epoch [0][10]\t Batch [400][550]\t Training Loss 0.3588\t Accuracy 0.9100\n",
      "Epoch [0][10]\t Batch [450][550]\t Training Loss 0.4040\t Accuracy 0.8900\n",
      "Epoch [0][10]\t Batch [500][550]\t Training Loss 0.3949\t Accuracy 0.8300\n",
      "\n",
      "Epoch [0]\t Average training loss 0.3878\t Average training accuracy 0.8871\n",
      "Epoch [0]\t Average validation loss 0.2566\t Average validation accuracy 0.9282\n",
      "\n",
      "Epoch [1][10]\t Batch [0][550]\t Training Loss 0.3891\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [50][550]\t Training Loss 0.3822\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [100][550]\t Training Loss 0.1748\t Accuracy 0.9300\n",
      "Epoch [1][10]\t Batch [150][550]\t Training Loss 0.2722\t Accuracy 0.9100\n",
      "Epoch [1][10]\t Batch [200][550]\t Training Loss 0.2314\t Accuracy 0.9400\n",
      "Epoch [1][10]\t Batch [250][550]\t Training Loss 0.1862\t Accuracy 0.9400\n",
      "Epoch [1][10]\t Batch [300][550]\t Training Loss 0.2265\t Accuracy 0.9300\n",
      "Epoch [1][10]\t Batch [350][550]\t Training Loss 0.3701\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [400][550]\t Training Loss 0.4074\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [450][550]\t Training Loss 0.4308\t Accuracy 0.9200\n",
      "Epoch [1][10]\t Batch [500][550]\t Training Loss 0.2923\t Accuracy 0.9400\n",
      "\n",
      "Epoch [1]\t Average training loss 0.3136\t Average training accuracy 0.9117\n",
      "Epoch [1]\t Average validation loss 0.2424\t Average validation accuracy 0.9338\n",
      "\n",
      "Epoch [2][10]\t Batch [0][550]\t Training Loss 0.2014\t Accuracy 0.9300\n",
      "Epoch [2][10]\t Batch [50][550]\t Training Loss 0.3340\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [100][550]\t Training Loss 0.5999\t Accuracy 0.8500\n",
      "Epoch [2][10]\t Batch [150][550]\t Training Loss 0.3566\t Accuracy 0.9100\n",
      "Epoch [2][10]\t Batch [200][550]\t Training Loss 0.2557\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [250][550]\t Training Loss 0.3595\t Accuracy 0.9100\n",
      "Epoch [2][10]\t Batch [300][550]\t Training Loss 0.3131\t Accuracy 0.9300\n",
      "Epoch [2][10]\t Batch [350][550]\t Training Loss 0.4204\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [400][550]\t Training Loss 0.3015\t Accuracy 0.8800\n",
      "Epoch [2][10]\t Batch [450][550]\t Training Loss 0.3496\t Accuracy 0.9100\n",
      "Epoch [2][10]\t Batch [500][550]\t Training Loss 0.2879\t Accuracy 0.8800\n",
      "\n",
      "Epoch [2]\t Average training loss 0.3027\t Average training accuracy 0.9154\n",
      "Epoch [2]\t Average validation loss 0.2426\t Average validation accuracy 0.9334\n",
      "\n",
      "Epoch [3][10]\t Batch [0][550]\t Training Loss 0.3004\t Accuracy 0.9300\n",
      "Epoch [3][10]\t Batch [50][550]\t Training Loss 0.5534\t Accuracy 0.9100\n",
      "Epoch [3][10]\t Batch [100][550]\t Training Loss 0.2450\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [150][550]\t Training Loss 0.2204\t Accuracy 0.9700\n",
      "Epoch [3][10]\t Batch [200][550]\t Training Loss 0.2318\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [250][550]\t Training Loss 0.4377\t Accuracy 0.8700\n",
      "Epoch [3][10]\t Batch [300][550]\t Training Loss 0.4408\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [350][550]\t Training Loss 0.4469\t Accuracy 0.8700\n",
      "Epoch [3][10]\t Batch [400][550]\t Training Loss 0.1635\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [450][550]\t Training Loss 0.4327\t Accuracy 0.9100\n",
      "Epoch [3][10]\t Batch [500][550]\t Training Loss 0.3612\t Accuracy 0.9000\n",
      "\n",
      "Epoch [3]\t Average training loss 0.2964\t Average training accuracy 0.9171\n",
      "Epoch [3]\t Average validation loss 0.2330\t Average validation accuracy 0.9364\n",
      "\n",
      "Epoch [4][10]\t Batch [0][550]\t Training Loss 0.3515\t Accuracy 0.9100\n",
      "Epoch [4][10]\t Batch [50][550]\t Training Loss 0.1307\t Accuracy 0.9600\n",
      "Epoch [4][10]\t Batch [100][550]\t Training Loss 0.1899\t Accuracy 0.9300\n",
      "Epoch [4][10]\t Batch [150][550]\t Training Loss 0.3647\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [200][550]\t Training Loss 0.2583\t Accuracy 0.9100\n",
      "Epoch [4][10]\t Batch [250][550]\t Training Loss 0.3382\t Accuracy 0.8800\n",
      "Epoch [4][10]\t Batch [300][550]\t Training Loss 0.2767\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [350][550]\t Training Loss 0.1727\t Accuracy 0.9300\n",
      "Epoch [4][10]\t Batch [400][550]\t Training Loss 0.2631\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [450][550]\t Training Loss 0.3333\t Accuracy 0.9400\n",
      "Epoch [4][10]\t Batch [500][550]\t Training Loss 0.2759\t Accuracy 0.9300\n",
      "\n",
      "Epoch [4]\t Average training loss 0.2904\t Average training accuracy 0.9191\n",
      "Epoch [4]\t Average validation loss 0.2350\t Average validation accuracy 0.9392\n",
      "\n",
      "Epoch [5][10]\t Batch [0][550]\t Training Loss 0.1622\t Accuracy 0.9500\n",
      "Epoch [5][10]\t Batch [50][550]\t Training Loss 0.4245\t Accuracy 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5][10]\t Batch [100][550]\t Training Loss 0.3612\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [150][550]\t Training Loss 0.2218\t Accuracy 0.9200\n",
      "Epoch [5][10]\t Batch [200][550]\t Training Loss 0.2932\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [250][550]\t Training Loss 0.2465\t Accuracy 0.9400\n",
      "Epoch [5][10]\t Batch [300][550]\t Training Loss 0.2996\t Accuracy 0.9100\n",
      "Epoch [5][10]\t Batch [350][550]\t Training Loss 0.3662\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [400][550]\t Training Loss 0.2764\t Accuracy 0.9200\n",
      "Epoch [5][10]\t Batch [450][550]\t Training Loss 0.1197\t Accuracy 0.9500\n",
      "Epoch [5][10]\t Batch [500][550]\t Training Loss 0.2922\t Accuracy 0.9000\n",
      "\n",
      "Epoch [5]\t Average training loss 0.2888\t Average training accuracy 0.9201\n",
      "Epoch [5]\t Average validation loss 0.2372\t Average validation accuracy 0.9372\n",
      "\n",
      "Epoch [6][10]\t Batch [0][550]\t Training Loss 0.2356\t Accuracy 0.9400\n",
      "Epoch [6][10]\t Batch [50][550]\t Training Loss 0.1629\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [100][550]\t Training Loss 0.1777\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [150][550]\t Training Loss 0.2876\t Accuracy 0.9300\n",
      "Epoch [6][10]\t Batch [200][550]\t Training Loss 0.3947\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [250][550]\t Training Loss 0.1044\t Accuracy 0.9800\n",
      "Epoch [6][10]\t Batch [300][550]\t Training Loss 0.2211\t Accuracy 0.9400\n",
      "Epoch [6][10]\t Batch [350][550]\t Training Loss 0.3191\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [400][550]\t Training Loss 0.1861\t Accuracy 0.9700\n",
      "Epoch [6][10]\t Batch [450][550]\t Training Loss 0.2607\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [500][550]\t Training Loss 0.1855\t Accuracy 0.9400\n",
      "\n",
      "Epoch [6]\t Average training loss 0.2847\t Average training accuracy 0.9211\n",
      "Epoch [6]\t Average validation loss 0.2333\t Average validation accuracy 0.9354\n",
      "\n",
      "Epoch [7][10]\t Batch [0][550]\t Training Loss 0.1949\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [50][550]\t Training Loss 0.4222\t Accuracy 0.9100\n",
      "Epoch [7][10]\t Batch [100][550]\t Training Loss 0.1172\t Accuracy 0.9700\n",
      "Epoch [7][10]\t Batch [150][550]\t Training Loss 0.1192\t Accuracy 0.9700\n",
      "Epoch [7][10]\t Batch [200][550]\t Training Loss 0.3143\t Accuracy 0.9100\n",
      "Epoch [7][10]\t Batch [250][550]\t Training Loss 0.2359\t Accuracy 0.9200\n",
      "Epoch [7][10]\t Batch [300][550]\t Training Loss 0.2039\t Accuracy 0.9300\n",
      "Epoch [7][10]\t Batch [350][550]\t Training Loss 0.3262\t Accuracy 0.9100\n",
      "Epoch [7][10]\t Batch [400][550]\t Training Loss 0.2426\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [450][550]\t Training Loss 0.2773\t Accuracy 0.9600\n",
      "Epoch [7][10]\t Batch [500][550]\t Training Loss 0.2286\t Accuracy 0.9300\n",
      "\n",
      "Epoch [7]\t Average training loss 0.2813\t Average training accuracy 0.9224\n",
      "Epoch [7]\t Average validation loss 0.2358\t Average validation accuracy 0.9356\n",
      "\n",
      "Epoch [8][10]\t Batch [0][550]\t Training Loss 0.4616\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [50][550]\t Training Loss 0.3195\t Accuracy 0.9100\n",
      "Epoch [8][10]\t Batch [100][550]\t Training Loss 0.4594\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [150][550]\t Training Loss 0.2882\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [200][550]\t Training Loss 0.3234\t Accuracy 0.9100\n",
      "Epoch [8][10]\t Batch [250][550]\t Training Loss 0.4520\t Accuracy 0.8700\n",
      "Epoch [8][10]\t Batch [300][550]\t Training Loss 0.2829\t Accuracy 0.9300\n",
      "Epoch [8][10]\t Batch [350][550]\t Training Loss 0.3442\t Accuracy 0.8800\n",
      "Epoch [8][10]\t Batch [400][550]\t Training Loss 0.5365\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [450][550]\t Training Loss 0.3906\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [500][550]\t Training Loss 0.2429\t Accuracy 0.9300\n",
      "\n",
      "Epoch [8]\t Average training loss 0.2800\t Average training accuracy 0.9232\n",
      "Epoch [8]\t Average validation loss 0.2340\t Average validation accuracy 0.9364\n",
      "\n",
      "Epoch [9][10]\t Batch [0][550]\t Training Loss 0.3060\t Accuracy 0.9300\n",
      "Epoch [9][10]\t Batch [50][550]\t Training Loss 0.1725\t Accuracy 0.9600\n",
      "Epoch [9][10]\t Batch [100][550]\t Training Loss 0.3985\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [150][550]\t Training Loss 0.2788\t Accuracy 0.9400\n",
      "Epoch [9][10]\t Batch [200][550]\t Training Loss 0.2560\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [250][550]\t Training Loss 0.2710\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [300][550]\t Training Loss 0.1844\t Accuracy 0.9400\n",
      "Epoch [9][10]\t Batch [350][550]\t Training Loss 0.5731\t Accuracy 0.8800\n",
      "Epoch [9][10]\t Batch [400][550]\t Training Loss 0.2374\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [450][550]\t Training Loss 0.3825\t Accuracy 0.8800\n",
      "Epoch [9][10]\t Batch [500][550]\t Training Loss 0.2960\t Accuracy 0.8800\n",
      "\n",
      "Epoch [9]\t Average training loss 0.2801\t Average training accuracy 0.9226\n",
      "Epoch [9]\t Average validation loss 0.2381\t Average validation accuracy 0.9362\n",
      "\n",
      "Epoch [0][10]\t Batch [0][550]\t Training Loss 2.4300\t Accuracy 0.0500\n",
      "Epoch [0][10]\t Batch [50][550]\t Training Loss 0.9196\t Accuracy 0.8300\n",
      "Epoch [0][10]\t Batch [100][550]\t Training Loss 0.4248\t Accuracy 0.8800\n",
      "Epoch [0][10]\t Batch [150][550]\t Training Loss 0.4418\t Accuracy 0.8700\n",
      "Epoch [0][10]\t Batch [200][550]\t Training Loss 0.3793\t Accuracy 0.8900\n",
      "Epoch [0][10]\t Batch [250][550]\t Training Loss 0.7111\t Accuracy 0.8800\n",
      "Epoch [0][10]\t Batch [300][550]\t Training Loss 0.7536\t Accuracy 0.8300\n",
      "Epoch [0][10]\t Batch [350][550]\t Training Loss 0.4796\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [400][550]\t Training Loss 0.3345\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [450][550]\t Training Loss 0.6583\t Accuracy 0.8400\n",
      "Epoch [0][10]\t Batch [500][550]\t Training Loss 0.2655\t Accuracy 0.9500\n",
      "\n",
      "Epoch [0]\t Average training loss 0.4992\t Average training accuracy 0.8743\n",
      "Epoch [0]\t Average validation loss 0.3236\t Average validation accuracy 0.9194\n",
      "\n",
      "Epoch [1][10]\t Batch [0][550]\t Training Loss 0.7036\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [50][550]\t Training Loss 0.4570\t Accuracy 0.8900\n",
      "Epoch [1][10]\t Batch [100][550]\t Training Loss 0.4339\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [150][550]\t Training Loss 0.4207\t Accuracy 0.8700\n",
      "Epoch [1][10]\t Batch [200][550]\t Training Loss 0.4430\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [250][550]\t Training Loss 0.1529\t Accuracy 0.9600\n",
      "Epoch [1][10]\t Batch [300][550]\t Training Loss 0.2981\t Accuracy 0.9300\n",
      "Epoch [1][10]\t Batch [350][550]\t Training Loss 0.4913\t Accuracy 0.9200\n",
      "Epoch [1][10]\t Batch [400][550]\t Training Loss 0.7466\t Accuracy 0.8600\n",
      "Epoch [1][10]\t Batch [450][550]\t Training Loss 0.6449\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [500][550]\t Training Loss 0.4900\t Accuracy 0.9000\n",
      "\n",
      "Epoch [1]\t Average training loss 0.4431\t Average training accuracy 0.8897\n",
      "Epoch [1]\t Average validation loss 0.3427\t Average validation accuracy 0.9198\n",
      "\n",
      "Epoch [2][10]\t Batch [0][550]\t Training Loss 0.4232\t Accuracy 0.8900\n",
      "Epoch [2][10]\t Batch [50][550]\t Training Loss 0.3584\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [100][550]\t Training Loss 0.3844\t Accuracy 0.9100\n",
      "Epoch [2][10]\t Batch [150][550]\t Training Loss 0.3238\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [200][550]\t Training Loss 0.3425\t Accuracy 0.9300\n",
      "Epoch [2][10]\t Batch [250][550]\t Training Loss 0.6352\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [300][550]\t Training Loss 0.4091\t Accuracy 0.8900\n",
      "Epoch [2][10]\t Batch [350][550]\t Training Loss 0.2322\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [400][550]\t Training Loss 0.2465\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [450][550]\t Training Loss 0.4119\t Accuracy 0.8900\n",
      "Epoch [2][10]\t Batch [500][550]\t Training Loss 0.1511\t Accuracy 0.9800\n",
      "\n",
      "Epoch [2]\t Average training loss 0.4340\t Average training accuracy 0.8952\n",
      "Epoch [2]\t Average validation loss 0.3821\t Average validation accuracy 0.9036\n",
      "\n",
      "Epoch [3][10]\t Batch [0][550]\t Training Loss 0.4197\t Accuracy 0.8800\n",
      "Epoch [3][10]\t Batch [50][550]\t Training Loss 0.5460\t Accuracy 0.8700\n",
      "Epoch [3][10]\t Batch [100][550]\t Training Loss 0.2069\t Accuracy 0.9300\n",
      "Epoch [3][10]\t Batch [150][550]\t Training Loss 0.1992\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [200][550]\t Training Loss 0.2826\t Accuracy 0.9300\n",
      "Epoch [3][10]\t Batch [250][550]\t Training Loss 0.5861\t Accuracy 0.8900\n",
      "Epoch [3][10]\t Batch [300][550]\t Training Loss 0.3519\t Accuracy 0.8900\n",
      "Epoch [3][10]\t Batch [350][550]\t Training Loss 0.3516\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [400][550]\t Training Loss 0.5180\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [450][550]\t Training Loss 0.1737\t Accuracy 0.9700\n",
      "Epoch [3][10]\t Batch [500][550]\t Training Loss 0.4026\t Accuracy 0.9100\n",
      "\n",
      "Epoch [3]\t Average training loss 0.4346\t Average training accuracy 0.8943\n",
      "Epoch [3]\t Average validation loss 0.3136\t Average validation accuracy 0.9236\n",
      "\n",
      "Epoch [4][10]\t Batch [0][550]\t Training Loss 0.3143\t Accuracy 0.9300\n",
      "Epoch [4][10]\t Batch [50][550]\t Training Loss 0.2121\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [100][550]\t Training Loss 0.2621\t Accuracy 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4][10]\t Batch [150][550]\t Training Loss 0.6699\t Accuracy 0.8500\n",
      "Epoch [4][10]\t Batch [200][550]\t Training Loss 0.6569\t Accuracy 0.8500\n",
      "Epoch [4][10]\t Batch [250][550]\t Training Loss 0.2730\t Accuracy 0.9300\n",
      "Epoch [4][10]\t Batch [300][550]\t Training Loss 0.2211\t Accuracy 0.9400\n",
      "Epoch [4][10]\t Batch [350][550]\t Training Loss 0.2980\t Accuracy 0.9300\n",
      "Epoch [4][10]\t Batch [400][550]\t Training Loss 0.2809\t Accuracy 0.9200\n",
      "Epoch [4][10]\t Batch [450][550]\t Training Loss 0.5204\t Accuracy 0.9200\n",
      "Epoch [4][10]\t Batch [500][550]\t Training Loss 0.4237\t Accuracy 0.8700\n",
      "\n",
      "Epoch [4]\t Average training loss 0.4288\t Average training accuracy 0.8957\n",
      "Epoch [4]\t Average validation loss 0.3489\t Average validation accuracy 0.9186\n",
      "\n",
      "Epoch [5][10]\t Batch [0][550]\t Training Loss 0.3582\t Accuracy 0.9100\n",
      "Epoch [5][10]\t Batch [50][550]\t Training Loss 0.3949\t Accuracy 0.9100\n",
      "Epoch [5][10]\t Batch [100][550]\t Training Loss 0.4045\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [150][550]\t Training Loss 0.5237\t Accuracy 0.8600\n",
      "Epoch [5][10]\t Batch [200][550]\t Training Loss 0.3469\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [250][550]\t Training Loss 0.2492\t Accuracy 0.9300\n",
      "Epoch [5][10]\t Batch [300][550]\t Training Loss 0.5510\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [350][550]\t Training Loss 0.5577\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [400][550]\t Training Loss 0.3967\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [450][550]\t Training Loss 0.2923\t Accuracy 0.9300\n",
      "Epoch [5][10]\t Batch [500][550]\t Training Loss 0.7705\t Accuracy 0.8600\n",
      "\n",
      "Epoch [5]\t Average training loss 0.4248\t Average training accuracy 0.8976\n",
      "Epoch [5]\t Average validation loss 0.3918\t Average validation accuracy 0.9070\n",
      "\n",
      "Epoch [6][10]\t Batch [0][550]\t Training Loss 0.2489\t Accuracy 0.9200\n",
      "Epoch [6][10]\t Batch [50][550]\t Training Loss 0.6988\t Accuracy 0.8300\n",
      "Epoch [6][10]\t Batch [100][550]\t Training Loss 0.6745\t Accuracy 0.8700\n",
      "Epoch [6][10]\t Batch [150][550]\t Training Loss 0.4462\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [200][550]\t Training Loss 0.4881\t Accuracy 0.9200\n",
      "Epoch [6][10]\t Batch [250][550]\t Training Loss 0.4459\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [300][550]\t Training Loss 0.1226\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [350][550]\t Training Loss 0.2308\t Accuracy 0.9300\n",
      "Epoch [6][10]\t Batch [400][550]\t Training Loss 0.4398\t Accuracy 0.8500\n",
      "Epoch [6][10]\t Batch [450][550]\t Training Loss 0.5231\t Accuracy 0.8500\n",
      "Epoch [6][10]\t Batch [500][550]\t Training Loss 0.6448\t Accuracy 0.8100\n",
      "\n",
      "Epoch [6]\t Average training loss 0.4282\t Average training accuracy 0.8968\n",
      "Epoch [6]\t Average validation loss 0.3620\t Average validation accuracy 0.9122\n",
      "\n",
      "Epoch [7][10]\t Batch [0][550]\t Training Loss 0.3191\t Accuracy 0.8900\n",
      "Epoch [7][10]\t Batch [50][550]\t Training Loss 0.3818\t Accuracy 0.9100\n",
      "Epoch [7][10]\t Batch [100][550]\t Training Loss 0.5256\t Accuracy 0.9100\n",
      "Epoch [7][10]\t Batch [150][550]\t Training Loss 0.2033\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [200][550]\t Training Loss 0.3357\t Accuracy 0.9100\n",
      "Epoch [7][10]\t Batch [250][550]\t Training Loss 0.2258\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [300][550]\t Training Loss 0.4778\t Accuracy 0.8900\n",
      "Epoch [7][10]\t Batch [350][550]\t Training Loss 0.2293\t Accuracy 0.9300\n",
      "Epoch [7][10]\t Batch [400][550]\t Training Loss 0.4482\t Accuracy 0.8900\n",
      "Epoch [7][10]\t Batch [450][550]\t Training Loss 0.3862\t Accuracy 0.8900\n",
      "Epoch [7][10]\t Batch [500][550]\t Training Loss 0.6482\t Accuracy 0.9000\n",
      "\n",
      "Epoch [7]\t Average training loss 0.4073\t Average training accuracy 0.8992\n",
      "Epoch [7]\t Average validation loss 0.3477\t Average validation accuracy 0.9210\n",
      "\n",
      "Epoch [8][10]\t Batch [0][550]\t Training Loss 0.3274\t Accuracy 0.9100\n",
      "Epoch [8][10]\t Batch [50][550]\t Training Loss 0.5683\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [100][550]\t Training Loss 0.3844\t Accuracy 0.9100\n",
      "Epoch [8][10]\t Batch [150][550]\t Training Loss 0.4385\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [200][550]\t Training Loss 0.5123\t Accuracy 0.8400\n",
      "Epoch [8][10]\t Batch [250][550]\t Training Loss 0.4040\t Accuracy 0.9100\n",
      "Epoch [8][10]\t Batch [300][550]\t Training Loss 0.3390\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [350][550]\t Training Loss 0.4015\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [400][550]\t Training Loss 0.5217\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [450][550]\t Training Loss 0.1778\t Accuracy 0.9600\n",
      "Epoch [8][10]\t Batch [500][550]\t Training Loss 0.4168\t Accuracy 0.9000\n",
      "\n",
      "Epoch [8]\t Average training loss 0.4096\t Average training accuracy 0.9007\n",
      "Epoch [8]\t Average validation loss 0.3405\t Average validation accuracy 0.9178\n",
      "\n",
      "Epoch [9][10]\t Batch [0][550]\t Training Loss 0.4108\t Accuracy 0.8900\n",
      "Epoch [9][10]\t Batch [50][550]\t Training Loss 0.2005\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [100][550]\t Training Loss 0.3749\t Accuracy 0.8600\n",
      "Epoch [9][10]\t Batch [150][550]\t Training Loss 0.4882\t Accuracy 0.8600\n",
      "Epoch [9][10]\t Batch [200][550]\t Training Loss 0.3921\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [250][550]\t Training Loss 0.5229\t Accuracy 0.8800\n",
      "Epoch [9][10]\t Batch [300][550]\t Training Loss 0.2468\t Accuracy 0.9300\n",
      "Epoch [9][10]\t Batch [350][550]\t Training Loss 0.4485\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [400][550]\t Training Loss 0.2224\t Accuracy 0.9400\n",
      "Epoch [9][10]\t Batch [450][550]\t Training Loss 0.6243\t Accuracy 0.8600\n",
      "Epoch [9][10]\t Batch [500][550]\t Training Loss 0.6969\t Accuracy 0.8700\n",
      "\n",
      "Epoch [9]\t Average training loss 0.4083\t Average training accuracy 0.8998\n",
      "Epoch [9]\t Average validation loss 0.3524\t Average validation accuracy 0.9174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    'data_root': 'data',\n",
    "    'max_epoch': 10,\n",
    "    'batch_size': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'momentum': 0.9,\n",
    "    'display_freq': 50,\n",
    "}\n",
    "learning_rates = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "accuracys = []\n",
    "for lr in learning_rates:\n",
    "    cfg['learning_rate'] = lr\n",
    "    runner = Solver(cfg)\n",
    "    runner.train()\n",
    "    test_loss, test_acc = runner.test()\n",
    "    accuracys.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8976999999999999,\n",
       " 0.9169000000000002,\n",
       " 0.9201,\n",
       " 0.9196999999999999,\n",
       " 0.9174,\n",
       " 0.9013]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][10]\t Batch [0][55000]\t Training Loss 3.0806\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [50][55000]\t Training Loss 1.1426\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [100][55000]\t Training Loss 0.1485\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [150][55000]\t Training Loss 7.2383\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [200][55000]\t Training Loss 2.1221\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [250][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [300][55000]\t Training Loss 0.0042\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [350][55000]\t Training Loss 0.2266\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [400][55000]\t Training Loss 0.6116\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [450][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [550][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [650][55000]\t Training Loss 11.9931\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [700][55000]\t Training Loss 0.0228\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [800][55000]\t Training Loss 3.7962\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [850][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [900][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1000][55000]\t Training Loss 0.0458\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1050][55000]\t Training Loss 0.1822\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1100][55000]\t Training Loss 17.0600\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [1150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1200][55000]\t Training Loss 0.7597\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1350][55000]\t Training Loss 1.9170\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [1400][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1450][55000]\t Training Loss 0.0418\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1500][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1550][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1600][55000]\t Training Loss 2.3417\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [1650][55000]\t Training Loss 2.6705\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [1700][55000]\t Training Loss 5.5020\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [1750][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1800][55000]\t Training Loss 0.0041\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1850][55000]\t Training Loss 0.0779\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1900][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1950][55000]\t Training Loss 0.1095\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2100][55000]\t Training Loss 5.7851\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [2150][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2200][55000]\t Training Loss 0.4290\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2300][55000]\t Training Loss 0.0087\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2350][55000]\t Training Loss 3.4109\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [2400][55000]\t Training Loss 0.0119\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2600][55000]\t Training Loss 8.6762\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [2650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2700][55000]\t Training Loss 2.6494\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [2750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2900][55000]\t Training Loss 0.0097\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [2950][55000]\t Training Loss 0.0395\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [3000][55000]\t Training Loss 10.8205\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [3050][55000]\t Training Loss 7.4996\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [3100][55000]\t Training Loss 0.0344\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [3150][55000]\t Training Loss 0.0090\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [3200][55000]\t Training Loss 0.0856\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [3250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [3300][55000]\t Training Loss 2.7089\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [3350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [3400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [3450][55000]\t Training Loss 2.7327\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [3500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [3550][55000]\t Training Loss 0.0418\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [3600][55000]\t Training Loss 0.2107\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [3650][55000]\t Training Loss 0.0027\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [3700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [3750][55000]\t Training Loss 0.0239\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [3800][55000]\t Training Loss 0.2972\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [3850][55000]\t Training Loss 3.1875\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [3900][55000]\t Training Loss 0.7658\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [3950][55000]\t Training Loss 0.0788\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4000][55000]\t Training Loss 0.0168\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4050][55000]\t Training Loss 0.2629\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4150][55000]\t Training Loss 0.0264\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4200][55000]\t Training Loss 0.0411\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4250][55000]\t Training Loss 0.0204\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4300][55000]\t Training Loss 0.7831\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [4350][55000]\t Training Loss 0.0174\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4400][55000]\t Training Loss 0.0204\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4450][55000]\t Training Loss 1.6977\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [4500][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4650][55000]\t Training Loss 0.0396\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4700][55000]\t Training Loss 0.0299\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4750][55000]\t Training Loss 0.0771\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4800][55000]\t Training Loss 0.1034\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4850][55000]\t Training Loss 0.0145\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [4950][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5000][55000]\t Training Loss 0.0690\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5050][55000]\t Training Loss 0.2816\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5100][55000]\t Training Loss 1.4631\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [5150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5250][55000]\t Training Loss 0.5969\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5300][55000]\t Training Loss 1.0192\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [5350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5400][55000]\t Training Loss 2.5517\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [5450][55000]\t Training Loss 6.7670\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [5500][55000]\t Training Loss 0.0852\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5550][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5600][55000]\t Training Loss 0.0036\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5650][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5700][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5750][55000]\t Training Loss 0.0113\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5800][55000]\t Training Loss 0.0094\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5900][55000]\t Training Loss 0.5954\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [5950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6050][55000]\t Training Loss 13.4510\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [6100][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][10]\t Batch [6300][55000]\t Training Loss 0.0079\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6450][55000]\t Training Loss 0.0265\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6500][55000]\t Training Loss 0.0907\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6550][55000]\t Training Loss 0.0563\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6600][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6650][55000]\t Training Loss 1.3130\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [6700][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6800][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6850][55000]\t Training Loss 2.1998\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [6900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [6950][55000]\t Training Loss 1.6457\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [7000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7050][55000]\t Training Loss 1.7142\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [7100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7200][55000]\t Training Loss 0.0041\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7350][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7500][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7650][55000]\t Training Loss 4.9743\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [7700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7750][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7800][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7850][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7900][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [7950][55000]\t Training Loss 0.0046\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8000][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8100][55000]\t Training Loss 0.0207\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8150][55000]\t Training Loss 1.8372\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [8200][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8250][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8300][55000]\t Training Loss 0.2400\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8350][55000]\t Training Loss 0.0582\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8400][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8450][55000]\t Training Loss 0.8632\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [8500][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8600][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8650][55000]\t Training Loss 0.0072\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8750][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8800][55000]\t Training Loss 0.5709\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8900][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [8950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [9000][55000]\t Training Loss 2.7993\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [9050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [9100][55000]\t Training Loss 12.4587\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [9150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [9200][55000]\t Training Loss 3.1422\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [9250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [9300][55000]\t Training Loss 3.9501\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [9350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [9400][55000]\t Training Loss 0.2102\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [9450][55000]\t Training Loss 0.0035\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [9500][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [9550][55000]\t Training Loss 14.3543\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [9600][55000]\t Training Loss 12.7945\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [9650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [9700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [9750][55000]\t Training Loss 0.2132\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [9800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [9850][55000]\t Training Loss 10.5341\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [9900][55000]\t Training Loss 0.3830\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [9950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10050][55000]\t Training Loss 0.0041\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10200][55000]\t Training Loss 0.0342\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10250][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10500][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10550][55000]\t Training Loss 11.4298\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [10600][55000]\t Training Loss 0.1259\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10650][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10800][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [10950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11000][55000]\t Training Loss 0.0050\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11250][55000]\t Training Loss 8.1677\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [11300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11350][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11400][55000]\t Training Loss 3.1143\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [11450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11500][55000]\t Training Loss 0.3913\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11600][55000]\t Training Loss 11.2774\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [11650][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11700][55000]\t Training Loss 0.0760\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11750][55000]\t Training Loss 0.0065\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [11950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12000][55000]\t Training Loss 0.0951\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12050][55000]\t Training Loss 0.0051\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12100][55000]\t Training Loss 0.4928\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12200][55000]\t Training Loss 0.0045\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12250][55000]\t Training Loss 0.8407\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [12300][55000]\t Training Loss 8.1643\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [12350][55000]\t Training Loss 3.1453\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][10]\t Batch [12400][55000]\t Training Loss 0.0509\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12500][55000]\t Training Loss 0.0031\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12550][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12600][55000]\t Training Loss 0.0121\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12750][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12850][55000]\t Training Loss 8.5348\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [12900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [12950][55000]\t Training Loss 0.0056\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13050][55000]\t Training Loss 0.0192\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13100][55000]\t Training Loss 0.0034\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13200][55000]\t Training Loss 8.8073\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [13250][55000]\t Training Loss 0.0078\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13350][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13550][55000]\t Training Loss 0.2810\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13600][55000]\t Training Loss 0.5498\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13750][55000]\t Training Loss 0.1252\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13800][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [13950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14000][55000]\t Training Loss 0.0533\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14050][55000]\t Training Loss 0.0086\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14150][55000]\t Training Loss 0.0130\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14200][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14350][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14400][55000]\t Training Loss 0.0482\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14450][55000]\t Training Loss 0.1880\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14500][55000]\t Training Loss 0.0150\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14650][55000]\t Training Loss 1.2137\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [14700][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14800][55000]\t Training Loss 0.0081\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14850][55000]\t Training Loss 0.0505\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [14900][55000]\t Training Loss 29.9526\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [14950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [15000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [15050][55000]\t Training Loss 0.0134\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [15100][55000]\t Training Loss 3.1135\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [15150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [15200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [15250][55000]\t Training Loss 8.0833\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [15300][55000]\t Training Loss 4.5244\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [15350][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [15400][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [15450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [15500][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [15550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [15600][55000]\t Training Loss 6.2036\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [15650][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [15700][55000]\t Training Loss 0.0695\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [15750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [15800][55000]\t Training Loss 0.0554\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [15850][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [15900][55000]\t Training Loss 2.4637\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [15950][55000]\t Training Loss 0.0056\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [16000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [16050][55000]\t Training Loss 0.8702\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [16100][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [16150][55000]\t Training Loss 5.0578\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [16200][55000]\t Training Loss 0.0048\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [16250][55000]\t Training Loss 1.4459\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [16300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [16350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [16400][55000]\t Training Loss 0.0050\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [16450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [16500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [16550][55000]\t Training Loss 0.0070\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [16600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [16650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [16700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [16750][55000]\t Training Loss 7.1510\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [16800][55000]\t Training Loss 9.5395\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [16850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [16900][55000]\t Training Loss 0.0918\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [16950][55000]\t Training Loss 14.5718\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [17000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17050][55000]\t Training Loss 0.0246\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17100][55000]\t Training Loss 0.0151\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17200][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17650][55000]\t Training Loss 0.0101\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17700][55000]\t Training Loss 0.0291\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17750][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17900][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [17950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18100][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18150][55000]\t Training Loss 0.1615\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18250][55000]\t Training Loss 9.4952\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [18300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18400][55000]\t Training Loss 0.0216\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18450][55000]\t Training Loss 3.1559\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][10]\t Batch [18500][55000]\t Training Loss 0.1156\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18550][55000]\t Training Loss 8.8812\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [18600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18850][55000]\t Training Loss 5.5188\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [18900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [18950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19050][55000]\t Training Loss 0.0150\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19200][55000]\t Training Loss 0.0086\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19250][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19300][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19350][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19400][55000]\t Training Loss 6.0366\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [19450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19550][55000]\t Training Loss 0.0148\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19700][55000]\t Training Loss 0.0216\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19800][55000]\t Training Loss 0.0029\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19850][55000]\t Training Loss 0.0254\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [19950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20050][55000]\t Training Loss 17.7170\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [20100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20200][55000]\t Training Loss 0.0048\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20300][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20450][55000]\t Training Loss 0.2372\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20550][55000]\t Training Loss 20.7093\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [20600][55000]\t Training Loss 7.8418\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [20650][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20800][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20900][55000]\t Training Loss 0.0837\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [20950][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21050][55000]\t Training Loss 0.0064\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21100][55000]\t Training Loss 0.0031\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21300][55000]\t Training Loss 3.4891\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [21350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21600][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21650][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21750][55000]\t Training Loss 0.0185\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21800][55000]\t Training Loss 0.5134\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21850][55000]\t Training Loss 0.4833\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [21950][55000]\t Training Loss 2.2623\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [22000][55000]\t Training Loss 10.2322\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [22050][55000]\t Training Loss 0.0111\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [22100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [22150][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [22200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [22250][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [22300][55000]\t Training Loss 0.0383\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [22350][55000]\t Training Loss 0.0423\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [22400][55000]\t Training Loss 0.0106\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [22450][55000]\t Training Loss 1.6256\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [22500][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [22550][55000]\t Training Loss 7.4835\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [22600][55000]\t Training Loss 0.0052\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [22650][55000]\t Training Loss 18.6731\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [22700][55000]\t Training Loss 0.4942\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [22750][55000]\t Training Loss 14.0938\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [22800][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [22850][55000]\t Training Loss 7.9475\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [22900][55000]\t Training Loss 0.2249\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [22950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23000][55000]\t Training Loss 0.0818\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23100][55000]\t Training Loss 1.1897\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [23150][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23200][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23300][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23400][55000]\t Training Loss 0.0257\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23500][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23550][55000]\t Training Loss 4.9913\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [23600][55000]\t Training Loss 1.0981\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [23650][55000]\t Training Loss 1.5544\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [23700][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23800][55000]\t Training Loss 0.0050\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23900][55000]\t Training Loss 0.2093\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [23950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24000][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24100][55000]\t Training Loss 0.0521\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24200][55000]\t Training Loss 0.0029\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24300][55000]\t Training Loss 0.3468\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24450][55000]\t Training Loss 0.0274\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24500][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24550][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24600][55000]\t Training Loss 0.5346\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24650][55000]\t Training Loss 0.2995\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24750][55000]\t Training Loss 3.9315\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][10]\t Batch [24800][55000]\t Training Loss 9.1344\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [24850][55000]\t Training Loss 2.5285\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [24900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [24950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25200][55000]\t Training Loss 3.9069\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [25250][55000]\t Training Loss 3.4620\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [25300][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25350][55000]\t Training Loss 0.0422\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25400][55000]\t Training Loss 0.0179\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25500][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25750][55000]\t Training Loss 0.0265\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [25950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26100][55000]\t Training Loss 0.0378\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26150][55000]\t Training Loss 0.0769\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26300][55000]\t Training Loss 0.7698\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26400][55000]\t Training Loss 0.0310\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26600][55000]\t Training Loss 0.2062\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26750][55000]\t Training Loss 0.3050\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [26900][55000]\t Training Loss 0.8325\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [26950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27050][55000]\t Training Loss 0.0744\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27100][55000]\t Training Loss 0.0414\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27200][55000]\t Training Loss 0.0145\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27250][55000]\t Training Loss 0.1141\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27300][55000]\t Training Loss 0.2973\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27400][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27500][55000]\t Training Loss 7.6597\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [27550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27700][55000]\t Training Loss 7.7981\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [27750][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27800][55000]\t Training Loss 1.4808\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [27850][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [27950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28000][55000]\t Training Loss 8.7155\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [28050][55000]\t Training Loss 7.2212\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [28100][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28200][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28300][55000]\t Training Loss 0.0040\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28500][55000]\t Training Loss 8.0125\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [28550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28600][55000]\t Training Loss 0.0051\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28650][55000]\t Training Loss 0.4699\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28700][55000]\t Training Loss 2.1369\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [28750][55000]\t Training Loss 0.0042\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [28950][55000]\t Training Loss 1.9512\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [29000][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [29050][55000]\t Training Loss 0.0731\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [29100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [29150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [29200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [29250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [29300][55000]\t Training Loss 0.2714\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [29350][55000]\t Training Loss 2.2759\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [29400][55000]\t Training Loss 0.7886\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [29450][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [29500][55000]\t Training Loss 0.0066\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [29550][55000]\t Training Loss 8.3581\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [29600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [29650][55000]\t Training Loss 0.0029\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [29700][55000]\t Training Loss 0.1885\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [29750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [29800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [29850][55000]\t Training Loss 7.1229\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [29900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [29950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30000][55000]\t Training Loss 5.9364\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [30050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30100][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30250][55000]\t Training Loss 0.0285\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30300][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30400][55000]\t Training Loss 0.9525\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [30450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30550][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30600][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30650][55000]\t Training Loss 0.4548\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30900][55000]\t Training Loss 0.0057\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [30950][55000]\t Training Loss 0.0199\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [31000][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][10]\t Batch [31050][55000]\t Training Loss 3.8361\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [31100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [31150][55000]\t Training Loss 0.4662\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [31200][55000]\t Training Loss 4.3147\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [31250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [31300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [31350][55000]\t Training Loss 0.3369\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [31400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [31450][55000]\t Training Loss 3.1134\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [31500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [31550][55000]\t Training Loss 0.0418\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [31600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [31650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [31700][55000]\t Training Loss 1.5108\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [31750][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [31800][55000]\t Training Loss 0.0642\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [31850][55000]\t Training Loss 0.4305\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [31900][55000]\t Training Loss 0.0743\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [31950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32000][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32050][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32150][55000]\t Training Loss 0.2893\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32350][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32400][55000]\t Training Loss 0.0226\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32450][55000]\t Training Loss 0.2281\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32700][55000]\t Training Loss 0.6472\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [32950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33050][55000]\t Training Loss 0.4206\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33200][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33250][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33300][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33350][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33500][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33650][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33850][55000]\t Training Loss 2.7048\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [33900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [33950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34000][55000]\t Training Loss 0.0776\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34100][55000]\t Training Loss 0.0862\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34150][55000]\t Training Loss 0.0048\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34250][55000]\t Training Loss 14.3464\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [34300][55000]\t Training Loss 0.0063\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34400][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34500][55000]\t Training Loss 0.0047\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34550][55000]\t Training Loss 0.0039\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34700][55000]\t Training Loss 0.0972\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34800][55000]\t Training Loss 14.2069\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [34850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [34950][55000]\t Training Loss 0.3738\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35050][55000]\t Training Loss 0.0366\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35150][55000]\t Training Loss 0.1942\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35250][55000]\t Training Loss 0.5447\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35400][55000]\t Training Loss 0.0645\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35500][55000]\t Training Loss 0.1802\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35600][55000]\t Training Loss 9.8988\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [35650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35700][55000]\t Training Loss 0.0147\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35750][55000]\t Training Loss 2.9826\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [35800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [35900][55000]\t Training Loss 3.5279\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [35950][55000]\t Training Loss 0.1693\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36000][55000]\t Training Loss 0.0028\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36250][55000]\t Training Loss 0.0257\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36300][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36400][55000]\t Training Loss 7.2965\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [36450][55000]\t Training Loss 21.3191\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [36500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36600][55000]\t Training Loss 0.0160\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36650][55000]\t Training Loss 0.0590\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36800][55000]\t Training Loss 0.4826\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36850][55000]\t Training Loss 0.0035\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36900][55000]\t Training Loss 0.0059\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [36950][55000]\t Training Loss 6.3285\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [37000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [37050][55000]\t Training Loss 8.7505\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [37100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [37150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [37200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [37250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][10]\t Batch [37300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [37350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [37400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [37450][55000]\t Training Loss 4.3237\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [37500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [37550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [37600][55000]\t Training Loss 0.1456\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [37650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [37700][55000]\t Training Loss 0.1625\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [37750][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [37800][55000]\t Training Loss 2.9682\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [37850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [37900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [37950][55000]\t Training Loss 1.5535\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [38000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38150][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38450][55000]\t Training Loss 0.0062\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38500][55000]\t Training Loss 11.6750\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [38550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38600][55000]\t Training Loss 3.5530\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [38650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38700][55000]\t Training Loss 0.4992\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38750][55000]\t Training Loss 0.0277\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38800][55000]\t Training Loss 3.2878\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [38850][55000]\t Training Loss 0.0075\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [38950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [39000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [39050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [39100][55000]\t Training Loss 0.0131\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [39150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [39200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [39250][55000]\t Training Loss 0.0344\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [39300][55000]\t Training Loss 0.8578\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [39350][55000]\t Training Loss 2.4316\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [39400][55000]\t Training Loss 6.3845\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [39450][55000]\t Training Loss 1.8549\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [39500][55000]\t Training Loss 1.8243\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [39550][55000]\t Training Loss 0.7143\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [39600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [39650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [39700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [39750][55000]\t Training Loss 1.1687\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [39800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [39850][55000]\t Training Loss 0.6636\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [39900][55000]\t Training Loss 0.0079\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [39950][55000]\t Training Loss 0.0140\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40000][55000]\t Training Loss 4.0525\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [40050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40100][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40400][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40550][55000]\t Training Loss 0.0442\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40600][55000]\t Training Loss 0.0510\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40800][55000]\t Training Loss 0.0304\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40850][55000]\t Training Loss 0.3920\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40900][55000]\t Training Loss 0.0087\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [40950][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41050][55000]\t Training Loss 0.0041\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41150][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41400][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41450][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41500][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41550][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41600][55000]\t Training Loss 0.0035\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41650][55000]\t Training Loss 5.7950\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [41700][55000]\t Training Loss 0.0262\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41750][55000]\t Training Loss 0.0263\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41800][55000]\t Training Loss 26.9557\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [41850][55000]\t Training Loss 2.1676\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [41900][55000]\t Training Loss 0.0140\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [41950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42000][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42150][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42250][55000]\t Training Loss 4.4081\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [42300][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42400][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42500][55000]\t Training Loss 6.8156\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [42550][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42800][55000]\t Training Loss 0.0383\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42900][55000]\t Training Loss 0.0145\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [42950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [43000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [43050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [43100][55000]\t Training Loss 6.6681\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [43150][55000]\t Training Loss 0.0028\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [43200][55000]\t Training Loss 2.6385\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [43250][55000]\t Training Loss 0.0232\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [43300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [43350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [43400][55000]\t Training Loss 0.0036\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][10]\t Batch [43450][55000]\t Training Loss 2.6712\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [43500][55000]\t Training Loss 1.1796\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [43550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [43600][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [43650][55000]\t Training Loss 4.3197\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [43700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [43750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [43800][55000]\t Training Loss 2.3731\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [43850][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [43900][55000]\t Training Loss 0.0034\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [43950][55000]\t Training Loss 0.0057\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44000][55000]\t Training Loss 0.0051\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44050][55000]\t Training Loss 6.7989\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [44100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44200][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44250][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44400][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44550][55000]\t Training Loss 0.0136\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44600][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44650][55000]\t Training Loss 0.0086\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44700][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44750][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [44950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45100][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45150][55000]\t Training Loss 0.0427\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45250][55000]\t Training Loss 0.2540\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45350][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45400][55000]\t Training Loss 0.1218\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45450][55000]\t Training Loss 4.8440\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [45500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45550][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45650][55000]\t Training Loss 0.0075\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45850][55000]\t Training Loss 0.1948\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [45950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46050][55000]\t Training Loss 0.4145\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46100][55000]\t Training Loss 0.3121\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46150][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46300][55000]\t Training Loss 0.2826\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46350][55000]\t Training Loss 0.0298\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46400][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46450][55000]\t Training Loss 2.6787\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [46500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46550][55000]\t Training Loss 0.0036\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46600][55000]\t Training Loss 0.0197\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46750][55000]\t Training Loss 0.0236\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46900][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [46950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47200][55000]\t Training Loss 0.4470\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47250][55000]\t Training Loss 0.1659\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47350][55000]\t Training Loss 0.0264\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47400][55000]\t Training Loss 14.7185\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [47450][55000]\t Training Loss 0.2213\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47550][55000]\t Training Loss 0.0267\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47650][55000]\t Training Loss 0.0163\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47800][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47850][55000]\t Training Loss 0.0095\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47900][55000]\t Training Loss 0.0378\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [47950][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48000][55000]\t Training Loss 0.7662\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [48050][55000]\t Training Loss 1.3814\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [48100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48150][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48550][55000]\t Training Loss 0.1901\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48700][55000]\t Training Loss 0.2072\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48750][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48850][55000]\t Training Loss 4.5609\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [48900][55000]\t Training Loss 0.0773\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [48950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [49000][55000]\t Training Loss 5.6516\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [49050][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [49100][55000]\t Training Loss 6.5132\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [49150][55000]\t Training Loss 2.2698\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [49200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [49250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [49300][55000]\t Training Loss 0.0132\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [49350][55000]\t Training Loss 1.2777\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [49400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [49450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][10]\t Batch [49500][55000]\t Training Loss 4.6140\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [49550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [49600][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [49650][55000]\t Training Loss 5.4643\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [49700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [49750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [49800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [49850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [49900][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [49950][55000]\t Training Loss 6.5101\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [50000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50500][55000]\t Training Loss 1.6913\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [50550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50600][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50650][55000]\t Training Loss 0.1896\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50750][55000]\t Training Loss 2.7303\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [50800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50850][55000]\t Training Loss 32.4381\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [50900][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [50950][55000]\t Training Loss 12.0137\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [51000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51050][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51150][55000]\t Training Loss 0.0070\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51300][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51350][55000]\t Training Loss 0.0525\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51450][55000]\t Training Loss 0.0028\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51550][55000]\t Training Loss 0.5934\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51600][55000]\t Training Loss 1.3766\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [51650][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51750][55000]\t Training Loss 0.4569\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51800][55000]\t Training Loss 0.0755\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [51950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52000][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52050][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52100][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52150][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52200][55000]\t Training Loss 0.0042\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52350][55000]\t Training Loss 13.4096\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [52400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52500][55000]\t Training Loss 0.0286\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52550][55000]\t Training Loss 0.5638\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52600][55000]\t Training Loss 0.0889\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52650][55000]\t Training Loss 6.8818\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [52700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52750][55000]\t Training Loss 0.0743\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52800][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [52950][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53050][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53200][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53350][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53450][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53500][55000]\t Training Loss 8.6737\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [53550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53600][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [53950][55000]\t Training Loss 0.1605\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54000][55000]\t Training Loss 0.3615\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54050][55000]\t Training Loss 11.0637\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [54100][55000]\t Training Loss 11.0523\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [54150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54300][55000]\t Training Loss 0.6181\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54450][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54550][55000]\t Training Loss 2.8501\t Accuracy 0.0000\n",
      "Epoch [0][10]\t Batch [54600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54800][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [54950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [0]\t Average training loss 0.7979\t Average training accuracy 0.8581\n",
      "Epoch [0]\t Average validation loss 0.5498\t Average validation accuracy 0.9090\n",
      "\n",
      "Epoch [1][10]\t Batch [0][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [200][55000]\t Training Loss 0.0377\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [250][55000]\t Training Loss 27.4056\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [300][55000]\t Training Loss 0.0663\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [350][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [400][55000]\t Training Loss 0.0063\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [500][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [600][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [650][55000]\t Training Loss 1.0049\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [750][55000]\t Training Loss 7.8564\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [950][55000]\t Training Loss 0.6623\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1300][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1450][55000]\t Training Loss 1.7037\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [1500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1600][55000]\t Training Loss 2.7203\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [1650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1800][55000]\t Training Loss 2.8594\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [1850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2050][55000]\t Training Loss 0.0227\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2200][55000]\t Training Loss 0.6047\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2250][55000]\t Training Loss 0.6561\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2400][55000]\t Training Loss 0.0110\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2500][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2750][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2800][55000]\t Training Loss 0.0884\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2850][55000]\t Training Loss 0.0300\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2900][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3300][55000]\t Training Loss 0.1840\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3750][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3850][55000]\t Training Loss 0.0063\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [3950][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4350][55000]\t Training Loss 2.6044\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [4400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4450][55000]\t Training Loss 0.0256\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4500][55000]\t Training Loss 2.7107\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [4550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4600][55000]\t Training Loss 2.5800\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [4650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4700][55000]\t Training Loss 4.6080\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [4750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [4950][55000]\t Training Loss 0.0395\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5100][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5150][55000]\t Training Loss 0.2439\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5350][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5400][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1][10]\t Batch [5500][55000]\t Training Loss 2.7280\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [5550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5700][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [5950][55000]\t Training Loss 0.0029\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [6000][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [6050][55000]\t Training Loss 0.0067\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [6100][55000]\t Training Loss 0.0160\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [6150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [6200][55000]\t Training Loss 0.1780\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [6250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [6300][55000]\t Training Loss 0.0065\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [6350][55000]\t Training Loss 0.0214\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [6400][55000]\t Training Loss 5.4143\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [6450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [6500][55000]\t Training Loss 0.7241\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [6550][55000]\t Training Loss 0.8525\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [6600][55000]\t Training Loss 2.3615\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [6650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [6700][55000]\t Training Loss 0.1377\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [6750][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [6800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [6850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [6900][55000]\t Training Loss 7.6263\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [6950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7200][55000]\t Training Loss 0.4258\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7350][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7450][55000]\t Training Loss 5.7204\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [7500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7650][55000]\t Training Loss 0.0024\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7850][55000]\t Training Loss 0.0039\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [7950][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8000][55000]\t Training Loss 0.1394\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8150][55000]\t Training Loss 0.0149\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8200][55000]\t Training Loss 2.4519\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [8250][55000]\t Training Loss 0.0080\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8350][55000]\t Training Loss 0.3978\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8400][55000]\t Training Loss 0.4658\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8450][55000]\t Training Loss 1.3651\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [8500][55000]\t Training Loss 0.0127\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8700][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8800][55000]\t Training Loss 16.8378\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [8850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [8950][55000]\t Training Loss 3.8339\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [9000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9150][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9200][55000]\t Training Loss 0.3839\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9450][55000]\t Training Loss 0.4880\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9700][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9900][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [9950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10050][55000]\t Training Loss 2.5196\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [10100][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10300][55000]\t Training Loss 1.0092\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [10350][55000]\t Training Loss 0.0039\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10400][55000]\t Training Loss 0.0053\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10450][55000]\t Training Loss 0.1521\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10500][55000]\t Training Loss 0.1455\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10550][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10600][55000]\t Training Loss 0.9649\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [10650][55000]\t Training Loss 0.1196\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10800][55000]\t Training Loss 0.1947\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10850][55000]\t Training Loss 8.4475\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [10900][55000]\t Training Loss 0.0140\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [10950][55000]\t Training Loss 0.5490\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [11000][55000]\t Training Loss 1.7838\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [11050][55000]\t Training Loss 4.9751\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [11100][55000]\t Training Loss 0.0050\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [11150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [11200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [11250][55000]\t Training Loss 0.0171\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [11300][55000]\t Training Loss 11.4582\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [11350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [11400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1][10]\t Batch [11450][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [11500][55000]\t Training Loss 0.0284\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [11550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [11600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [11650][55000]\t Training Loss 23.9291\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [11700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [11750][55000]\t Training Loss 0.0672\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [11800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [11850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [11900][55000]\t Training Loss 2.3731\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [11950][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12000][55000]\t Training Loss 0.0344\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12100][55000]\t Training Loss 0.0065\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12200][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12250][55000]\t Training Loss 1.8822\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [12300][55000]\t Training Loss 0.1562\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12400][55000]\t Training Loss 0.9089\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [12450][55000]\t Training Loss 8.5143\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [12500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12650][55000]\t Training Loss 6.2567\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [12700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12800][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12850][55000]\t Training Loss 0.0090\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [12950][55000]\t Training Loss 0.0576\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13000][55000]\t Training Loss 3.0833\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [13050][55000]\t Training Loss 5.5698\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [13100][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13150][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13200][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13300][55000]\t Training Loss 0.1540\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13350][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13650][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13800][55000]\t Training Loss 3.7728\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [13850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [13900][55000]\t Training Loss 2.0077\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [13950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14050][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14100][55000]\t Training Loss 9.4873\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [14150][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14250][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14550][55000]\t Training Loss 11.6842\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [14600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14650][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14700][55000]\t Training Loss 3.7705\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [14750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14800][55000]\t Training Loss 0.0131\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14900][55000]\t Training Loss 0.2411\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [14950][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15100][55000]\t Training Loss 11.9257\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [15150][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15200][55000]\t Training Loss 7.4074\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [15250][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15400][55000]\t Training Loss 7.7257\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [15450][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15650][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15850][55000]\t Training Loss 0.0361\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [15950][55000]\t Training Loss 3.0488\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [16000][55000]\t Training Loss 3.0891\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [16050][55000]\t Training Loss 0.0423\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [16100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [16150][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [16200][55000]\t Training Loss 1.6882\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [16250][55000]\t Training Loss 1.1067\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [16300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [16350][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [16400][55000]\t Training Loss 2.2609\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [16450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [16500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [16550][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [16600][55000]\t Training Loss 0.1007\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [16650][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [16700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [16750][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [16800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [16850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [16900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [16950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17000][55000]\t Training Loss 0.0144\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17100][55000]\t Training Loss 0.3155\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17200][55000]\t Training Loss 0.0047\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17400][55000]\t Training Loss 9.6056\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [17450][55000]\t Training Loss 0.0069\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17500][55000]\t Training Loss 0.7002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17550][55000]\t Training Loss 0.0121\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17700][55000]\t Training Loss 0.0059\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1][10]\t Batch [17750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17800][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [17950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18000][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18050][55000]\t Training Loss 0.0073\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18150][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18200][55000]\t Training Loss 3.7370\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [18250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18300][55000]\t Training Loss 0.0637\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18350][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18550][55000]\t Training Loss 2.5968\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [18600][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18650][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18800][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [18950][55000]\t Training Loss 4.9509\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [19000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [19050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [19100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [19150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [19200][55000]\t Training Loss 0.0852\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [19250][55000]\t Training Loss 0.0134\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [19300][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [19350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [19400][55000]\t Training Loss 1.4504\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [19450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [19500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [19550][55000]\t Training Loss 0.1429\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [19600][55000]\t Training Loss 4.4285\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [19650][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [19700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [19750][55000]\t Training Loss 4.3942\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [19800][55000]\t Training Loss 3.8751\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [19850][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [19900][55000]\t Training Loss 0.1000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [19950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20050][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20150][55000]\t Training Loss 0.0028\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20350][55000]\t Training Loss 1.0014\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [20400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20550][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20750][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20850][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [20950][55000]\t Training Loss 0.0184\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21050][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21100][55000]\t Training Loss 12.4867\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [21150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21250][55000]\t Training Loss 0.0098\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21300][55000]\t Training Loss 8.3918\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [21350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21500][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21600][55000]\t Training Loss 0.2406\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21650][55000]\t Training Loss 0.5775\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21900][55000]\t Training Loss 0.5105\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [21950][55000]\t Training Loss 0.0307\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22050][55000]\t Training Loss 0.0136\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22150][55000]\t Training Loss 0.0232\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22250][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22300][55000]\t Training Loss 10.9604\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [22350][55000]\t Training Loss 0.0620\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22450][55000]\t Training Loss 0.0310\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22600][55000]\t Training Loss 1.4631\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [22650][55000]\t Training Loss 0.0127\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22850][55000]\t Training Loss 0.6145\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22900][55000]\t Training Loss 0.0074\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [22950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23000][55000]\t Training Loss 3.8074\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [23050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23150][55000]\t Training Loss 7.4165\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [23200][55000]\t Training Loss 1.0132\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [23250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23500][55000]\t Training Loss 1.2249\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [23550][55000]\t Training Loss 0.0182\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23600][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23650][55000]\t Training Loss 0.0097\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23700][55000]\t Training Loss 0.0159\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [23950][55000]\t Training Loss 0.0055\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1][10]\t Batch [24050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24150][55000]\t Training Loss 0.0051\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24200][55000]\t Training Loss 10.5701\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [24250][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24300][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24350][55000]\t Training Loss 3.2931\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [24400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24450][55000]\t Training Loss 0.0159\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24600][55000]\t Training Loss 0.0295\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [24950][55000]\t Training Loss 1.2302\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [25000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25100][55000]\t Training Loss 6.6348\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [25150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25200][55000]\t Training Loss 0.0319\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25250][55000]\t Training Loss 8.3785\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [25300][55000]\t Training Loss 0.0036\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25550][55000]\t Training Loss 0.0038\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25650][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25850][55000]\t Training Loss 7.9099\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [25900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [25950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26100][55000]\t Training Loss 0.0150\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26250][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26350][55000]\t Training Loss 0.0259\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26500][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26550][55000]\t Training Loss 0.0368\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26700][55000]\t Training Loss 10.8415\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [26750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [26900][55000]\t Training Loss 6.0679\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [26950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27300][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27400][55000]\t Training Loss 3.9327\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [27450][55000]\t Training Loss 0.0040\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27550][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27650][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27900][55000]\t Training Loss 0.0080\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [27950][55000]\t Training Loss 0.0081\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28000][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28250][55000]\t Training Loss 5.3722\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [28300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28350][55000]\t Training Loss 0.0051\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28400][55000]\t Training Loss 1.1551\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [28450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28500][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28700][55000]\t Training Loss 0.0135\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28850][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [28900][55000]\t Training Loss 3.7896\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [28950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29000][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29150][55000]\t Training Loss 0.0056\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29350][55000]\t Training Loss 0.0982\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29400][55000]\t Training Loss 0.0251\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29450][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29500][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29550][55000]\t Training Loss 0.0057\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29600][55000]\t Training Loss 0.0059\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29700][55000]\t Training Loss 0.0158\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29750][55000]\t Training Loss 0.1377\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29800][55000]\t Training Loss 0.0360\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [29950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [30000][55000]\t Training Loss 0.1310\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [30050][55000]\t Training Loss 0.0091\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [30100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [30150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [30200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [30250][55000]\t Training Loss 0.0554\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [30300][55000]\t Training Loss 4.0002\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1][10]\t Batch [30350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [30400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [30450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [30500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [30550][55000]\t Training Loss 3.2489\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [30600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [30650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [30700][55000]\t Training Loss 4.2055\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [30750][55000]\t Training Loss 4.2336\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [30800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [30850][55000]\t Training Loss 0.0100\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [30900][55000]\t Training Loss 7.8147\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [30950][55000]\t Training Loss 8.6445\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [31000][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31150][55000]\t Training Loss 0.0055\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31200][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31250][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31300][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31350][55000]\t Training Loss 0.0090\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31400][55000]\t Training Loss 4.6444\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [31450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31500][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31550][55000]\t Training Loss 0.2254\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31750][55000]\t Training Loss 0.0028\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31900][55000]\t Training Loss 0.0056\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [31950][55000]\t Training Loss 0.7889\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [32000][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32050][55000]\t Training Loss 0.0035\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32250][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32400][55000]\t Training Loss 18.0337\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [32450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32500][55000]\t Training Loss 1.0157\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [32550][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32650][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32700][55000]\t Training Loss 0.0063\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32800][55000]\t Training Loss 2.2528\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [32850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [32950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33000][55000]\t Training Loss 0.0438\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33050][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33100][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33200][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33300][55000]\t Training Loss 0.1467\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33350][55000]\t Training Loss 0.0024\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33400][55000]\t Training Loss 0.0039\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33500][55000]\t Training Loss 1.8989\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [33550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33700][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33750][55000]\t Training Loss 0.0088\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [33950][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34050][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34100][55000]\t Training Loss 4.4050\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [34150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34250][55000]\t Training Loss 0.0041\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34350][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34400][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34600][55000]\t Training Loss 0.3693\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34750][55000]\t Training Loss 0.0045\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34800][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [34950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35000][55000]\t Training Loss 2.0383\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [35050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35100][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35350][55000]\t Training Loss 0.6562\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35500][55000]\t Training Loss 0.0191\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35550][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35600][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35700][55000]\t Training Loss 0.0480\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35750][55000]\t Training Loss 0.4906\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35800][55000]\t Training Loss 0.0208\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35850][55000]\t Training Loss 0.0353\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [35900][55000]\t Training Loss 1.0197\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [35950][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36050][55000]\t Training Loss 0.0144\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36100][55000]\t Training Loss 0.0388\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36150][55000]\t Training Loss 1.9328\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [36200][55000]\t Training Loss 0.3951\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36250][55000]\t Training Loss 0.6228\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36300][55000]\t Training Loss 1.9387\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [36350][55000]\t Training Loss 0.3290\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36450][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36500][55000]\t Training Loss 0.0708\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36600][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1][10]\t Batch [36650][55000]\t Training Loss 0.2219\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36900][55000]\t Training Loss 0.0049\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [36950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37000][55000]\t Training Loss 1.5319\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [37050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37150][55000]\t Training Loss 0.7107\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [37200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37250][55000]\t Training Loss 0.1104\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37400][55000]\t Training Loss 3.6925\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [37450][55000]\t Training Loss 0.0378\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37500][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37650][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [37950][55000]\t Training Loss 0.0105\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38150][55000]\t Training Loss 10.1550\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [38200][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38300][55000]\t Training Loss 0.0369\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38350][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38400][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38450][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38600][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38650][55000]\t Training Loss 1.3264\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [38700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38900][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [38950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [39000][55000]\t Training Loss 2.1062\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [39050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [39100][55000]\t Training Loss 1.6107\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [39150][55000]\t Training Loss 2.9224\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [39200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [39250][55000]\t Training Loss 16.9809\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [39300][55000]\t Training Loss 1.1970\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [39350][55000]\t Training Loss 0.0062\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [39400][55000]\t Training Loss 0.0087\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [39450][55000]\t Training Loss 7.5296\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [39500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [39550][55000]\t Training Loss 0.0041\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [39600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [39650][55000]\t Training Loss 0.0231\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [39700][55000]\t Training Loss 0.5526\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [39750][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [39800][55000]\t Training Loss 0.0029\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [39850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [39900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [39950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40050][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40400][55000]\t Training Loss 0.0131\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40550][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40600][55000]\t Training Loss 0.0055\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40700][55000]\t Training Loss 0.0085\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40800][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [40950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41100][55000]\t Training Loss 0.0454\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41150][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41500][55000]\t Training Loss 0.7391\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [41550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41600][55000]\t Training Loss 6.8599\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [41650][55000]\t Training Loss 0.0027\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41750][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41800][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41850][55000]\t Training Loss 0.0911\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [41950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42100][55000]\t Training Loss 0.0624\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42150][55000]\t Training Loss 2.4199\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [42200][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42250][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42350][55000]\t Training Loss 0.3882\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42450][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42500][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42550][55000]\t Training Loss 0.1654\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42600][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42650][55000]\t Training Loss 0.0038\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42750][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42800][55000]\t Training Loss 0.6192\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42850][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [42900][55000]\t Training Loss 0.9705\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1][10]\t Batch [42950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43000][55000]\t Training Loss 0.2454\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43050][55000]\t Training Loss 6.8530\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [43100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43200][55000]\t Training Loss 1.8286\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [43250][55000]\t Training Loss 0.0129\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43500][55000]\t Training Loss 0.0091\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43600][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43800][55000]\t Training Loss 0.1585\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [43950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44000][55000]\t Training Loss 0.0099\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44050][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44250][55000]\t Training Loss 4.4077\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [44300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44350][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44550][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44650][55000]\t Training Loss 0.0055\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44800][55000]\t Training Loss 0.5173\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44850][55000]\t Training Loss 0.0093\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [44950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45000][55000]\t Training Loss 0.0474\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45050][55000]\t Training Loss 0.1726\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45100][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45150][55000]\t Training Loss 0.0087\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45350][55000]\t Training Loss 9.4857\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [45400][55000]\t Training Loss 1.4659\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [45450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45600][55000]\t Training Loss 0.0203\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45800][55000]\t Training Loss 24.6122\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [45850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [45950][55000]\t Training Loss 0.0205\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46050][55000]\t Training Loss 0.1387\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46100][55000]\t Training Loss 9.6861\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [46150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46400][55000]\t Training Loss 1.5936\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [46450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46700][55000]\t Training Loss 0.3259\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46900][55000]\t Training Loss 0.0424\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [46950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47000][55000]\t Training Loss 0.0415\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47050][55000]\t Training Loss 0.0054\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47200][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47250][55000]\t Training Loss 0.0204\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47300][55000]\t Training Loss 0.3881\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47350][55000]\t Training Loss 0.0069\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47450][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47650][55000]\t Training Loss 3.1776\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [47700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47750][55000]\t Training Loss 9.3878\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [47800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47900][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [47950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [48000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [48050][55000]\t Training Loss 5.1408\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [48100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [48150][55000]\t Training Loss 0.0781\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [48200][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [48250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [48300][55000]\t Training Loss 14.5079\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [48350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [48400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [48450][55000]\t Training Loss 5.4860\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [48500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [48550][55000]\t Training Loss 6.0271\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [48600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [48650][55000]\t Training Loss 1.9416\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [48700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [48750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [48800][55000]\t Training Loss 0.0146\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [48850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [48900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [48950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49050][55000]\t Training Loss 19.5585\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [49100][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49150][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49200][55000]\t Training Loss 5.2983\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1][10]\t Batch [49250][55000]\t Training Loss 0.0244\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49500][55000]\t Training Loss 9.6920\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [49550][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49750][55000]\t Training Loss 0.1143\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49900][55000]\t Training Loss 0.4725\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [49950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50000][55000]\t Training Loss 0.6923\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50050][55000]\t Training Loss 2.1529\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [50100][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50150][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50200][55000]\t Training Loss 16.6083\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [50250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50300][55000]\t Training Loss 0.1066\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50500][55000]\t Training Loss 0.1261\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50550][55000]\t Training Loss 6.9304\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [50600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50700][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50750][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50800][55000]\t Training Loss 0.0215\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50850][55000]\t Training Loss 0.0075\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [50950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51000][55000]\t Training Loss 1.7710\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [51050][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51100][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51250][55000]\t Training Loss 0.2068\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51450][55000]\t Training Loss 1.0596\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [51500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51700][55000]\t Training Loss 39.0096\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [51750][55000]\t Training Loss 0.1411\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51850][55000]\t Training Loss 0.0132\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [51950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52300][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52400][55000]\t Training Loss 12.9515\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [52450][55000]\t Training Loss 0.0077\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52500][55000]\t Training Loss 0.0370\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52550][55000]\t Training Loss 2.7324\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [52600][55000]\t Training Loss 0.1054\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52750][55000]\t Training Loss 0.0112\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52850][55000]\t Training Loss 0.0043\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52900][55000]\t Training Loss 0.0070\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [52950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53100][55000]\t Training Loss 0.8463\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [53150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53200][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53250][55000]\t Training Loss 0.0476\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53300][55000]\t Training Loss 0.0075\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53400][55000]\t Training Loss 3.9368\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [53450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53500][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53650][55000]\t Training Loss 11.2809\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [53700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53750][55000]\t Training Loss 0.2252\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53850][55000]\t Training Loss 0.1780\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [53950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54000][55000]\t Training Loss 0.0041\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54300][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54350][55000]\t Training Loss 8.3389\t Accuracy 0.0000\n",
      "Epoch [1][10]\t Batch [54400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54800][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [54950][55000]\t Training Loss 0.8799\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1]\t Average training loss 0.7674\t Average training accuracy 0.8762\n",
      "Epoch [1]\t Average validation loss 0.7746\t Average validation accuracy 0.8654\n",
      "\n",
      "Epoch [2][10]\t Batch [0][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [100][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [150][55000]\t Training Loss 9.7967\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [200][55000]\t Training Loss 0.0183\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [300][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [350][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [500][55000]\t Training Loss 0.0040\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [600][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [650][55000]\t Training Loss 4.3128\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [700][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [750][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [800][55000]\t Training Loss 0.2258\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [950][55000]\t Training Loss 0.0076\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1150][55000]\t Training Loss 2.3077\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [1200][55000]\t Training Loss 0.5051\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1250][55000]\t Training Loss 0.0057\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1300][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1600][55000]\t Training Loss 0.1031\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1650][55000]\t Training Loss 5.7196\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [1700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1800][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1850][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1950][55000]\t Training Loss 0.0133\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2050][55000]\t Training Loss 0.0207\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2300][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2450][55000]\t Training Loss 0.0087\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2550][55000]\t Training Loss 0.0065\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2750][55000]\t Training Loss 0.0133\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2850][55000]\t Training Loss 0.0885\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3050][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3300][55000]\t Training Loss 1.1520\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [3350][55000]\t Training Loss 0.0112\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3400][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3450][55000]\t Training Loss 5.0417\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [3500][55000]\t Training Loss 7.6430\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [3550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3700][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3750][55000]\t Training Loss 0.4524\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3800][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [3950][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4300][55000]\t Training Loss 0.1094\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4500][55000]\t Training Loss 1.7474\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [4550][55000]\t Training Loss 0.1110\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4600][55000]\t Training Loss 0.0525\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4700][55000]\t Training Loss 0.0035\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [4950][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5000][55000]\t Training Loss 0.0549\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5300][55000]\t Training Loss 0.0618\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5450][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5500][55000]\t Training Loss 0.6313\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2][10]\t Batch [5600][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5900][55000]\t Training Loss 0.8241\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [5950][55000]\t Training Loss 0.0134\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6250][55000]\t Training Loss 0.0076\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6300][55000]\t Training Loss 2.9830\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [6350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6400][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6600][55000]\t Training Loss 0.2617\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6650][55000]\t Training Loss 0.0582\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6900][55000]\t Training Loss 0.0041\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [6950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7000][55000]\t Training Loss 0.0148\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7050][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7150][55000]\t Training Loss 0.0140\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7200][55000]\t Training Loss 1.6160\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [7250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7350][55000]\t Training Loss 0.6319\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7400][55000]\t Training Loss 0.1016\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7600][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7700][55000]\t Training Loss 0.0083\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7750][55000]\t Training Loss 2.8192\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [7800][55000]\t Training Loss 0.0390\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [7950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8100][55000]\t Training Loss 0.1453\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8200][55000]\t Training Loss 0.5921\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8300][55000]\t Training Loss 0.0901\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8550][55000]\t Training Loss 0.0260\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8600][55000]\t Training Loss 8.6690\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [8650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8700][55000]\t Training Loss 0.0067\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8750][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8900][55000]\t Training Loss 0.1592\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [8950][55000]\t Training Loss 1.0782\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [9000][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9100][55000]\t Training Loss 0.1684\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9250][55000]\t Training Loss 0.0543\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9450][55000]\t Training Loss 0.3051\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9600][55000]\t Training Loss 17.4298\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [9650][55000]\t Training Loss 5.3749\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [9700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9900][55000]\t Training Loss 0.0156\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [9950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10100][55000]\t Training Loss 0.0660\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10350][55000]\t Training Loss 0.0466\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10550][55000]\t Training Loss 2.2051\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [10600][55000]\t Training Loss 0.8502\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [10650][55000]\t Training Loss 0.0081\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10900][55000]\t Training Loss 0.0968\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [10950][55000]\t Training Loss 0.7720\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [11000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11050][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11150][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11200][55000]\t Training Loss 0.9089\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [11250][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11450][55000]\t Training Loss 3.3431\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [11500][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11550][55000]\t Training Loss 0.0042\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11700][55000]\t Training Loss 0.0064\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2][10]\t Batch [11750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [11950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12050][55000]\t Training Loss 1.8114\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [12100][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12200][55000]\t Training Loss 1.4961\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [12250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12300][55000]\t Training Loss 0.0992\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12500][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12600][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12650][55000]\t Training Loss 0.5471\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12850][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [12950][55000]\t Training Loss 0.0107\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13100][55000]\t Training Loss 2.4138\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [13150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13350][55000]\t Training Loss 0.6423\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13450][55000]\t Training Loss 0.0050\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13550][55000]\t Training Loss 0.0550\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13650][55000]\t Training Loss 0.0088\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13700][55000]\t Training Loss 1.9589\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [13750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13850][55000]\t Training Loss 15.3128\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [13900][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [13950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14050][55000]\t Training Loss 0.0071\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14100][55000]\t Training Loss 0.0056\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14150][55000]\t Training Loss 0.0753\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14200][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14250][55000]\t Training Loss 0.0504\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14600][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14650][55000]\t Training Loss 3.4498\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [14700][55000]\t Training Loss 3.5145\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [14750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14800][55000]\t Training Loss 1.4907\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [14850][55000]\t Training Loss 0.0373\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [14950][55000]\t Training Loss 0.0219\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15250][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15350][55000]\t Training Loss 0.0453\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15550][55000]\t Training Loss 16.5345\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [15600][55000]\t Training Loss 6.4896\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [15650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15750][55000]\t Training Loss 0.0166\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15850][55000]\t Training Loss 0.0121\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [15950][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16150][55000]\t Training Loss 0.0263\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16250][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16300][55000]\t Training Loss 3.0100\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [16350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16450][55000]\t Training Loss 0.8070\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16750][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16850][55000]\t Training Loss 0.0225\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [16900][55000]\t Training Loss 17.9065\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [16950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17000][55000]\t Training Loss 0.2221\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17100][55000]\t Training Loss 0.0202\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17250][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17350][55000]\t Training Loss 5.1037\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [17400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17500][55000]\t Training Loss 0.0130\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17700][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17750][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17800][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2][10]\t Batch [17900][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [17950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18050][55000]\t Training Loss 0.0267\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18100][55000]\t Training Loss 15.0606\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [18150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18250][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18300][55000]\t Training Loss 2.8587\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [18350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18550][55000]\t Training Loss 0.0031\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18600][55000]\t Training Loss 0.3631\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18650][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18700][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18800][55000]\t Training Loss 18.4316\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [18850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [18950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19300][55000]\t Training Loss 5.1445\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [19350][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19500][55000]\t Training Loss 0.0719\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19700][55000]\t Training Loss 5.7443\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [19750][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19900][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [19950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20050][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20400][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20450][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20500][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20750][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20850][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [20900][55000]\t Training Loss 7.1821\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [20950][55000]\t Training Loss 4.9683\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [21000][55000]\t Training Loss 0.0118\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21100][55000]\t Training Loss 5.9789\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [21150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21200][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21250][55000]\t Training Loss 0.0098\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21350][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21550][55000]\t Training Loss 0.0734\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21600][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21650][55000]\t Training Loss 0.0230\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21850][55000]\t Training Loss 0.0082\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [21950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22000][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22150][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22350][55000]\t Training Loss 0.0054\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22400][55000]\t Training Loss 7.6376\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [22450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22550][55000]\t Training Loss 0.0117\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22600][55000]\t Training Loss 0.4452\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22650][55000]\t Training Loss 0.4953\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22700][55000]\t Training Loss 0.3087\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22750][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22850][55000]\t Training Loss 0.0033\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [22950][55000]\t Training Loss 0.0039\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23050][55000]\t Training Loss 22.7906\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [23100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23150][55000]\t Training Loss 0.6944\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23200][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23250][55000]\t Training Loss 0.0057\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23650][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23700][55000]\t Training Loss 0.0789\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23850][55000]\t Training Loss 2.0370\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [23900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [23950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2][10]\t Batch [24000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24150][55000]\t Training Loss 0.0362\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24250][55000]\t Training Loss 0.0272\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24600][55000]\t Training Loss 0.0332\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24700][55000]\t Training Loss 4.4803\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [24750][55000]\t Training Loss 0.1873\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24850][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24900][55000]\t Training Loss 0.0065\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [24950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25000][55000]\t Training Loss 9.4630\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [25050][55000]\t Training Loss 0.1039\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25100][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25300][55000]\t Training Loss 0.0034\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25400][55000]\t Training Loss 0.0725\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25450][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25550][55000]\t Training Loss 0.1325\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25650][55000]\t Training Loss 0.6161\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25750][55000]\t Training Loss 0.0201\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25900][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [25950][55000]\t Training Loss 2.2522\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [26000][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26050][55000]\t Training Loss 0.2765\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26300][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26350][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26400][55000]\t Training Loss 0.0044\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26500][55000]\t Training Loss 6.5581\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [26550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26900][55000]\t Training Loss 0.0504\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [26950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27050][55000]\t Training Loss 0.0113\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27100][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27200][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27250][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27350][55000]\t Training Loss 0.0383\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27550][55000]\t Training Loss 0.1536\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27650][55000]\t Training Loss 0.0127\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27750][55000]\t Training Loss 0.4167\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27850][55000]\t Training Loss 0.0762\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [27950][55000]\t Training Loss 4.7651\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [28000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28100][55000]\t Training Loss 0.0219\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28150][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28250][55000]\t Training Loss 0.0061\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28400][55000]\t Training Loss 0.0038\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28600][55000]\t Training Loss 0.0124\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28650][55000]\t Training Loss 0.0183\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28700][55000]\t Training Loss 0.2264\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28750][55000]\t Training Loss 0.2264\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [28900][55000]\t Training Loss 17.8667\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [28950][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29000][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29100][55000]\t Training Loss 0.0024\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29150][55000]\t Training Loss 7.4473\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [29200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29400][55000]\t Training Loss 0.0097\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29500][55000]\t Training Loss 0.1771\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29550][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29650][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29750][55000]\t Training Loss 14.5322\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [29800][55000]\t Training Loss 0.5067\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29850][55000]\t Training Loss 0.0203\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29900][55000]\t Training Loss 0.0039\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [29950][55000]\t Training Loss 0.0080\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30000][55000]\t Training Loss 2.7903\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [30050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2][10]\t Batch [30100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30250][55000]\t Training Loss 7.7631\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [30300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30400][55000]\t Training Loss 12.6710\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [30450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30500][55000]\t Training Loss 0.0235\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30600][55000]\t Training Loss 0.1242\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30650][55000]\t Training Loss 0.3625\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30700][55000]\t Training Loss 0.0063\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30750][55000]\t Training Loss 0.4287\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30800][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30850][55000]\t Training Loss 0.2446\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30900][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [30950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31050][55000]\t Training Loss 0.0028\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31250][55000]\t Training Loss 0.0657\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31300][55000]\t Training Loss 0.0980\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31350][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31400][55000]\t Training Loss 0.0841\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31450][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31550][55000]\t Training Loss 8.1303\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [31600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31650][55000]\t Training Loss 4.0219\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [31700][55000]\t Training Loss 2.5997\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [31750][55000]\t Training Loss 0.0733\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [31900][55000]\t Training Loss 5.0022\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [31950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32000][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32150][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32200][55000]\t Training Loss 0.0031\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32350][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32500][55000]\t Training Loss 2.3423\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [32550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32600][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32650][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32750][55000]\t Training Loss 8.4085\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [32800][55000]\t Training Loss 9.9676\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [32850][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [32900][55000]\t Training Loss 5.6517\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [32950][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33000][55000]\t Training Loss 0.0432\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33050][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33150][55000]\t Training Loss 5.3579\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [33200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33300][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33350][55000]\t Training Loss 0.0122\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33400][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33500][55000]\t Training Loss 0.0280\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33600][55000]\t Training Loss 0.0607\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33700][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33750][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33900][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [33950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34100][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34200][55000]\t Training Loss 0.0033\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34300][55000]\t Training Loss 0.5935\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34350][55000]\t Training Loss 8.0487\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [34400][55000]\t Training Loss 0.0398\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34500][55000]\t Training Loss 0.0044\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34550][55000]\t Training Loss 5.6650\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [34600][55000]\t Training Loss 0.0049\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34700][55000]\t Training Loss 0.3964\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34900][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [34950][55000]\t Training Loss 0.3341\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35000][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35200][55000]\t Training Loss 0.0050\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35250][55000]\t Training Loss 0.0416\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35350][55000]\t Training Loss 2.6726\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [35400][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35550][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35700][55000]\t Training Loss 0.1948\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35750][55000]\t Training Loss 7.1381\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [35800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [35900][55000]\t Training Loss 3.9255\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [35950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36000][55000]\t Training Loss 0.0202\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36050][55000]\t Training Loss 1.7196\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [36100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36150][55000]\t Training Loss 0.0094\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2][10]\t Batch [36200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36250][55000]\t Training Loss 1.0067\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [36300][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36600][55000]\t Training Loss 1.2269\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [36650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36700][55000]\t Training Loss 0.0096\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36900][55000]\t Training Loss 0.0027\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [36950][55000]\t Training Loss 0.7438\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [37000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37050][55000]\t Training Loss 0.0092\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37100][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37350][55000]\t Training Loss 0.0038\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37400][55000]\t Training Loss 0.0824\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37650][55000]\t Training Loss 2.7733\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [37700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37800][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37900][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [37950][55000]\t Training Loss 6.6963\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [38000][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38050][55000]\t Training Loss 0.0081\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38400][55000]\t Training Loss 5.1234\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [38450][55000]\t Training Loss 0.1658\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38600][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [38950][55000]\t Training Loss 1.4422\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [39000][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39100][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39150][55000]\t Training Loss 1.1912\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [39200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39250][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39300][55000]\t Training Loss 0.0051\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39350][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39550][55000]\t Training Loss 0.1453\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39850][55000]\t Training Loss 1.4829\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [39900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [39950][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40000][55000]\t Training Loss 2.3782\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [40050][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40150][55000]\t Training Loss 0.0081\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40200][55000]\t Training Loss 0.0052\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40400][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40600][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40650][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40700][55000]\t Training Loss 0.0877\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [40850][55000]\t Training Loss 11.4363\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [40900][55000]\t Training Loss 20.0078\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [40950][55000]\t Training Loss 2.1494\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [41000][55000]\t Training Loss 11.2180\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [41050][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41300][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41350][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41400][55000]\t Training Loss 0.0038\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41500][55000]\t Training Loss 0.0095\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41650][55000]\t Training Loss 0.0285\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41750][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41800][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2][10]\t Batch [41900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [41950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42150][55000]\t Training Loss 0.4340\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42300][55000]\t Training Loss 4.2348\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [42350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42550][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42650][55000]\t Training Loss 9.3523\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [42700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42750][55000]\t Training Loss 0.0082\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42900][55000]\t Training Loss 0.3246\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [42950][55000]\t Training Loss 0.0548\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43050][55000]\t Training Loss 0.0141\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43150][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43250][55000]\t Training Loss 0.6821\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43350][55000]\t Training Loss 5.4288\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [43400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43450][55000]\t Training Loss 5.4211\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [43500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43550][55000]\t Training Loss 0.3304\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43650][55000]\t Training Loss 5.8287\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [43700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [43950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44150][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44350][55000]\t Training Loss 0.3712\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44450][55000]\t Training Loss 1.5239\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [44500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44650][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44700][55000]\t Training Loss 11.5801\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [44750][55000]\t Training Loss 10.6785\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [44800][55000]\t Training Loss 0.1922\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44850][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [44950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45150][55000]\t Training Loss 0.1677\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45200][55000]\t Training Loss 0.8460\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [45250][55000]\t Training Loss 1.4121\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [45300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45350][55000]\t Training Loss 0.0050\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45400][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45550][55000]\t Training Loss 0.0345\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45600][55000]\t Training Loss 10.9474\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [45650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [45950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46000][55000]\t Training Loss 0.3077\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46050][55000]\t Training Loss 0.0028\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46150][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46200][55000]\t Training Loss 3.0948\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [46250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46350][55000]\t Training Loss 0.1359\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46550][55000]\t Training Loss 2.3585\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [46600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46650][55000]\t Training Loss 15.7196\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [46700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46750][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46850][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [46950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47050][55000]\t Training Loss 0.0842\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47350][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47400][55000]\t Training Loss 0.0095\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47450][55000]\t Training Loss 5.5447\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [47500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47550][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2][10]\t Batch [47650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47850][55000]\t Training Loss 6.2352\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [47900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [47950][55000]\t Training Loss 0.8834\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [48000][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48100][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48150][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48250][55000]\t Training Loss 0.1395\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48300][55000]\t Training Loss 0.0549\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48400][55000]\t Training Loss 0.0743\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48700][55000]\t Training Loss 0.3520\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48850][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [48950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49100][55000]\t Training Loss 6.6515\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [49150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49200][55000]\t Training Loss 0.0243\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49250][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49300][55000]\t Training Loss 0.0084\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49400][55000]\t Training Loss 0.0034\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49550][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49700][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49750][55000]\t Training Loss 0.0050\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [49950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50050][55000]\t Training Loss 0.0029\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50100][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50200][55000]\t Training Loss 0.2124\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50250][55000]\t Training Loss 13.1686\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [50300][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50350][55000]\t Training Loss 7.1710\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [50400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50450][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50500][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50550][55000]\t Training Loss 0.2708\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50650][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50750][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50800][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50850][55000]\t Training Loss 7.5643\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [50900][55000]\t Training Loss 0.0516\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [50950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51000][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51050][55000]\t Training Loss 0.0397\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51150][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51200][55000]\t Training Loss 1.7969\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [51250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51350][55000]\t Training Loss 0.0101\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51550][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51650][55000]\t Training Loss 1.3188\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [51700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51750][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51800][55000]\t Training Loss 0.0157\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51850][55000]\t Training Loss 0.3091\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [51950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52150][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52200][55000]\t Training Loss 0.0062\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52350][55000]\t Training Loss 0.0431\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52500][55000]\t Training Loss 15.1308\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [52550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52600][55000]\t Training Loss 0.0048\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52750][55000]\t Training Loss 15.9378\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [52800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52850][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [52950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53200][55000]\t Training Loss 0.0302\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53400][55000]\t Training Loss 0.0433\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53500][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53550][55000]\t Training Loss 0.0161\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53600][55000]\t Training Loss 0.0150\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53650][55000]\t Training Loss 7.1172\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2][10]\t Batch [53700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53750][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [53950][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54200][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54250][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54300][55000]\t Training Loss 8.6397\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [54350][55000]\t Training Loss 0.1660\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54400][55000]\t Training Loss 0.1719\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54500][55000]\t Training Loss 0.0234\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54600][55000]\t Training Loss 0.3245\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54650][55000]\t Training Loss 7.7018\t Accuracy 0.0000\n",
      "Epoch [2][10]\t Batch [54700][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54850][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54900][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [54950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "\n",
      "Epoch [2]\t Average training loss 0.7387\t Average training accuracy 0.8805\n",
      "Epoch [2]\t Average validation loss 0.5920\t Average validation accuracy 0.9116\n",
      "\n",
      "Epoch [3][10]\t Batch [0][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [100][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [150][55000]\t Training Loss 2.4989\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [300][55000]\t Training Loss 0.0282\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [350][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [450][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [600][55000]\t Training Loss 0.3315\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [650][55000]\t Training Loss 1.1340\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [700][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [800][55000]\t Training Loss 14.7028\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [850][55000]\t Training Loss 0.1060\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1050][55000]\t Training Loss 0.9024\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [1100][55000]\t Training Loss 14.8616\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [1150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1350][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1450][55000]\t Training Loss 4.0519\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [1500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1550][55000]\t Training Loss 2.7934\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [1600][55000]\t Training Loss 4.6937\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [1650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1750][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1800][55000]\t Training Loss 0.0436\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1850][55000]\t Training Loss 0.0485\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1900][55000]\t Training Loss 5.6128\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [1950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2050][55000]\t Training Loss 4.0550\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [2100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2150][55000]\t Training Loss 0.3340\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2200][55000]\t Training Loss 1.1574\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [2250][55000]\t Training Loss 0.0080\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2300][55000]\t Training Loss 0.6596\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2350][55000]\t Training Loss 12.6036\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [2400][55000]\t Training Loss 0.0773\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2450][55000]\t Training Loss 0.0500\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2500][55000]\t Training Loss 0.8793\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [2550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2600][55000]\t Training Loss 3.4731\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [2650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2700][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2800][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2900][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3000][55000]\t Training Loss 0.6470\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3250][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3300][55000]\t Training Loss 0.0045\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3650][55000]\t Training Loss 0.0506\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3700][55000]\t Training Loss 13.1121\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [3750][55000]\t Training Loss 0.0442\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3800][55000]\t Training Loss 0.0771\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3900][55000]\t Training Loss 0.0062\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [3950][55000]\t Training Loss 0.0069\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [4000][55000]\t Training Loss 0.0027\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [4050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [4100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [4150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [4200][55000]\t Training Loss 13.9974\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [4250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [4300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [4350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [4400][55000]\t Training Loss 0.1154\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [4450][55000]\t Training Loss 1.0012\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [4500][55000]\t Training Loss 0.0050\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [4550][55000]\t Training Loss 0.0905\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [4600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [4650][55000]\t Training Loss 0.1219\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [4700][55000]\t Training Loss 1.1345\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [4750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [4800][55000]\t Training Loss 0.2643\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [4850][55000]\t Training Loss 6.8105\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [4900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3][10]\t Batch [4950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5050][55000]\t Training Loss 1.9193\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [5100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5350][55000]\t Training Loss 1.3331\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [5400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5500][55000]\t Training Loss 0.0062\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5800][55000]\t Training Loss 0.0625\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5850][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [5950][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6100][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6250][55000]\t Training Loss 1.5865\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [6300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6450][55000]\t Training Loss 0.0131\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6600][55000]\t Training Loss 1.4572\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [6650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6700][55000]\t Training Loss 0.1589\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6850][55000]\t Training Loss 49.6855\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [6900][55000]\t Training Loss 0.2405\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [6950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7050][55000]\t Training Loss 2.3746\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [7100][55000]\t Training Loss 0.4066\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7200][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7250][55000]\t Training Loss 0.0077\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7350][55000]\t Training Loss 0.9728\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [7400][55000]\t Training Loss 0.1755\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7500][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7700][55000]\t Training Loss 0.0082\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7750][55000]\t Training Loss 0.4609\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7850][55000]\t Training Loss 2.1241\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [7900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [7950][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8150][55000]\t Training Loss 0.0691\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8250][55000]\t Training Loss 0.0044\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8400][55000]\t Training Loss 0.0167\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8450][55000]\t Training Loss 15.1209\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [8500][55000]\t Training Loss 0.0100\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8550][55000]\t Training Loss 0.9895\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [8600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8800][55000]\t Training Loss 0.0080\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [8950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9200][55000]\t Training Loss 0.7083\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9250][55000]\t Training Loss 0.1338\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9550][55000]\t Training Loss 3.8462\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [9600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9650][55000]\t Training Loss 0.0080\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9700][55000]\t Training Loss 0.0162\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9750][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9800][55000]\t Training Loss 1.9726\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [9850][55000]\t Training Loss 0.0296\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [9950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10100][55000]\t Training Loss 0.0076\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10350][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3][10]\t Batch [10500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10600][55000]\t Training Loss 0.0349\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10650][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10850][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10900][55000]\t Training Loss 0.5398\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [10950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11050][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11150][55000]\t Training Loss 3.6722\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [11200][55000]\t Training Loss 0.0388\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11300][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11450][55000]\t Training Loss 25.8022\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [11500][55000]\t Training Loss 0.8788\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [11550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11600][55000]\t Training Loss 0.0045\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11700][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11800][55000]\t Training Loss 0.0463\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [11900][55000]\t Training Loss 2.4567\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [11950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12000][55000]\t Training Loss 0.0739\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12150][55000]\t Training Loss 0.0041\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12200][55000]\t Training Loss 0.0058\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12350][55000]\t Training Loss 0.0231\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12400][55000]\t Training Loss 0.3719\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12450][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12550][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12750][55000]\t Training Loss 0.0066\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [12950][55000]\t Training Loss 2.0476\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [13000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13150][55000]\t Training Loss 0.0118\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13200][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13400][55000]\t Training Loss 0.1006\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13450][55000]\t Training Loss 0.8041\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [13500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13550][55000]\t Training Loss 1.1143\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [13600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13650][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [13950][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14050][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14250][55000]\t Training Loss 0.0204\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14300][55000]\t Training Loss 0.2220\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14400][55000]\t Training Loss 0.0040\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14500][55000]\t Training Loss 0.0083\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14550][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14650][55000]\t Training Loss 0.0066\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14700][55000]\t Training Loss 0.9150\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [14750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14850][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [14950][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15050][55000]\t Training Loss 1.2800\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [15100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15150][55000]\t Training Loss 0.6903\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15250][55000]\t Training Loss 0.0102\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15300][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15350][55000]\t Training Loss 0.0133\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15400][55000]\t Training Loss 0.0331\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15450][55000]\t Training Loss 0.2230\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15850][55000]\t Training Loss 3.5376\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [15900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [15950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16050][55000]\t Training Loss 1.9147\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [16100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16200][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3][10]\t Batch [16250][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16400][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16550][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16600][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16750][55000]\t Training Loss 0.0051\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16900][55000]\t Training Loss 0.0053\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [16950][55000]\t Training Loss 0.1868\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17050][55000]\t Training Loss 0.0105\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17200][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17250][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17600][55000]\t Training Loss 0.1141\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17750][55000]\t Training Loss 9.1991\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [17800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [17850][55000]\t Training Loss 7.1447\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [17900][55000]\t Training Loss 1.5042\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [17950][55000]\t Training Loss 4.0335\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [18000][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18100][55000]\t Training Loss 0.0433\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18250][55000]\t Training Loss 6.8687\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [18300][55000]\t Training Loss 0.4637\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18450][55000]\t Training Loss 1.7295\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [18500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18650][55000]\t Training Loss 0.7355\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [18700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [18950][55000]\t Training Loss 0.0681\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19000][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19150][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19200][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19450][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19500][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19550][55000]\t Training Loss 0.1630\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19600][55000]\t Training Loss 0.0038\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19650][55000]\t Training Loss 0.1176\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [19950][55000]\t Training Loss 0.0062\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20050][55000]\t Training Loss 0.0029\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20100][55000]\t Training Loss 0.6033\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20250][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20300][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20400][55000]\t Training Loss 0.0065\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20450][55000]\t Training Loss 0.0276\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20500][55000]\t Training Loss 0.0521\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20750][55000]\t Training Loss 0.1341\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20800][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20850][55000]\t Training Loss 0.0060\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20900][55000]\t Training Loss 0.0225\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [20950][55000]\t Training Loss 1.0226\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [21000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21050][55000]\t Training Loss 2.6388\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [21100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21150][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21400][55000]\t Training Loss 0.0489\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21550][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21600][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21700][55000]\t Training Loss 0.0202\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [21850][55000]\t Training Loss 19.2843\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [21900][55000]\t Training Loss 1.8387\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [21950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3][10]\t Batch [22000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22050][55000]\t Training Loss 0.0359\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22100][55000]\t Training Loss 0.1889\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22150][55000]\t Training Loss 0.1806\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22200][55000]\t Training Loss 1.3931\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [22250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22350][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22400][55000]\t Training Loss 2.0859\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [22450][55000]\t Training Loss 0.1849\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22500][55000]\t Training Loss 0.0035\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22550][55000]\t Training Loss 0.8682\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [22600][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22800][55000]\t Training Loss 0.0759\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [22950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23100][55000]\t Training Loss 0.0616\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23300][55000]\t Training Loss 0.0044\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23400][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23450][55000]\t Training Loss 0.0086\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23500][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23550][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23600][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23650][55000]\t Training Loss 0.0111\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23750][55000]\t Training Loss 0.2907\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23800][55000]\t Training Loss 0.0315\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23850][55000]\t Training Loss 0.1290\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [23950][55000]\t Training Loss 0.8441\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [24000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [24050][55000]\t Training Loss 7.6640\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [24100][55000]\t Training Loss 0.7251\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [24150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [24200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [24250][55000]\t Training Loss 0.0131\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [24300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [24350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [24400][55000]\t Training Loss 0.0057\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [24450][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [24500][55000]\t Training Loss 6.1542\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [24550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [24600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [24650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [24700][55000]\t Training Loss 8.8880\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [24750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [24800][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [24850][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [24900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [24950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25000][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25100][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25150][55000]\t Training Loss 0.1281\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25200][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25300][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25350][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25500][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25550][55000]\t Training Loss 10.3403\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [25600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25750][55000]\t Training Loss 10.0092\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [25800][55000]\t Training Loss 0.4676\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25850][55000]\t Training Loss 3.9176\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [25900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [25950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26650][55000]\t Training Loss 1.7577\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [26700][55000]\t Training Loss 0.8016\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [26750][55000]\t Training Loss 0.0048\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26850][55000]\t Training Loss 0.0073\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26900][55000]\t Training Loss 0.0091\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [26950][55000]\t Training Loss 0.6823\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27000][55000]\t Training Loss 0.0091\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27050][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27100][55000]\t Training Loss 0.0168\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27250][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27350][55000]\t Training Loss 0.0205\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27400][55000]\t Training Loss 0.0726\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27450][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27500][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27550][55000]\t Training Loss 0.0035\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27600][55000]\t Training Loss 0.0051\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27700][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [27950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3][10]\t Batch [28000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28050][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28150][55000]\t Training Loss 0.2003\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28200][55000]\t Training Loss 0.0220\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28250][55000]\t Training Loss 0.0287\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28300][55000]\t Training Loss 0.0207\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28400][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28450][55000]\t Training Loss 0.0102\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28500][55000]\t Training Loss 0.0627\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28650][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28700][55000]\t Training Loss 0.0068\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28800][55000]\t Training Loss 0.0155\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [28950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29050][55000]\t Training Loss 0.0208\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29100][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29200][55000]\t Training Loss 0.0113\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29300][55000]\t Training Loss 0.0055\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29500][55000]\t Training Loss 6.9603\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [29550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29600][55000]\t Training Loss 2.9134\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [29650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29700][55000]\t Training Loss 0.0067\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [29950][55000]\t Training Loss 0.2955\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30000][55000]\t Training Loss 1.9889\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [30050][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30100][55000]\t Training Loss 0.1269\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30250][55000]\t Training Loss 0.0092\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30300][55000]\t Training Loss 2.2174\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [30350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30500][55000]\t Training Loss 13.3173\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [30550][55000]\t Training Loss 1.6877\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [30600][55000]\t Training Loss 0.0050\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30750][55000]\t Training Loss 0.0127\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [30950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [31000][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [31050][55000]\t Training Loss 0.0163\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [31100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [31150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [31200][55000]\t Training Loss 0.8389\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [31250][55000]\t Training Loss 0.0467\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [31300][55000]\t Training Loss 2.6770\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [31350][55000]\t Training Loss 0.0119\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [31400][55000]\t Training Loss 3.2919\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [31450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [31500][55000]\t Training Loss 0.0410\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [31550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [31600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [31650][55000]\t Training Loss 2.9076\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [31700][55000]\t Training Loss 0.4359\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [31750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [31800][55000]\t Training Loss 4.2636\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [31850][55000]\t Training Loss 0.0232\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [31900][55000]\t Training Loss 2.0395\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [31950][55000]\t Training Loss 0.5151\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32150][55000]\t Training Loss 0.0053\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32200][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32400][55000]\t Training Loss 0.1329\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32550][55000]\t Training Loss 0.0093\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32700][55000]\t Training Loss 0.6257\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [32950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33250][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33500][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33550][55000]\t Training Loss 0.3111\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33650][55000]\t Training Loss 0.0111\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33700][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33800][55000]\t Training Loss 0.0029\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [33950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34050][55000]\t Training Loss 5.5423\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [34100][55000]\t Training Loss 1.9253\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [34150][55000]\t Training Loss 2.5050\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3][10]\t Batch [34200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34250][55000]\t Training Loss 0.0328\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34350][55000]\t Training Loss 0.0074\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34700][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34750][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34850][55000]\t Training Loss 0.1165\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34900][55000]\t Training Loss 0.1054\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [34950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35100][55000]\t Training Loss 9.0567\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [35150][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35300][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35350][55000]\t Training Loss 2.7293\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [35400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35450][55000]\t Training Loss 3.6570\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [35500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35800][55000]\t Training Loss 0.0989\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [35950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36050][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36200][55000]\t Training Loss 6.3026\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [36250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36350][55000]\t Training Loss 0.0031\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36450][55000]\t Training Loss 0.0139\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36550][55000]\t Training Loss 6.4608\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [36600][55000]\t Training Loss 0.0045\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36650][55000]\t Training Loss 0.2379\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36700][55000]\t Training Loss 1.9636\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [36750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36800][55000]\t Training Loss 0.0780\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36850][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36900][55000]\t Training Loss 0.0498\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [36950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37000][55000]\t Training Loss 0.0082\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37050][55000]\t Training Loss 0.5009\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37200][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37250][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37300][55000]\t Training Loss 2.5109\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [37350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37450][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37500][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37550][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37600][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37650][55000]\t Training Loss 13.8661\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [37700][55000]\t Training Loss 0.0028\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37800][55000]\t Training Loss 0.0550\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [37950][55000]\t Training Loss 0.0230\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38000][55000]\t Training Loss 0.0024\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38550][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38600][55000]\t Training Loss 0.1547\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38650][55000]\t Training Loss 0.0757\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38700][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38800][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [38950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39000][55000]\t Training Loss 0.3247\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39250][55000]\t Training Loss 5.8879\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [39300][55000]\t Training Loss 2.3897\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [39350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39400][55000]\t Training Loss 1.8538\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [39450][55000]\t Training Loss 1.1105\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [39500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39550][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39750][55000]\t Training Loss 0.0284\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39800][55000]\t Training Loss 0.0075\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [39950][55000]\t Training Loss 0.0087\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40050][55000]\t Training Loss 0.0027\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40200][55000]\t Training Loss 0.0563\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3][10]\t Batch [40400][55000]\t Training Loss 0.4340\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40550][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40650][55000]\t Training Loss 21.4059\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [40700][55000]\t Training Loss 3.7842\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [40750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40900][55000]\t Training Loss 0.1103\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [40950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41000][55000]\t Training Loss 0.0117\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41100][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41350][55000]\t Training Loss 0.0998\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41550][55000]\t Training Loss 0.0049\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41650][55000]\t Training Loss 0.0113\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41700][55000]\t Training Loss 14.2638\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [41750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41850][55000]\t Training Loss 5.9340\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [41900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [41950][55000]\t Training Loss 1.8056\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [42000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [42050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [42100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [42150][55000]\t Training Loss 3.4115\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [42200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [42250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [42300][55000]\t Training Loss 17.1165\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [42350][55000]\t Training Loss 0.0039\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [42400][55000]\t Training Loss 3.1248\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [42450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [42500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [42550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [42600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [42650][55000]\t Training Loss 13.8160\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [42700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [42750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [42800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [42850][55000]\t Training Loss 0.1231\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [42900][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [42950][55000]\t Training Loss 4.1553\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [43000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43200][55000]\t Training Loss 0.4338\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43300][55000]\t Training Loss 0.0926\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43450][55000]\t Training Loss 0.1203\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43550][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43750][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43900][55000]\t Training Loss 0.0614\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [43950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44100][55000]\t Training Loss 0.1450\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44200][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44250][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44500][55000]\t Training Loss 0.0238\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44700][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44750][55000]\t Training Loss 0.0033\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [44950][55000]\t Training Loss 0.0415\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45000][55000]\t Training Loss 0.0049\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45050][55000]\t Training Loss 0.1329\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45300][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45550][55000]\t Training Loss 0.0027\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45650][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45750][55000]\t Training Loss 0.0795\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45850][55000]\t Training Loss 0.0584\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [45900][55000]\t Training Loss 4.4472\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [45950][55000]\t Training Loss 0.0424\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46000][55000]\t Training Loss 0.2015\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46050][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46100][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46350][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46400][55000]\t Training Loss 5.4408\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [46450][55000]\t Training Loss 0.0271\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46500][55000]\t Training Loss 0.0405\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3][10]\t Batch [46600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46750][55000]\t Training Loss 1.4387\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [46800][55000]\t Training Loss 0.0413\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [46950][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47000][55000]\t Training Loss 1.0193\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [47050][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47100][55000]\t Training Loss 2.3327\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [47150][55000]\t Training Loss 0.0374\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47250][55000]\t Training Loss 0.0054\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47300][55000]\t Training Loss 0.0046\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47350][55000]\t Training Loss 0.0219\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47450][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47550][55000]\t Training Loss 17.1083\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [47600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47850][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47900][55000]\t Training Loss 0.1517\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [47950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48150][55000]\t Training Loss 0.0159\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48300][55000]\t Training Loss 0.3628\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48500][55000]\t Training Loss 5.2592\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [48550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48600][55000]\t Training Loss 1.4917\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [48650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48700][55000]\t Training Loss 0.0105\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48850][55000]\t Training Loss 0.0043\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [48950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49400][55000]\t Training Loss 2.3529\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [49450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49500][55000]\t Training Loss 0.3917\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49650][55000]\t Training Loss 0.0116\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49800][55000]\t Training Loss 2.8122\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [49850][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [49950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50000][55000]\t Training Loss 10.2328\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [50050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50250][55000]\t Training Loss 0.0034\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50750][55000]\t Training Loss 0.0036\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50900][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51000][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51200][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51800][55000]\t Training Loss 3.2096\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [51850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [51950][55000]\t Training Loss 1.5873\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [52000][55000]\t Training Loss 0.0049\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52050][55000]\t Training Loss 0.0048\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52100][55000]\t Training Loss 0.0056\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52200][55000]\t Training Loss 0.0097\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52400][55000]\t Training Loss 0.0737\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52450][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3][10]\t Batch [52600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52650][55000]\t Training Loss 10.3479\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [52700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [52950][55000]\t Training Loss 0.0902\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53150][55000]\t Training Loss 0.0210\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53400][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53550][55000]\t Training Loss 0.0270\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53650][55000]\t Training Loss 6.3703\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [53700][55000]\t Training Loss 9.7358\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [53750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53900][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [53950][55000]\t Training Loss 0.0058\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54200][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54250][55000]\t Training Loss 14.5487\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [54300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54350][55000]\t Training Loss 4.2230\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [54400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54600][55000]\t Training Loss 0.0038\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54650][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54800][55000]\t Training Loss 9.8875\t Accuracy 0.0000\n",
      "Epoch [3][10]\t Batch [54850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [54950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "\n",
      "Epoch [3]\t Average training loss 0.7371\t Average training accuracy 0.8833\n",
      "Epoch [3]\t Average validation loss 0.5815\t Average validation accuracy 0.9058\n",
      "\n",
      "Epoch [4][10]\t Batch [0][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [100][55000]\t Training Loss 0.0430\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [200][55000]\t Training Loss 0.0464\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [500][55000]\t Training Loss 0.0677\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [600][55000]\t Training Loss 6.3218\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [850][55000]\t Training Loss 0.3892\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [950][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1050][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1150][55000]\t Training Loss 0.0031\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1200][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1350][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1500][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1550][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1600][55000]\t Training Loss 0.0342\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1650][55000]\t Training Loss 1.1586\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [1700][55000]\t Training Loss 0.3749\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1850][55000]\t Training Loss 2.5119\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [1900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2000][55000]\t Training Loss 2.4361\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [2050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2150][55000]\t Training Loss 14.6470\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [2200][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2300][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2350][55000]\t Training Loss 0.0048\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2450][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2550][55000]\t Training Loss 0.3482\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2750][55000]\t Training Loss 0.1725\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2800][55000]\t Training Loss 0.0041\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2850][55000]\t Training Loss 0.0187\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2900][55000]\t Training Loss 11.7682\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [2950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3100][55000]\t Training Loss 0.0156\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3300][55000]\t Training Loss 0.0035\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3350][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3750][55000]\t Training Loss 0.1693\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3800][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [3900][55000]\t Training Loss 1.8168\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [3950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4050][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4100][55000]\t Training Loss 1.3508\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [4150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4550][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4600][55000]\t Training Loss 0.0035\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4650][55000]\t Training Loss 0.0284\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4750][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4800][55000]\t Training Loss 11.5016\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [4850][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [4950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5050][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5100][55000]\t Training Loss 0.6623\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5150][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5200][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5250][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5450][55000]\t Training Loss 0.3837\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5550][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4][10]\t Batch [5650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [5950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [6000][55000]\t Training Loss 0.1037\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [6050][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [6100][55000]\t Training Loss 0.0703\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [6150][55000]\t Training Loss 16.8388\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [6200][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [6250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [6300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [6350][55000]\t Training Loss 9.9555\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [6400][55000]\t Training Loss 0.0156\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [6450][55000]\t Training Loss 36.3873\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [6500][55000]\t Training Loss 7.0044\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [6550][55000]\t Training Loss 0.1245\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [6600][55000]\t Training Loss 9.7021\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [6650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [6700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [6750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [6800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [6850][55000]\t Training Loss 0.0075\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [6900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [6950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7200][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7250][55000]\t Training Loss 0.0057\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7300][55000]\t Training Loss 0.0097\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7350][55000]\t Training Loss 0.0461\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7400][55000]\t Training Loss 0.0448\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7800][55000]\t Training Loss 0.2047\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7850][55000]\t Training Loss 3.3117\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [7900][55000]\t Training Loss 0.0056\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [7950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8000][55000]\t Training Loss 1.5828\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [8050][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8100][55000]\t Training Loss 0.0214\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8200][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8400][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8450][55000]\t Training Loss 0.1438\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8500][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8600][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8700][55000]\t Training Loss 0.0120\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [8950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9000][55000]\t Training Loss 1.8434\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [9050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9150][55000]\t Training Loss 4.1436\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [9200][55000]\t Training Loss 0.1949\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9250][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9450][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9500][55000]\t Training Loss 0.0047\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9600][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9700][55000]\t Training Loss 1.3655\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [9750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9850][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9900][55000]\t Training Loss 0.6009\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [9950][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10000][55000]\t Training Loss 0.3406\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10150][55000]\t Training Loss 0.0233\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10200][55000]\t Training Loss 1.2656\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [10250][55000]\t Training Loss 0.7082\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10300][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10500][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10600][55000]\t Training Loss 4.3365\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [10650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10750][55000]\t Training Loss 21.5315\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [10800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [10950][55000]\t Training Loss 0.0050\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11000][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11050][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11100][55000]\t Training Loss 1.9637\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [11150][55000]\t Training Loss 0.3707\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11200][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11250][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11300][55000]\t Training Loss 0.1089\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11500][55000]\t Training Loss 0.0346\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11800][55000]\t Training Loss 7.7105\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4][10]\t Batch [11850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [11950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12100][55000]\t Training Loss 0.0518\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12250][55000]\t Training Loss 3.4981\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [12300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12350][55000]\t Training Loss 0.0726\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12400][55000]\t Training Loss 0.0744\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12650][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12750][55000]\t Training Loss 0.1806\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12900][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [12950][55000]\t Training Loss 0.1509\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [13000][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [13050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [13100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [13150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [13200][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [13250][55000]\t Training Loss 1.3325\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [13300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [13350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [13400][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [13450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [13500][55000]\t Training Loss 3.5168\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [13550][55000]\t Training Loss 6.7489\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [13600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [13650][55000]\t Training Loss 4.0980\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [13700][55000]\t Training Loss 0.0053\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [13750][55000]\t Training Loss 10.6950\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [13800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [13850][55000]\t Training Loss 0.8980\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [13900][55000]\t Training Loss 1.2292\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [13950][55000]\t Training Loss 0.0094\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14050][55000]\t Training Loss 7.1534\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [14100][55000]\t Training Loss 1.7979\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [14150][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14300][55000]\t Training Loss 0.3823\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14500][55000]\t Training Loss 11.5959\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [14550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14600][55000]\t Training Loss 0.3769\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14700][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14800][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14850][55000]\t Training Loss 5.8316\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [14900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [14950][55000]\t Training Loss 0.0622\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15150][55000]\t Training Loss 8.7775\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [15200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15600][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15700][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15750][55000]\t Training Loss 4.0390\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [15800][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15900][55000]\t Training Loss 0.2538\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [15950][55000]\t Training Loss 0.0028\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16000][55000]\t Training Loss 0.1039\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16050][55000]\t Training Loss 0.8291\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [16100][55000]\t Training Loss 4.9002\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [16150][55000]\t Training Loss 0.0203\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16250][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16350][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16550][55000]\t Training Loss 0.0389\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16650][55000]\t Training Loss 8.2195\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [16700][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16750][55000]\t Training Loss 0.0686\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16850][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [16950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17050][55000]\t Training Loss 1.1581\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [17100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17250][55000]\t Training Loss 0.0077\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17400][55000]\t Training Loss 0.0497\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17550][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17600][55000]\t Training Loss 0.0042\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17750][55000]\t Training Loss 0.0154\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17850][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17900][55000]\t Training Loss 0.0131\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [17950][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4][10]\t Batch [18000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18400][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18450][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18550][55000]\t Training Loss 4.9078\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [18600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18650][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18800][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [18950][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19050][55000]\t Training Loss 10.9342\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [19100][55000]\t Training Loss 0.0118\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19150][55000]\t Training Loss 0.0553\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19300][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19350][55000]\t Training Loss 3.2375\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [19400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19500][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19800][55000]\t Training Loss 4.1022\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [19850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [19900][55000]\t Training Loss 10.7597\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [19950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20050][55000]\t Training Loss 15.1130\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [20100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20150][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20250][55000]\t Training Loss 6.7215\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [20300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20350][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20450][55000]\t Training Loss 0.1340\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20550][55000]\t Training Loss 0.0042\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20700][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20750][55000]\t Training Loss 0.8095\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20850][55000]\t Training Loss 1.5516\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [20900][55000]\t Training Loss 0.1626\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [20950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21000][55000]\t Training Loss 0.1341\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21300][55000]\t Training Loss 0.0079\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21350][55000]\t Training Loss 6.0524\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [21400][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21500][55000]\t Training Loss 0.0135\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21650][55000]\t Training Loss 0.2633\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21750][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [21950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22050][55000]\t Training Loss 1.4939\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [22100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22150][55000]\t Training Loss 0.0438\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22200][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22250][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22400][55000]\t Training Loss 0.0878\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22800][55000]\t Training Loss 0.0055\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [22950][55000]\t Training Loss 2.4333\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [23000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23100][55000]\t Training Loss 0.0161\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23150][55000]\t Training Loss 0.0051\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23200][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23650][55000]\t Training Loss 0.0061\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23700][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23750][55000]\t Training Loss 0.0919\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23800][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [23900][55000]\t Training Loss 39.0726\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [23950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24100][55000]\t Training Loss 0.0035\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24150][55000]\t Training Loss 0.0052\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4][10]\t Batch [24200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24350][55000]\t Training Loss 1.8438\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [24400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24600][55000]\t Training Loss 0.1389\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24850][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [24950][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25000][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25250][55000]\t Training Loss 0.2879\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25400][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25450][55000]\t Training Loss 3.3442\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [25500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25600][55000]\t Training Loss 0.0128\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25700][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25900][55000]\t Training Loss 0.3404\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [25950][55000]\t Training Loss 0.6088\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26050][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26350][55000]\t Training Loss 18.1521\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [26400][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26550][55000]\t Training Loss 0.0456\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26600][55000]\t Training Loss 9.9851\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [26650][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26700][55000]\t Training Loss 5.9817\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [26750][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26800][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [26950][55000]\t Training Loss 0.0350\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27050][55000]\t Training Loss 0.0926\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27200][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27250][55000]\t Training Loss 1.7329\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [27300][55000]\t Training Loss 9.4395\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [27350][55000]\t Training Loss 0.0059\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27400][55000]\t Training Loss 0.0059\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27500][55000]\t Training Loss 0.0113\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27750][55000]\t Training Loss 0.0038\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27800][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27900][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [27950][55000]\t Training Loss 0.0052\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28300][55000]\t Training Loss 0.0118\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28350][55000]\t Training Loss 0.5543\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28400][55000]\t Training Loss 0.0083\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28450][55000]\t Training Loss 1.3070\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [28500][55000]\t Training Loss 0.1411\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28600][55000]\t Training Loss 0.0484\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28650][55000]\t Training Loss 0.1543\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28750][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28850][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [28950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29250][55000]\t Training Loss 0.0511\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29450][55000]\t Training Loss 4.8368\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [29500][55000]\t Training Loss 14.0364\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [29550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29600][55000]\t Training Loss 23.3989\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [29650][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29700][55000]\t Training Loss 9.3454\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [29750][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29800][55000]\t Training Loss 0.0046\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29850][55000]\t Training Loss 0.0239\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [29950][55000]\t Training Loss 0.0064\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30000][55000]\t Training Loss 0.0199\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30050][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30150][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4][10]\t Batch [30300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30350][55000]\t Training Loss 5.1279\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [30400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30700][55000]\t Training Loss 0.5943\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30750][55000]\t Training Loss 0.0090\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [30950][55000]\t Training Loss 2.9494\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [31000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31150][55000]\t Training Loss 0.0388\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31400][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31450][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31600][55000]\t Training Loss 0.0791\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31700][55000]\t Training Loss 0.0229\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31750][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31800][55000]\t Training Loss 6.6941\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [31850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [31900][55000]\t Training Loss 6.9807\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [31950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32050][55000]\t Training Loss 0.0089\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32100][55000]\t Training Loss 3.2327\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [32150][55000]\t Training Loss 0.4957\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32200][55000]\t Training Loss 1.3102\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [32250][55000]\t Training Loss 0.0130\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32450][55000]\t Training Loss 0.2186\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32500][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32550][55000]\t Training Loss 0.0271\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32650][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32700][55000]\t Training Loss 0.3934\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32800][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32850][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32900][55000]\t Training Loss 0.4057\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [32950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33050][55000]\t Training Loss 0.0024\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33100][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33150][55000]\t Training Loss 0.1067\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33200][55000]\t Training Loss 3.0622\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [33250][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33300][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33450][55000]\t Training Loss 1.2665\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [33500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33600][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33650][55000]\t Training Loss 3.6606\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [33700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33750][55000]\t Training Loss 0.3999\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33800][55000]\t Training Loss 1.8872\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [33850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33900][55000]\t Training Loss 0.1862\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [33950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34000][55000]\t Training Loss 0.4500\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34050][55000]\t Training Loss 0.0587\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34200][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34250][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34500][55000]\t Training Loss 0.0257\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34700][55000]\t Training Loss 0.0086\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34750][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34900][55000]\t Training Loss 0.0196\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [34950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35200][55000]\t Training Loss 0.0298\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35250][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35300][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35750][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35800][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35850][55000]\t Training Loss 3.3144\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [35900][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [35950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36050][55000]\t Training Loss 6.7204\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [36100][55000]\t Training Loss 0.4626\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36200][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36300][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36350][55000]\t Training Loss 3.1151\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [36400][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4][10]\t Batch [36450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36750][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [36950][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37050][55000]\t Training Loss 1.5379\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [37100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37200][55000]\t Training Loss 4.2521\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [37250][55000]\t Training Loss 0.6840\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37300][55000]\t Training Loss 0.1241\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37350][55000]\t Training Loss 0.0551\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37400][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37600][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37700][55000]\t Training Loss 0.0076\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37750][55000]\t Training Loss 0.0286\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37800][55000]\t Training Loss 0.0229\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [37950][55000]\t Training Loss 1.1880\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [38000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [38050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [38100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [38150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [38200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [38250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [38300][55000]\t Training Loss 0.1418\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [38350][55000]\t Training Loss 2.0613\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [38400][55000]\t Training Loss 0.4488\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [38450][55000]\t Training Loss 0.0109\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [38500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [38550][55000]\t Training Loss 0.3035\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [38600][55000]\t Training Loss 0.0243\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [38650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [38700][55000]\t Training Loss 6.1811\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [38750][55000]\t Training Loss 17.6210\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [38800][55000]\t Training Loss 0.2003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [38850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [38900][55000]\t Training Loss 21.1415\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [38950][55000]\t Training Loss 0.1107\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39000][55000]\t Training Loss 0.0104\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39250][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39600][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [39950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40200][55000]\t Training Loss 4.1595\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [40250][55000]\t Training Loss 0.1046\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40300][55000]\t Training Loss 0.0064\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40400][55000]\t Training Loss 15.0343\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [40450][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40600][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40650][55000]\t Training Loss 0.2019\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40700][55000]\t Training Loss 2.1351\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [40750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40800][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40850][55000]\t Training Loss 0.0059\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40900][55000]\t Training Loss 0.0695\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [40950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41050][55000]\t Training Loss 0.0086\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41100][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41150][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41300][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41550][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41600][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41650][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41800][55000]\t Training Loss 25.6544\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [41850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41900][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [41950][55000]\t Training Loss 0.0266\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42200][55000]\t Training Loss 29.9309\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [42250][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42400][55000]\t Training Loss 0.1688\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4][10]\t Batch [42550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42600][55000]\t Training Loss 0.2328\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42650][55000]\t Training Loss 0.1210\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42750][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42800][55000]\t Training Loss 0.1405\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [42950][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43000][55000]\t Training Loss 0.1625\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43150][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43200][55000]\t Training Loss 0.0348\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43400][55000]\t Training Loss 0.0028\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43450][55000]\t Training Loss 4.2427\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [43500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43550][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43600][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43650][55000]\t Training Loss 0.0585\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [43950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44000][55000]\t Training Loss 4.3900\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [44050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44150][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44200][55000]\t Training Loss 1.0873\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [44250][55000]\t Training Loss 0.0088\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44300][55000]\t Training Loss 5.9087\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [44350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44600][55000]\t Training Loss 0.2355\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44650][55000]\t Training Loss 0.0053\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44700][55000]\t Training Loss 0.1050\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [44950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45250][55000]\t Training Loss 0.4767\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45400][55000]\t Training Loss 0.0250\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45450][55000]\t Training Loss 0.4742\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45500][55000]\t Training Loss 17.7044\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [45550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45600][55000]\t Training Loss 5.8095\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [45650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45900][55000]\t Training Loss 0.1647\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [45950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46200][55000]\t Training Loss 0.2339\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46300][55000]\t Training Loss 0.2628\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46400][55000]\t Training Loss 0.0065\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46500][55000]\t Training Loss 1.4289\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [46550][55000]\t Training Loss 11.2577\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [46600][55000]\t Training Loss 0.3932\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46700][55000]\t Training Loss 0.0939\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46800][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46850][55000]\t Training Loss 1.1699\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [46900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [46950][55000]\t Training Loss 0.0024\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47000][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47050][55000]\t Training Loss 12.3752\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [47100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47150][55000]\t Training Loss 0.7767\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [47200][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47300][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47350][55000]\t Training Loss 16.1885\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [47400][55000]\t Training Loss 0.4766\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47450][55000]\t Training Loss 0.0686\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47500][55000]\t Training Loss 0.0271\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47550][55000]\t Training Loss 8.0039\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [47600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47850][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [47950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48050][55000]\t Training Loss 0.0068\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48100][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48150][55000]\t Training Loss 0.0512\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48200][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48250][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48350][55000]\t Training Loss 0.6106\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48450][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48550][55000]\t Training Loss 0.0276\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48650][55000]\t Training Loss 0.0209\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4][10]\t Batch [48750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48800][55000]\t Training Loss 0.0095\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48850][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [48950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49000][55000]\t Training Loss 12.0219\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [49050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49100][55000]\t Training Loss 0.0040\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49150][55000]\t Training Loss 0.1826\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49300][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49450][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49500][55000]\t Training Loss 5.2124\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [49550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49600][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49900][55000]\t Training Loss 0.0648\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [49950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50200][55000]\t Training Loss 0.0083\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50250][55000]\t Training Loss 4.4886\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [50300][55000]\t Training Loss 0.0071\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50350][55000]\t Training Loss 3.5838\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [50400][55000]\t Training Loss 10.2671\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [50450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50550][55000]\t Training Loss 0.0060\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50700][55000]\t Training Loss 0.0073\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50800][55000]\t Training Loss 1.0868\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [50850][55000]\t Training Loss 0.0096\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [50950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51000][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51100][55000]\t Training Loss 0.0222\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51200][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51250][55000]\t Training Loss 0.0027\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51300][55000]\t Training Loss 0.0029\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51350][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51450][55000]\t Training Loss 0.0064\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51500][55000]\t Training Loss 4.9872\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [51550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51650][55000]\t Training Loss 1.3586\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [51700][55000]\t Training Loss 0.9832\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [51750][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [51950][55000]\t Training Loss 0.0043\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52000][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52050][55000]\t Training Loss 0.0160\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52100][55000]\t Training Loss 0.0109\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52200][55000]\t Training Loss 0.0873\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52300][55000]\t Training Loss 1.6311\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [52350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52600][55000]\t Training Loss 0.0919\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52800][55000]\t Training Loss 0.2805\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52850][55000]\t Training Loss 0.0232\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [52950][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53000][55000]\t Training Loss 0.0524\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53050][55000]\t Training Loss 0.6617\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53200][55000]\t Training Loss 0.0877\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53350][55000]\t Training Loss 1.2315\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [53400][55000]\t Training Loss 0.1007\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53500][55000]\t Training Loss 0.0064\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53600][55000]\t Training Loss 1.4381\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [53650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53700][55000]\t Training Loss 0.2345\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53850][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53900][55000]\t Training Loss 0.0140\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [53950][55000]\t Training Loss 0.0435\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54050][55000]\t Training Loss 0.2765\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54100][55000]\t Training Loss 0.0598\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54150][55000]\t Training Loss 0.2234\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54200][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54250][55000]\t Training Loss 0.0320\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54350][55000]\t Training Loss 0.0189\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54400][55000]\t Training Loss 0.0039\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54600][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54650][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54750][55000]\t Training Loss 1.0289\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [54800][55000]\t Training Loss 3.7132\t Accuracy 0.0000\n",
      "Epoch [4][10]\t Batch [54850][55000]\t Training Loss 4.5701\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4][10]\t Batch [54900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [54950][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "\n",
      "Epoch [4]\t Average training loss 0.7265\t Average training accuracy 0.8855\n",
      "Epoch [4]\t Average validation loss 0.6763\t Average validation accuracy 0.8918\n",
      "\n",
      "Epoch [5][10]\t Batch [0][55000]\t Training Loss 0.0083\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [100][55000]\t Training Loss 0.0145\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [150][55000]\t Training Loss 0.0213\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [250][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [300][55000]\t Training Loss 0.1798\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [450][55000]\t Training Loss 0.5881\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [500][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [600][55000]\t Training Loss 0.1807\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [700][55000]\t Training Loss 7.0435\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [750][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [800][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [850][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [900][55000]\t Training Loss 0.0096\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1200][55000]\t Training Loss 0.2459\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1250][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1350][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1400][55000]\t Training Loss 2.4014\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [1450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1600][55000]\t Training Loss 0.0110\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1650][55000]\t Training Loss 0.2170\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1850][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1950][55000]\t Training Loss 0.0095\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2200][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2600][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2650][55000]\t Training Loss 0.0740\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2700][55000]\t Training Loss 0.0123\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2800][55000]\t Training Loss 1.3767\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [2850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2900][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2950][55000]\t Training Loss 0.0054\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3150][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3200][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3250][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3400][55000]\t Training Loss 0.8777\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3500][55000]\t Training Loss 0.0362\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3550][55000]\t Training Loss 4.4716\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [3600][55000]\t Training Loss 0.0142\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3650][55000]\t Training Loss 0.4323\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3750][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3800][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3850][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [3950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4000][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4050][55000]\t Training Loss 0.3412\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4200][55000]\t Training Loss 0.0075\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4250][55000]\t Training Loss 0.1560\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4300][55000]\t Training Loss 4.5839\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [4350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4400][55000]\t Training Loss 0.0055\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4450][55000]\t Training Loss 3.5141\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [4500][55000]\t Training Loss 0.1397\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4550][55000]\t Training Loss 0.0029\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4650][55000]\t Training Loss 6.1838\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [4700][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4850][55000]\t Training Loss 0.5555\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [4900][55000]\t Training Loss 3.1440\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [4950][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5000][55000]\t Training Loss 7.0791\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [5050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5100][55000]\t Training Loss 0.0890\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5250][55000]\t Training Loss 3.5354\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [5300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5400][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5450][55000]\t Training Loss 0.0934\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5750][55000]\t Training Loss 0.0336\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5800][55000]\t Training Loss 1.1775\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [5850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [5950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6000][55000]\t Training Loss 0.3490\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6100][55000]\t Training Loss 0.0127\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5][10]\t Batch [6150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6200][55000]\t Training Loss 4.3461\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [6250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6450][55000]\t Training Loss 2.8162\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [6500][55000]\t Training Loss 0.0387\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6600][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6650][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6700][55000]\t Training Loss 0.0280\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6750][55000]\t Training Loss 0.0171\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6800][55000]\t Training Loss 0.2408\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [6950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [7000][55000]\t Training Loss 17.0849\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [7050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [7100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [7150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [7200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [7250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [7300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [7350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [7400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [7450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [7500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [7550][55000]\t Training Loss 1.1963\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [7600][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [7650][55000]\t Training Loss 1.4332\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [7700][55000]\t Training Loss 0.0212\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [7750][55000]\t Training Loss 0.0105\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [7800][55000]\t Training Loss 7.1072\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [7850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [7900][55000]\t Training Loss 2.4118\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [7950][55000]\t Training Loss 0.5311\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8050][55000]\t Training Loss 0.0071\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8100][55000]\t Training Loss 9.0696\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [8150][55000]\t Training Loss 2.4362\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [8200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8300][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8350][55000]\t Training Loss 5.8506\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [8400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8550][55000]\t Training Loss 0.5677\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8600][55000]\t Training Loss 2.4809\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [8650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8700][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8750][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8900][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [8950][55000]\t Training Loss 0.1049\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9100][55000]\t Training Loss 4.8106\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [9150][55000]\t Training Loss 0.1625\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9200][55000]\t Training Loss 0.0043\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9350][55000]\t Training Loss 9.8194\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [9400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9550][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9650][55000]\t Training Loss 0.1503\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9700][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9750][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9850][55000]\t Training Loss 6.4435\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [9900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [9950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10050][55000]\t Training Loss 0.2846\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10100][55000]\t Training Loss 2.0371\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [10150][55000]\t Training Loss 0.3126\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10200][55000]\t Training Loss 0.0565\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10300][55000]\t Training Loss 0.2644\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10350][55000]\t Training Loss 19.6469\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [10400][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10450][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [10900][55000]\t Training Loss 0.7902\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [10950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11050][55000]\t Training Loss 5.0559\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [11100][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11400][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11800][55000]\t Training Loss 0.0236\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [11950][55000]\t Training Loss 0.1675\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [12000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [12050][55000]\t Training Loss 0.1192\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [12100][55000]\t Training Loss 0.1579\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [12150][55000]\t Training Loss 23.8786\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [12200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5][10]\t Batch [12250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [12300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [12350][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [12400][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [12450][55000]\t Training Loss 11.9344\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [12500][55000]\t Training Loss 5.8739\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [12550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [12600][55000]\t Training Loss 0.0205\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [12650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [12700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [12750][55000]\t Training Loss 3.3564\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [12800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [12850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [12900][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [12950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13150][55000]\t Training Loss 0.0980\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13200][55000]\t Training Loss 2.8758\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [13250][55000]\t Training Loss 0.0667\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13350][55000]\t Training Loss 0.0298\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13400][55000]\t Training Loss 2.7055\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [13450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13500][55000]\t Training Loss 0.1523\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13550][55000]\t Training Loss 0.0070\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13600][55000]\t Training Loss 0.0081\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13700][55000]\t Training Loss 0.1056\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13750][55000]\t Training Loss 4.2614\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [13800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [13950][55000]\t Training Loss 14.1018\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [14000][55000]\t Training Loss 0.0029\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14100][55000]\t Training Loss 0.1170\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14300][55000]\t Training Loss 0.1248\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14400][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14650][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14750][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14800][55000]\t Training Loss 0.0076\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14850][55000]\t Training Loss 0.2030\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [14950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15000][55000]\t Training Loss 3.2915\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [15050][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15200][55000]\t Training Loss 0.0550\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15550][55000]\t Training Loss 9.1110\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [15600][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15700][55000]\t Training Loss 0.5432\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15800][55000]\t Training Loss 4.5230\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [15850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [15950][55000]\t Training Loss 0.0171\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16100][55000]\t Training Loss 0.2392\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16150][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16250][55000]\t Training Loss 6.3525\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [16300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16350][55000]\t Training Loss 4.2883\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [16400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16450][55000]\t Training Loss 0.0513\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16550][55000]\t Training Loss 0.0223\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16650][55000]\t Training Loss 4.8317\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [16700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16800][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16850][55000]\t Training Loss 0.0045\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [16950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17000][55000]\t Training Loss 0.2068\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17100][55000]\t Training Loss 1.5990\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [17150][55000]\t Training Loss 0.0237\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17200][55000]\t Training Loss 3.3202\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [17250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17450][55000]\t Training Loss 0.0156\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17500][55000]\t Training Loss 1.0628\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [17550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17700][55000]\t Training Loss 0.0306\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17800][55000]\t Training Loss 7.3419\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [17850][55000]\t Training Loss 0.0186\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [17950][55000]\t Training Loss 12.3265\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [18000][55000]\t Training Loss 0.1934\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18200][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18250][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18300][55000]\t Training Loss 0.0406\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18450][55000]\t Training Loss 8.2622\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [18500][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5][10]\t Batch [18550][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18600][55000]\t Training Loss 0.0097\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18650][55000]\t Training Loss 0.0054\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18800][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18850][55000]\t Training Loss 0.0048\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18900][55000]\t Training Loss 0.0068\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [18950][55000]\t Training Loss 0.0087\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19300][55000]\t Training Loss 0.1833\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19400][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19650][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19850][55000]\t Training Loss 0.0070\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19900][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [19950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20000][55000]\t Training Loss 0.0038\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20200][55000]\t Training Loss 0.0880\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20300][55000]\t Training Loss 3.7440\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [20350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20400][55000]\t Training Loss 0.0483\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20450][55000]\t Training Loss 0.0042\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20500][55000]\t Training Loss 0.3053\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20550][55000]\t Training Loss 0.0045\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20600][55000]\t Training Loss 1.6010\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [20650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20700][55000]\t Training Loss 0.0039\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20800][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20900][55000]\t Training Loss 0.1963\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [20950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21000][55000]\t Training Loss 0.0047\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21200][55000]\t Training Loss 3.9589\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [21250][55000]\t Training Loss 0.4042\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21400][55000]\t Training Loss 0.1970\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21750][55000]\t Training Loss 7.4010\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [21800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21850][55000]\t Training Loss 0.0945\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [21950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22000][55000]\t Training Loss 3.3213\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [22050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22200][55000]\t Training Loss 0.0220\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22250][55000]\t Training Loss 0.0374\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22450][55000]\t Training Loss 0.0230\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22600][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22750][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22800][55000]\t Training Loss 14.7358\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [22850][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [22950][55000]\t Training Loss 12.0769\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [23000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23050][55000]\t Training Loss 0.3803\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23100][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23150][55000]\t Training Loss 0.0192\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23400][55000]\t Training Loss 2.5922\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [23450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23500][55000]\t Training Loss 0.4270\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23700][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23800][55000]\t Training Loss 1.4553\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [23850][55000]\t Training Loss 0.9336\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [23900][55000]\t Training Loss 0.0289\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [23950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [24000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [24050][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [24100][55000]\t Training Loss 1.1417\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [24150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [24200][55000]\t Training Loss 1.0279\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [24250][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [24300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [24350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [24400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [24450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [24500][55000]\t Training Loss 15.7609\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [24550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [24600][55000]\t Training Loss 0.1956\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [24650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [24700][55000]\t Training Loss 0.0357\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [24750][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5][10]\t Batch [24800][55000]\t Training Loss 4.5421\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [24850][55000]\t Training Loss 0.9726\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [24900][55000]\t Training Loss 0.0502\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [24950][55000]\t Training Loss 0.0081\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25150][55000]\t Training Loss 0.3724\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25200][55000]\t Training Loss 0.0749\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25400][55000]\t Training Loss 0.1480\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25500][55000]\t Training Loss 0.4266\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25550][55000]\t Training Loss 0.3280\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25600][55000]\t Training Loss 0.3980\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25650][55000]\t Training Loss 3.0653\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [25700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25750][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [25950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26000][55000]\t Training Loss 0.0559\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26200][55000]\t Training Loss 10.8841\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [26250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26400][55000]\t Training Loss 8.7943\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [26450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26550][55000]\t Training Loss 0.0077\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26650][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26700][55000]\t Training Loss 6.0465\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [26750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26800][55000]\t Training Loss 1.6910\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [26850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [26950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27000][55000]\t Training Loss 0.0631\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27150][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27450][55000]\t Training Loss 0.0870\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27550][55000]\t Training Loss 0.0029\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27600][55000]\t Training Loss 0.0462\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27700][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27750][55000]\t Training Loss 0.0041\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27800][55000]\t Training Loss 1.1779\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [27850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [27900][55000]\t Training Loss 9.1565\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [27950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28000][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28050][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28250][55000]\t Training Loss 0.0070\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28300][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28400][55000]\t Training Loss 0.0152\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28450][55000]\t Training Loss 0.0346\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28550][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28600][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28650][55000]\t Training Loss 10.1516\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [28700][55000]\t Training Loss 7.3738\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [28750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28850][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28900][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [28950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29050][55000]\t Training Loss 0.0741\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29150][55000]\t Training Loss 7.3040\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [29200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29500][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29550][55000]\t Training Loss 10.6315\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [29600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29800][55000]\t Training Loss 17.4541\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [29850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [29950][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30000][55000]\t Training Loss 5.6358\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [30050][55000]\t Training Loss 14.0090\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [30100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30200][55000]\t Training Loss 2.2884\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [30250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30550][55000]\t Training Loss 0.0624\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30600][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30650][55000]\t Training Loss 0.3008\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30750][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30800][55000]\t Training Loss 0.0062\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [30950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [31000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [31050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5][10]\t Batch [31100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [31150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [31200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [31250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [31300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [31350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [31400][55000]\t Training Loss 0.7627\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [31450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [31500][55000]\t Training Loss 6.7526\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [31550][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [31600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [31650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [31700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [31750][55000]\t Training Loss 6.2388\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [31800][55000]\t Training Loss 0.9121\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [31850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [31900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [31950][55000]\t Training Loss 3.5469\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [32000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32300][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32500][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32550][55000]\t Training Loss 0.0423\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32650][55000]\t Training Loss 8.2426\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [32700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32750][55000]\t Training Loss 1.5781\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [32800][55000]\t Training Loss 8.3528\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [32850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32900][55000]\t Training Loss 0.1310\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [32950][55000]\t Training Loss 0.5738\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33000][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33250][55000]\t Training Loss 0.0103\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33400][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33450][55000]\t Training Loss 0.0045\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33850][55000]\t Training Loss 1.0356\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [33900][55000]\t Training Loss 0.0040\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [33950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34050][55000]\t Training Loss 4.2473\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [34100][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34200][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34300][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34350][55000]\t Training Loss 6.2741\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [34400][55000]\t Training Loss 2.0651\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [34450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34550][55000]\t Training Loss 0.0157\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34650][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34700][55000]\t Training Loss 0.0145\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34750][55000]\t Training Loss 0.0046\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34800][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34850][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [34900][55000]\t Training Loss 2.0379\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [34950][55000]\t Training Loss 0.0162\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35300][55000]\t Training Loss 0.0503\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35500][55000]\t Training Loss 0.0040\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35550][55000]\t Training Loss 0.0388\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35600][55000]\t Training Loss 0.0137\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35650][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35750][55000]\t Training Loss 7.2149\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [35800][55000]\t Training Loss 0.0076\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35850][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [35950][55000]\t Training Loss 0.0206\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36050][55000]\t Training Loss 3.7047\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [36100][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36200][55000]\t Training Loss 0.0220\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36250][55000]\t Training Loss 0.0076\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36300][55000]\t Training Loss 0.0495\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36350][55000]\t Training Loss 0.2201\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36600][55000]\t Training Loss 0.0238\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36700][55000]\t Training Loss 0.0092\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36750][55000]\t Training Loss 3.0142\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [36800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36850][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [36900][55000]\t Training Loss 7.9619\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [36950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37000][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37100][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37300][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37350][55000]\t Training Loss 0.0751\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5][10]\t Batch [37400][55000]\t Training Loss 0.0043\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [37950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38000][55000]\t Training Loss 14.1708\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [38050][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38100][55000]\t Training Loss 0.5100\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38150][55000]\t Training Loss 17.6577\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [38200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38250][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38300][55000]\t Training Loss 1.5741\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [38350][55000]\t Training Loss 0.0110\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38450][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38600][55000]\t Training Loss 0.0280\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38700][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38850][55000]\t Training Loss 0.8179\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [38900][55000]\t Training Loss 0.0696\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [38950][55000]\t Training Loss 0.6156\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39000][55000]\t Training Loss 0.0537\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39050][55000]\t Training Loss 0.0198\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39200][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39250][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39400][55000]\t Training Loss 0.0340\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39650][55000]\t Training Loss 0.2355\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39700][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39800][55000]\t Training Loss 4.9948\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [39850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [39950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40100][55000]\t Training Loss 5.3956\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [40150][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40200][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40300][55000]\t Training Loss 4.5150\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [40350][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40500][55000]\t Training Loss 0.0233\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40800][55000]\t Training Loss 4.4140\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [40850][55000]\t Training Loss 2.5239\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [40900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [40950][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41100][55000]\t Training Loss 0.0085\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41250][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41400][55000]\t Training Loss 27.3693\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [41450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [41950][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42000][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42300][55000]\t Training Loss 0.0249\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42350][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42450][55000]\t Training Loss 0.0594\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42500][55000]\t Training Loss 0.0911\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42600][55000]\t Training Loss 9.7767\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [42650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [42950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43000][55000]\t Training Loss 2.8799\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [43050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43100][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43250][55000]\t Training Loss 0.0483\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43350][55000]\t Training Loss 0.1113\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43400][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43450][55000]\t Training Loss 0.1851\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43550][55000]\t Training Loss 1.5880\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [43600][55000]\t Training Loss 0.0262\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5][10]\t Batch [43650][55000]\t Training Loss 0.2687\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43700][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43850][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [43950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44000][55000]\t Training Loss 0.3571\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44200][55000]\t Training Loss 0.0101\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44700][55000]\t Training Loss 0.2202\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44800][55000]\t Training Loss 2.8461\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [44850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [44950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45000][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45100][55000]\t Training Loss 0.0130\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45200][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45400][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45450][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45500][55000]\t Training Loss 0.0058\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45750][55000]\t Training Loss 0.0078\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [45950][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46100][55000]\t Training Loss 0.6349\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46200][55000]\t Training Loss 2.4874\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [46250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46500][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46550][55000]\t Training Loss 0.0038\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46600][55000]\t Training Loss 3.4222\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [46650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46800][55000]\t Training Loss 1.9148\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [46850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46900][55000]\t Training Loss 0.4444\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [46950][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47050][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47200][55000]\t Training Loss 0.1705\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47300][55000]\t Training Loss 0.0821\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47450][55000]\t Training Loss 0.0049\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47750][55000]\t Training Loss 0.5496\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [47900][55000]\t Training Loss 7.3552\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [47950][55000]\t Training Loss 1.3979\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [48000][55000]\t Training Loss 0.5762\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48150][55000]\t Training Loss 0.0268\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48250][55000]\t Training Loss 0.0129\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48300][55000]\t Training Loss 0.0055\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48400][55000]\t Training Loss 0.0098\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48500][55000]\t Training Loss 0.0710\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48850][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [48950][55000]\t Training Loss 3.7566\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [49000][55000]\t Training Loss 4.6679\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [49050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49150][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49250][55000]\t Training Loss 0.0028\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49450][55000]\t Training Loss 4.9518\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [49500][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49750][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [49900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5][10]\t Batch [49950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50100][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50200][55000]\t Training Loss 0.0033\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50350][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50500][55000]\t Training Loss 0.0246\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50550][55000]\t Training Loss 0.0167\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50600][55000]\t Training Loss 0.0083\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50750][55000]\t Training Loss 0.6557\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50800][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [50950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [51000][55000]\t Training Loss 5.7516\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [51050][55000]\t Training Loss 2.5582\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [51100][55000]\t Training Loss 6.1454\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [51150][55000]\t Training Loss 0.6340\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [51200][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [51250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [51300][55000]\t Training Loss 1.6984\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [51350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [51400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [51450][55000]\t Training Loss 0.0166\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [51500][55000]\t Training Loss 18.3621\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [51550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [51600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [51650][55000]\t Training Loss 0.1347\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [51700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [51750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [51800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [51850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [51900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [51950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52100][55000]\t Training Loss 0.0095\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52300][55000]\t Training Loss 0.1712\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52450][55000]\t Training Loss 0.0052\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52500][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52750][55000]\t Training Loss 6.0379\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [52800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52900][55000]\t Training Loss 0.1260\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [52950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53050][55000]\t Training Loss 17.5180\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [53100][55000]\t Training Loss 0.4790\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53250][55000]\t Training Loss 1.8250\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [53300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53350][55000]\t Training Loss 0.0067\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53400][55000]\t Training Loss 0.0101\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53500][55000]\t Training Loss 6.9057\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [53550][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53850][55000]\t Training Loss 0.0456\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [53950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54150][55000]\t Training Loss 1.0114\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [54200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54250][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54450][55000]\t Training Loss 6.6198\t Accuracy 0.0000\n",
      "Epoch [5][10]\t Batch [54500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54550][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54900][55000]\t Training Loss 0.0196\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [54950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "\n",
      "Epoch [5]\t Average training loss 0.7277\t Average training accuracy 0.8851\n",
      "Epoch [5]\t Average validation loss 0.5981\t Average validation accuracy 0.9058\n",
      "\n",
      "Epoch [6][10]\t Batch [0][55000]\t Training Loss 0.0024\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [100][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [150][55000]\t Training Loss 0.0241\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [200][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [400][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [750][55000]\t Training Loss 0.0148\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [850][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [900][55000]\t Training Loss 2.4300\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1000][55000]\t Training Loss 0.0204\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1150][55000]\t Training Loss 0.0230\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1250][55000]\t Training Loss 6.4885\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [1300][55000]\t Training Loss 0.0034\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1450][55000]\t Training Loss 0.0101\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1500][55000]\t Training Loss 0.0406\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1600][55000]\t Training Loss 0.0173\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1700][55000]\t Training Loss 0.0501\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1850][55000]\t Training Loss 0.4530\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [1950][55000]\t Training Loss 3.0627\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [2000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [2050][55000]\t Training Loss 13.6906\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [2100][55000]\t Training Loss 0.2770\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [2150][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [2200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [2250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [2300][55000]\t Training Loss 0.0090\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [2350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [2400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [2450][55000]\t Training Loss 3.0581\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [2500][55000]\t Training Loss 0.3226\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6][10]\t Batch [2550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [2600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [2650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [2700][55000]\t Training Loss 2.1571\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [2750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [2800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [2850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [2900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [2950][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3050][55000]\t Training Loss 0.6978\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3150][55000]\t Training Loss 0.1594\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3500][55000]\t Training Loss 0.1125\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3600][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3800][55000]\t Training Loss 0.0074\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3900][55000]\t Training Loss 0.1417\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [3950][55000]\t Training Loss 0.0063\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4250][55000]\t Training Loss 0.0173\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4450][55000]\t Training Loss 0.0938\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4550][55000]\t Training Loss 0.1123\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4600][55000]\t Training Loss 0.1732\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4850][55000]\t Training Loss 0.0038\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4900][55000]\t Training Loss 0.0029\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [4950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5450][55000]\t Training Loss 0.0916\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5550][55000]\t Training Loss 0.0094\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5600][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5650][55000]\t Training Loss 2.8402\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [5700][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5800][55000]\t Training Loss 0.0052\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [5950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6050][55000]\t Training Loss 0.8633\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [6100][55000]\t Training Loss 0.0068\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6150][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6250][55000]\t Training Loss 12.8814\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [6300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6450][55000]\t Training Loss 0.0111\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6500][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6650][55000]\t Training Loss 0.2568\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6700][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6750][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6800][55000]\t Training Loss 0.0145\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6850][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [6950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7000][55000]\t Training Loss 0.0666\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7150][55000]\t Training Loss 0.9919\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [7200][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7500][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7550][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7750][55000]\t Training Loss 0.4215\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7850][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [7900][55000]\t Training Loss 0.9060\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [7950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8000][55000]\t Training Loss 0.0059\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8300][55000]\t Training Loss 0.5598\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8400][55000]\t Training Loss 0.7941\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8500][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8550][55000]\t Training Loss 0.6900\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8600][55000]\t Training Loss 4.2925\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [8650][55000]\t Training Loss 0.2404\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8750][55000]\t Training Loss 3.0333\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [8800][55000]\t Training Loss 0.0237\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6][10]\t Batch [8850][55000]\t Training Loss 0.1500\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [8900][55000]\t Training Loss 21.5951\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [8950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9000][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9100][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9300][55000]\t Training Loss 0.1067\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9350][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9500][55000]\t Training Loss 2.3484\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [9550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [9950][55000]\t Training Loss 0.0053\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10100][55000]\t Training Loss 1.5325\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [10150][55000]\t Training Loss 0.0226\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10200][55000]\t Training Loss 3.3943\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [10250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10350][55000]\t Training Loss 3.1936\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [10400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10650][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10700][55000]\t Training Loss 1.8319\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [10750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10900][55000]\t Training Loss 0.0066\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [10950][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11000][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11200][55000]\t Training Loss 0.0467\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11500][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11550][55000]\t Training Loss 0.7753\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [11600][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11650][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11700][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11850][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [11950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12100][55000]\t Training Loss 0.0049\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12250][55000]\t Training Loss 0.7220\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [12300][55000]\t Training Loss 0.0085\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12350][55000]\t Training Loss 13.8678\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [12400][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12600][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12850][55000]\t Training Loss 0.0543\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [12950][55000]\t Training Loss 0.0949\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13000][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13150][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13200][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13450][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13600][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13650][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13750][55000]\t Training Loss 9.4439\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [13800][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13900][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [13950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14000][55000]\t Training Loss 0.0053\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14050][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14100][55000]\t Training Loss 0.0047\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14200][55000]\t Training Loss 0.8089\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [14250][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14300][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14550][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [14950][55000]\t Training Loss 0.7489\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6][10]\t Batch [15050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15600][55000]\t Training Loss 0.7607\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15650][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15750][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15900][55000]\t Training Loss 0.0024\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [15950][55000]\t Training Loss 0.0063\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16300][55000]\t Training Loss 0.0040\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16500][55000]\t Training Loss 9.9670\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [16550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16600][55000]\t Training Loss 1.2131\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [16650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16700][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16750][55000]\t Training Loss 0.0091\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16850][55000]\t Training Loss 0.0043\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [16950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17350][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17400][55000]\t Training Loss 4.4340\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [17450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17550][55000]\t Training Loss 10.7164\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [17600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17700][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [17950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18000][55000]\t Training Loss 0.0049\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18200][55000]\t Training Loss 0.0199\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18250][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18350][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18450][55000]\t Training Loss 0.3201\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18800][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18900][55000]\t Training Loss 0.0115\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [18950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19000][55000]\t Training Loss 0.0094\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19100][55000]\t Training Loss 0.2444\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19300][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19400][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19500][55000]\t Training Loss 1.0286\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [19550][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19600][55000]\t Training Loss 23.6976\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [19650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19800][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19850][55000]\t Training Loss 0.0281\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [19950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20150][55000]\t Training Loss 14.0355\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [20200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20250][55000]\t Training Loss 0.1217\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20500][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [20950][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21050][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21250][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21300][55000]\t Training Loss 46.6750\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6][10]\t Batch [21350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21600][55000]\t Training Loss 12.9610\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [21650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21700][55000]\t Training Loss 0.2495\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21850][55000]\t Training Loss 0.0734\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [21950][55000]\t Training Loss 0.0067\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22000][55000]\t Training Loss 0.2989\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22200][55000]\t Training Loss 0.1819\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22300][55000]\t Training Loss 0.1780\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22350][55000]\t Training Loss 0.0244\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22600][55000]\t Training Loss 0.0314\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22650][55000]\t Training Loss 0.0112\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22700][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [22950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23000][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23050][55000]\t Training Loss 0.0202\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23200][55000]\t Training Loss 0.0047\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23250][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23300][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23400][55000]\t Training Loss 1.5781\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [23450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23600][55000]\t Training Loss 0.0492\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23650][55000]\t Training Loss 5.0410\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [23700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23750][55000]\t Training Loss 0.4826\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23850][55000]\t Training Loss 0.0142\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [23950][55000]\t Training Loss 1.6097\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [24000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24250][55000]\t Training Loss 3.2170\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [24300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24450][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24550][55000]\t Training Loss 1.5972\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [24600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24700][55000]\t Training Loss 0.0298\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24750][55000]\t Training Loss 0.0080\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24850][55000]\t Training Loss 0.0063\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [24950][55000]\t Training Loss 0.6838\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25050][55000]\t Training Loss 0.0145\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25100][55000]\t Training Loss 0.0510\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25400][55000]\t Training Loss 0.1192\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25800][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25900][55000]\t Training Loss 0.0169\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [25950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [26000][55000]\t Training Loss 13.0639\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [26050][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [26100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [26150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [26200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [26250][55000]\t Training Loss 0.0298\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [26300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [26350][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [26400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [26450][55000]\t Training Loss 11.3888\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [26500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [26550][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [26600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [26650][55000]\t Training Loss 0.0067\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [26700][55000]\t Training Loss 3.2769\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [26750][55000]\t Training Loss 0.0066\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [26800][55000]\t Training Loss 1.2025\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [26850][55000]\t Training Loss 19.2062\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [26900][55000]\t Training Loss 0.0987\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [26950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [27000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [27050][55000]\t Training Loss 0.0224\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [27100][55000]\t Training Loss 30.2641\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [27150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [27200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [27250][55000]\t Training Loss 0.3226\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [27300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [27350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [27400][55000]\t Training Loss 7.6533\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [27450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [27500][55000]\t Training Loss 0.0061\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [27550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [27600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6][10]\t Batch [27650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [27700][55000]\t Training Loss 0.0043\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [27750][55000]\t Training Loss 10.9275\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [27800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [27850][55000]\t Training Loss 5.6639\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [27900][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [27950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28000][55000]\t Training Loss 0.0905\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28150][55000]\t Training Loss 8.8191\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [28200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28300][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28500][55000]\t Training Loss 0.1759\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28600][55000]\t Training Loss 0.1811\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28750][55000]\t Training Loss 5.1188\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [28800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28850][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [28950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29050][55000]\t Training Loss 17.2697\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [29100][55000]\t Training Loss 4.3951\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [29150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29200][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29500][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29550][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29800][55000]\t Training Loss 0.0069\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29850][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [29950][55000]\t Training Loss 0.0399\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30050][55000]\t Training Loss 0.3234\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30100][55000]\t Training Loss 4.4039\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [30150][55000]\t Training Loss 0.0040\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30200][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30250][55000]\t Training Loss 0.7910\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [30300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30600][55000]\t Training Loss 0.6094\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30650][55000]\t Training Loss 0.0045\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [30950][55000]\t Training Loss 0.0077\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31050][55000]\t Training Loss 0.0316\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31150][55000]\t Training Loss 5.8030\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [31200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31250][55000]\t Training Loss 0.0064\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31300][55000]\t Training Loss 0.3865\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31400][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31450][55000]\t Training Loss 0.0089\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31550][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31600][55000]\t Training Loss 0.6187\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31700][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [31950][55000]\t Training Loss 0.7268\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [32000][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32100][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32150][55000]\t Training Loss 4.3997\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [32200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32400][55000]\t Training Loss 0.2621\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32450][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32850][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32900][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [32950][55000]\t Training Loss 0.1559\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33150][55000]\t Training Loss 8.7079\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [33200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33300][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33550][55000]\t Training Loss 0.1009\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33800][55000]\t Training Loss 0.9600\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6][10]\t Batch [33850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33900][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [33950][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34000][55000]\t Training Loss 0.1797\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34100][55000]\t Training Loss 0.0024\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34200][55000]\t Training Loss 9.1416\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [34250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34600][55000]\t Training Loss 2.1895\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [34650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34850][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [34950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35250][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35400][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35450][55000]\t Training Loss 0.0031\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35500][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35550][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35600][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35700][55000]\t Training Loss 6.9812\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [35750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35850][55000]\t Training Loss 0.3737\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [35950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36000][55000]\t Training Loss 0.0024\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36100][55000]\t Training Loss 0.8540\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [36150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36250][55000]\t Training Loss 2.7634\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [36300][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36400][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36500][55000]\t Training Loss 4.8670\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [36550][55000]\t Training Loss 0.0058\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [36950][55000]\t Training Loss 0.0466\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37050][55000]\t Training Loss 0.5434\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37100][55000]\t Training Loss 0.0261\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37150][55000]\t Training Loss 8.4860\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [37200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37250][55000]\t Training Loss 0.0138\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37300][55000]\t Training Loss 1.1854\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [37350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37400][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37450][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37500][55000]\t Training Loss 8.4531\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [37550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37600][55000]\t Training Loss 0.0229\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37850][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37900][55000]\t Training Loss 0.0113\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [37950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38000][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38150][55000]\t Training Loss 0.0355\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38250][55000]\t Training Loss 0.4807\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38300][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38350][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38400][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38450][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38700][55000]\t Training Loss 3.8459\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [38750][55000]\t Training Loss 0.0664\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38850][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38900][55000]\t Training Loss 0.0112\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [38950][55000]\t Training Loss 0.2874\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39000][55000]\t Training Loss 0.0043\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39150][55000]\t Training Loss 1.2133\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [39200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39250][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39300][55000]\t Training Loss 17.1716\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [39350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39750][55000]\t Training Loss 0.0169\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39800][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [39900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6][10]\t Batch [39950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40300][55000]\t Training Loss 0.0146\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40400][55000]\t Training Loss 0.0044\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40650][55000]\t Training Loss 0.0072\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40850][55000]\t Training Loss 1.5888\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [40900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [40950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41250][55000]\t Training Loss 3.3395\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [41300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41400][55000]\t Training Loss 0.0229\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41600][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41700][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41850][55000]\t Training Loss 0.1678\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41900][55000]\t Training Loss 0.0065\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [41950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42050][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42100][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42150][55000]\t Training Loss 0.0068\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42350][55000]\t Training Loss 5.1802\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [42400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42450][55000]\t Training Loss 0.0871\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42500][55000]\t Training Loss 25.2079\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [42550][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42700][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42900][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [42950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43000][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43100][55000]\t Training Loss 8.3348\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [43150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43250][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43300][55000]\t Training Loss 0.1048\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43350][55000]\t Training Loss 0.1980\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43400][55000]\t Training Loss 0.0622\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43550][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43600][55000]\t Training Loss 11.8026\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [43650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43700][55000]\t Training Loss 6.1914\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [43750][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [43950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44150][55000]\t Training Loss 1.0109\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [44200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44300][55000]\t Training Loss 0.0184\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44350][55000]\t Training Loss 0.2231\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44400][55000]\t Training Loss 0.4057\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44550][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44600][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44700][55000]\t Training Loss 5.5541\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [44750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44800][55000]\t Training Loss 0.0676\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [44950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45000][55000]\t Training Loss 0.0074\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45150][55000]\t Training Loss 2.9937\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [45200][55000]\t Training Loss 0.8854\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [45250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45350][55000]\t Training Loss 0.1403\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45450][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45600][55000]\t Training Loss 1.3895\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [45650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45800][55000]\t Training Loss 0.1046\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45900][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [45950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46000][55000]\t Training Loss 0.0082\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46050][55000]\t Training Loss 0.0245\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46100][55000]\t Training Loss 0.0060\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6][10]\t Batch [46150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46300][55000]\t Training Loss 0.0127\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46450][55000]\t Training Loss 4.0362\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [46500][55000]\t Training Loss 0.0106\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46550][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46600][55000]\t Training Loss 0.5073\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46650][55000]\t Training Loss 0.0031\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46700][55000]\t Training Loss 2.7977\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [46750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46850][55000]\t Training Loss 0.0392\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46900][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [46950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47000][55000]\t Training Loss 0.0179\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47050][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47200][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47300][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47350][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47500][55000]\t Training Loss 5.3707\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [47550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47700][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47750][55000]\t Training Loss 0.0195\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47850][55000]\t Training Loss 0.1029\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [47950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48100][55000]\t Training Loss 0.6456\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48200][55000]\t Training Loss 0.0985\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48550][55000]\t Training Loss 0.2539\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48600][55000]\t Training Loss 0.6097\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48850][55000]\t Training Loss 6.5126\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [48900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [48950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49050][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49150][55000]\t Training Loss 0.4844\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49300][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49350][55000]\t Training Loss 4.8457\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [49400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49450][55000]\t Training Loss 0.0033\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49550][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49750][55000]\t Training Loss 0.0228\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49800][55000]\t Training Loss 7.3537\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [49850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [49950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50050][55000]\t Training Loss 0.0093\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50300][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50350][55000]\t Training Loss 1.1259\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [50400][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50450][55000]\t Training Loss 0.0214\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50900][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [50950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51000][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51100][55000]\t Training Loss 0.8991\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [51150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51200][55000]\t Training Loss 2.2567\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [51250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51550][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51650][55000]\t Training Loss 0.4643\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51700][55000]\t Training Loss 0.3166\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51750][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51800][55000]\t Training Loss 0.0097\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [51950][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [52000][55000]\t Training Loss 0.7968\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [52050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [52100][55000]\t Training Loss 8.7948\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [52150][55000]\t Training Loss 0.0088\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [52200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [52250][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [52300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [52350][55000]\t Training Loss 6.4026\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [52400][55000]\t Training Loss 0.1345\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6][10]\t Batch [52450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [52500][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [52550][55000]\t Training Loss 0.6497\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [52600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [52650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [52700][55000]\t Training Loss 0.9324\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [52750][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [52800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [52850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [52900][55000]\t Training Loss 10.4179\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [52950][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53250][55000]\t Training Loss 5.3057\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [53300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53450][55000]\t Training Loss 0.0950\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53600][55000]\t Training Loss 0.0103\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53650][55000]\t Training Loss 2.1237\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [53700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53900][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [53950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54000][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54200][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54300][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54450][55000]\t Training Loss 3.9191\t Accuracy 0.0000\n",
      "Epoch [6][10]\t Batch [54500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54550][55000]\t Training Loss 0.0191\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54600][55000]\t Training Loss 0.0319\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54900][55000]\t Training Loss 0.0453\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [54950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "\n",
      "Epoch [6]\t Average training loss 0.7254\t Average training accuracy 0.8858\n",
      "Epoch [6]\t Average validation loss 0.8709\t Average validation accuracy 0.8666\n",
      "\n",
      "Epoch [7][10]\t Batch [0][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [100][55000]\t Training Loss 5.9749\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [550][55000]\t Training Loss 0.0028\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [600][55000]\t Training Loss 0.1828\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [650][55000]\t Training Loss 0.0488\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [750][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [850][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1000][55000]\t Training Loss 0.0084\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1150][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1200][55000]\t Training Loss 0.3206\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1250][55000]\t Training Loss 1.6986\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [1300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1450][55000]\t Training Loss 0.0069\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1500][55000]\t Training Loss 0.2293\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1550][55000]\t Training Loss 0.6046\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1700][55000]\t Training Loss 0.0594\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1900][55000]\t Training Loss 0.0067\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2300][55000]\t Training Loss 0.0239\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2350][55000]\t Training Loss 0.0083\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2400][55000]\t Training Loss 0.0386\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2550][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2750][55000]\t Training Loss 0.4106\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2800][55000]\t Training Loss 0.2038\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2850][55000]\t Training Loss 32.2693\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [2900][55000]\t Training Loss 5.5928\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [2950][55000]\t Training Loss 14.2864\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [3000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3150][55000]\t Training Loss 0.3503\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3200][55000]\t Training Loss 0.0067\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3400][55000]\t Training Loss 3.2190\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [3450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3550][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3600][55000]\t Training Loss 0.0091\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3700][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3850][55000]\t Training Loss 0.1309\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [3950][55000]\t Training Loss 0.0041\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4550][55000]\t Training Loss 0.0710\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4700][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4750][55000]\t Training Loss 0.0588\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4850][55000]\t Training Loss 0.1558\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [4950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5000][55000]\t Training Loss 0.0095\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5100][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5250][55000]\t Training Loss 0.0081\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5500][55000]\t Training Loss 0.1352\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5550][55000]\t Training Loss 0.2003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5650][55000]\t Training Loss 0.0674\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7][10]\t Batch [5750][55000]\t Training Loss 0.2931\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [5950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [6000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [6050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [6100][55000]\t Training Loss 8.3345\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [6150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [6200][55000]\t Training Loss 0.1601\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [6250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [6300][55000]\t Training Loss 0.1151\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [6350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [6400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [6450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [6500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [6550][55000]\t Training Loss 2.6440\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [6600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [6650][55000]\t Training Loss 6.6961\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [6700][55000]\t Training Loss 2.1134\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [6750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [6800][55000]\t Training Loss 0.2952\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [6850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [6900][55000]\t Training Loss 5.0246\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [6950][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7100][55000]\t Training Loss 2.0578\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [7150][55000]\t Training Loss 0.0040\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7200][55000]\t Training Loss 11.6530\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [7250][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7350][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7400][55000]\t Training Loss 4.9618\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [7450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7600][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7900][55000]\t Training Loss 0.0119\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [7950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8050][55000]\t Training Loss 0.3534\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8150][55000]\t Training Loss 5.0216\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [8200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8250][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8300][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8350][55000]\t Training Loss 9.6785\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [8400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8600][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8700][55000]\t Training Loss 0.2311\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8750][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8850][55000]\t Training Loss 0.0304\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8900][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [8950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9200][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9350][55000]\t Training Loss 0.0262\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9400][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9550][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9650][55000]\t Training Loss 0.0387\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9700][55000]\t Training Loss 7.1057\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [9750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [9950][55000]\t Training Loss 0.0028\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10200][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10250][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10400][55000]\t Training Loss 10.2265\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [10450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10600][55000]\t Training Loss 4.4886\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [10650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [10950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11000][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11150][55000]\t Training Loss 5.3199\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [11200][55000]\t Training Loss 13.5003\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [11250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11300][55000]\t Training Loss 0.0071\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11400][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11550][55000]\t Training Loss 4.9194\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [11600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11650][55000]\t Training Loss 0.0612\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11700][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11800][55000]\t Training Loss 0.0048\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11850][55000]\t Training Loss 0.0054\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11900][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [11950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7][10]\t Batch [12000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12300][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12650][55000]\t Training Loss 0.0069\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12700][55000]\t Training Loss 0.0581\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [12950][55000]\t Training Loss 5.0119\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [13000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13100][55000]\t Training Loss 0.4378\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13250][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13350][55000]\t Training Loss 0.0039\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13500][55000]\t Training Loss 10.5125\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [13550][55000]\t Training Loss 0.0414\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13650][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13750][55000]\t Training Loss 0.0698\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [13950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14150][55000]\t Training Loss 4.7708\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [14200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14450][55000]\t Training Loss 0.0210\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14800][55000]\t Training Loss 0.0578\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [14850][55000]\t Training Loss 14.5736\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [14900][55000]\t Training Loss 13.7176\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [14950][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15000][55000]\t Training Loss 13.4989\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [15050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15250][55000]\t Training Loss 6.8473\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [15300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15400][55000]\t Training Loss 0.0056\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15450][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15500][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15700][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15750][55000]\t Training Loss 0.2754\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [15950][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16100][55000]\t Training Loss 1.9192\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [16150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16200][55000]\t Training Loss 0.0079\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16250][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16400][55000]\t Training Loss 0.1681\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16450][55000]\t Training Loss 0.0447\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16850][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [16950][55000]\t Training Loss 0.1119\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17000][55000]\t Training Loss 0.0064\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17200][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17350][55000]\t Training Loss 0.6118\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17450][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17550][55000]\t Training Loss 0.0045\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17600][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17650][55000]\t Training Loss 7.1466\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [17700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17750][55000]\t Training Loss 2.1145\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [17800][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [17950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18150][55000]\t Training Loss 0.1961\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18200][55000]\t Training Loss 0.0042\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18250][55000]\t Training Loss 0.0418\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7][10]\t Batch [18300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18350][55000]\t Training Loss 0.4394\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18400][55000]\t Training Loss 0.7591\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [18450][55000]\t Training Loss 0.0186\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18500][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18600][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18650][55000]\t Training Loss 1.6648\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [18700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18750][55000]\t Training Loss 0.4042\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18800][55000]\t Training Loss 1.2215\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [18850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18900][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [18950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19050][55000]\t Training Loss 5.7563\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [19100][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19250][55000]\t Training Loss 0.3153\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19300][55000]\t Training Loss 0.0081\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19350][55000]\t Training Loss 1.3007\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [19400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19450][55000]\t Training Loss 0.0072\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19550][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19700][55000]\t Training Loss 11.4713\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [19750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19850][55000]\t Training Loss 3.6992\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [19900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [19950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20050][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20200][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20300][55000]\t Training Loss 0.1392\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20400][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20450][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20500][55000]\t Training Loss 4.1223\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [20550][55000]\t Training Loss 0.0044\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20800][55000]\t Training Loss 0.0371\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20900][55000]\t Training Loss 0.0165\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [20950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [21000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [21050][55000]\t Training Loss 11.1219\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [21100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [21150][55000]\t Training Loss 3.7111\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [21200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [21250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [21300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [21350][55000]\t Training Loss 2.1924\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [21400][55000]\t Training Loss 0.0917\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [21450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [21500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [21550][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [21600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [21650][55000]\t Training Loss 0.4791\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [21700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [21750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [21800][55000]\t Training Loss 1.2946\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [21850][55000]\t Training Loss 2.4016\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [21900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [21950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22000][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22200][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22350][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22550][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [22950][55000]\t Training Loss 0.0585\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23250][55000]\t Training Loss 0.6820\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23300][55000]\t Training Loss 0.0107\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23550][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23650][55000]\t Training Loss 0.0596\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [23900][55000]\t Training Loss 1.1197\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [23950][55000]\t Training Loss 1.9774\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [24000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24100][55000]\t Training Loss 0.0333\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24150][55000]\t Training Loss 6.8819\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [24200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24450][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24500][55000]\t Training Loss 0.1378\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24550][55000]\t Training Loss 4.3766\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7][10]\t Batch [24600][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24650][55000]\t Training Loss 20.6757\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [24700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24750][55000]\t Training Loss 0.2827\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [24950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25000][55000]\t Training Loss 0.1192\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25150][55000]\t Training Loss 0.0057\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25250][55000]\t Training Loss 0.0063\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25350][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25600][55000]\t Training Loss 0.1412\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25650][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25750][55000]\t Training Loss 0.0392\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25900][55000]\t Training Loss 0.1523\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [25950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26000][55000]\t Training Loss 2.9756\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [26050][55000]\t Training Loss 2.9842\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [26100][55000]\t Training Loss 4.6465\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [26150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26200][55000]\t Training Loss 0.0369\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26600][55000]\t Training Loss 0.0024\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26700][55000]\t Training Loss 2.8197\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [26750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [26950][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27000][55000]\t Training Loss 1.2732\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [27050][55000]\t Training Loss 0.0042\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27150][55000]\t Training Loss 0.1084\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27250][55000]\t Training Loss 0.0039\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27400][55000]\t Training Loss 3.0946\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [27450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27650][55000]\t Training Loss 0.6091\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27850][55000]\t Training Loss 0.1489\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27900][55000]\t Training Loss 0.3202\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [27950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28050][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28150][55000]\t Training Loss 0.0334\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28300][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28450][55000]\t Training Loss 0.0168\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28500][55000]\t Training Loss 3.7130\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [28550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28650][55000]\t Training Loss 0.0389\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28700][55000]\t Training Loss 7.2438\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [28750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28850][55000]\t Training Loss 0.0189\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [28950][55000]\t Training Loss 0.1281\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29100][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29300][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29450][55000]\t Training Loss 0.0048\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29500][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29550][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29600][55000]\t Training Loss 1.4550\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [29650][55000]\t Training Loss 0.0215\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29700][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29850][55000]\t Training Loss 0.0175\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29900][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [29950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30100][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30200][55000]\t Training Loss 0.7510\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [30250][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30300][55000]\t Training Loss 0.0128\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30400][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30450][55000]\t Training Loss 0.0167\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30500][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30550][55000]\t Training Loss 0.8516\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [30600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30800][55000]\t Training Loss 0.0138\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7][10]\t Batch [30850][55000]\t Training Loss 0.0469\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [30950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31150][55000]\t Training Loss 0.0962\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31300][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31400][55000]\t Training Loss 1.1199\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [31450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31500][55000]\t Training Loss 0.0671\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31600][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31800][55000]\t Training Loss 0.4854\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31900][55000]\t Training Loss 0.0596\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [31950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32050][55000]\t Training Loss 1.2502\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [32100][55000]\t Training Loss 3.0816\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [32150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32200][55000]\t Training Loss 0.0179\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32300][55000]\t Training Loss 0.5331\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32450][55000]\t Training Loss 0.5535\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32600][55000]\t Training Loss 0.0035\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32650][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32700][55000]\t Training Loss 1.9839\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [32750][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32850][55000]\t Training Loss 13.8942\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [32900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [32950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [33000][55000]\t Training Loss 4.3102\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [33050][55000]\t Training Loss 0.5812\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [33100][55000]\t Training Loss 24.0023\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [33150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [33200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [33250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [33300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [33350][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [33400][55000]\t Training Loss 3.9354\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [33450][55000]\t Training Loss 4.4319\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [33500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [33550][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [33600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [33650][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [33700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [33750][55000]\t Training Loss 4.1851\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [33800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [33850][55000]\t Training Loss 0.1647\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [33900][55000]\t Training Loss 0.0918\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [33950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34000][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34100][55000]\t Training Loss 5.7980\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [34150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34250][55000]\t Training Loss 0.0087\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34350][55000]\t Training Loss 9.2736\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [34400][55000]\t Training Loss 0.0300\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34500][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34550][55000]\t Training Loss 0.0612\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34650][55000]\t Training Loss 0.0088\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34800][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [34950][55000]\t Training Loss 13.1583\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [35000][55000]\t Training Loss 4.5852\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [35050][55000]\t Training Loss 8.0132\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [35100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35200][55000]\t Training Loss 0.4845\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35300][55000]\t Training Loss 0.3278\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35350][55000]\t Training Loss 0.1161\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35400][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35500][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35550][55000]\t Training Loss 0.0061\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35600][55000]\t Training Loss 0.4623\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35650][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35750][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35900][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [35950][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36200][55000]\t Training Loss 0.0631\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36250][55000]\t Training Loss 0.0177\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36300][55000]\t Training Loss 0.3378\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36350][55000]\t Training Loss 0.0143\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36400][55000]\t Training Loss 0.1661\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36450][55000]\t Training Loss 1.3451\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [36500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36800][55000]\t Training Loss 0.0408\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36850][55000]\t Training Loss 3.0394\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [36900][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [36950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [37000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [37050][55000]\t Training Loss 0.0035\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7][10]\t Batch [37100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [37150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [37200][55000]\t Training Loss 11.1258\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [37250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [37300][55000]\t Training Loss 0.0225\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [37350][55000]\t Training Loss 0.1538\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [37400][55000]\t Training Loss 2.4425\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [37450][55000]\t Training Loss 0.0965\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [37500][55000]\t Training Loss 11.7660\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [37550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [37600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [37650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [37700][55000]\t Training Loss 19.5539\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [37750][55000]\t Training Loss 0.0111\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [37800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [37850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [37900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [37950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38000][55000]\t Training Loss 0.1582\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38150][55000]\t Training Loss 0.3445\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38200][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38300][55000]\t Training Loss 0.0158\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38350][55000]\t Training Loss 0.1099\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38400][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38500][55000]\t Training Loss 0.0218\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38750][55000]\t Training Loss 8.4990\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [38800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [38950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39050][55000]\t Training Loss 8.4150\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [39100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39250][55000]\t Training Loss 0.0270\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39350][55000]\t Training Loss 8.4341\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [39400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39450][55000]\t Training Loss 0.3681\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39550][55000]\t Training Loss 0.1444\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39800][55000]\t Training Loss 0.0051\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [39950][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40400][55000]\t Training Loss 0.0121\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40450][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40650][55000]\t Training Loss 0.0055\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40700][55000]\t Training Loss 0.4389\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40750][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [40950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41050][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41100][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41200][55000]\t Training Loss 0.2132\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41250][55000]\t Training Loss 1.2001\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [41300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41550][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41600][55000]\t Training Loss 1.2306\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [41650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41750][55000]\t Training Loss 0.0357\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41800][55000]\t Training Loss 3.5650\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [41850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [41950][55000]\t Training Loss 0.0058\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42000][55000]\t Training Loss 0.0106\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42100][55000]\t Training Loss 0.1464\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42250][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42450][55000]\t Training Loss 0.2909\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42500][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42550][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42600][55000]\t Training Loss 0.0286\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42650][55000]\t Training Loss 0.2576\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42750][55000]\t Training Loss 0.0567\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42900][55000]\t Training Loss 0.4053\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [42950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43100][55000]\t Training Loss 4.0201\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [43150][55000]\t Training Loss 0.0097\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43200][55000]\t Training Loss 0.0107\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7][10]\t Batch [43350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43400][55000]\t Training Loss 13.2535\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [43450][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43550][55000]\t Training Loss 0.0509\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43600][55000]\t Training Loss 0.0227\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43650][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43700][55000]\t Training Loss 0.0436\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43750][55000]\t Training Loss 7.2231\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [43800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43850][55000]\t Training Loss 0.0414\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [43950][55000]\t Training Loss 2.3892\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [44000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [44050][55000]\t Training Loss 2.6583\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [44100][55000]\t Training Loss 1.9466\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [44150][55000]\t Training Loss 0.0121\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [44200][55000]\t Training Loss 1.0896\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [44250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [44300][55000]\t Training Loss 5.4775\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [44350][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [44400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [44450][55000]\t Training Loss 14.0882\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [44500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [44550][55000]\t Training Loss 0.1172\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [44600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [44650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [44700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [44750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [44800][55000]\t Training Loss 0.9681\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [44850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [44900][55000]\t Training Loss 0.5169\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [44950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [45000][55000]\t Training Loss 17.4535\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [45050][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [45100][55000]\t Training Loss 3.7111\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [45150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [45200][55000]\t Training Loss 0.9871\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [45250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [45300][55000]\t Training Loss 0.2652\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [45350][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [45400][55000]\t Training Loss 3.7465\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [45450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [45500][55000]\t Training Loss 0.2366\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [45550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [45600][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [45650][55000]\t Training Loss 6.0710\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [45700][55000]\t Training Loss 0.0128\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [45750][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [45800][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [45850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [45900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [45950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46000][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46100][55000]\t Training Loss 0.0377\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46150][55000]\t Training Loss 0.0201\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46200][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46300][55000]\t Training Loss 30.7589\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [46350][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46450][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46650][55000]\t Training Loss 1.3514\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [46700][55000]\t Training Loss 0.0151\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46750][55000]\t Training Loss 0.0387\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [46950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47000][55000]\t Training Loss 0.1204\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47100][55000]\t Training Loss 9.2177\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [47150][55000]\t Training Loss 0.1115\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47300][55000]\t Training Loss 1.5329\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [47350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47550][55000]\t Training Loss 0.0112\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47600][55000]\t Training Loss 0.2371\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47750][55000]\t Training Loss 0.0227\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [47950][55000]\t Training Loss 0.0115\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48100][55000]\t Training Loss 3.7059\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [48150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48200][55000]\t Training Loss 0.0043\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48250][55000]\t Training Loss 0.0243\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48500][55000]\t Training Loss 0.8152\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [48550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48650][55000]\t Training Loss 0.0452\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48700][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [48950][55000]\t Training Loss 1.5692\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [49000][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [49050][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [49100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [49150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [49200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [49250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [49300][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [49350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [49400][55000]\t Training Loss 3.7326\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [49450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [49500][55000]\t Training Loss 0.3759\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [49550][55000]\t Training Loss 14.1040\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [49600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7][10]\t Batch [49650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [49700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [49750][55000]\t Training Loss 0.0086\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [49800][55000]\t Training Loss 0.8612\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [49850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [49900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [49950][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50000][55000]\t Training Loss 2.6047\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [50050][55000]\t Training Loss 1.7241\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [50100][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50300][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50350][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50400][55000]\t Training Loss 0.0033\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50450][55000]\t Training Loss 0.0225\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50750][55000]\t Training Loss 11.4640\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [50800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50900][55000]\t Training Loss 0.0053\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51050][55000]\t Training Loss 0.2886\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51100][55000]\t Training Loss 2.2538\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [51150][55000]\t Training Loss 9.4660\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [51200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51250][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51350][55000]\t Training Loss 0.0570\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51400][55000]\t Training Loss 0.3778\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51450][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51650][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51750][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [51950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52050][55000]\t Training Loss 0.0802\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52150][55000]\t Training Loss 0.2149\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52500][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52600][55000]\t Training Loss 0.0325\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52700][55000]\t Training Loss 0.9901\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [52750][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52800][55000]\t Training Loss 10.7717\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [52850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [52900][55000]\t Training Loss 1.9530\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [52950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53050][55000]\t Training Loss 0.5894\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53500][55000]\t Training Loss 0.1762\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53600][55000]\t Training Loss 0.0211\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53650][55000]\t Training Loss 0.1547\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53750][55000]\t Training Loss 0.0600\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53800][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53850][55000]\t Training Loss 4.7154\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [53900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [53950][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54000][55000]\t Training Loss 0.0067\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54050][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54100][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54150][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54250][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54350][55000]\t Training Loss 0.0085\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54450][55000]\t Training Loss 0.0070\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54550][55000]\t Training Loss 0.6943\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54750][55000]\t Training Loss 3.2890\t Accuracy 0.0000\n",
      "Epoch [7][10]\t Batch [54800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54850][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [54950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "\n",
      "Epoch [7]\t Average training loss 0.7207\t Average training accuracy 0.8862\n",
      "Epoch [7]\t Average validation loss 0.5436\t Average validation accuracy 0.9122\n",
      "\n",
      "Epoch [8][10]\t Batch [0][55000]\t Training Loss 0.0157\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [100][55000]\t Training Loss 0.0548\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [300][55000]\t Training Loss 0.6288\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [350][55000]\t Training Loss 0.0038\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [400][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [450][55000]\t Training Loss 0.0027\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [700][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [800][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [900][55000]\t Training Loss 0.0077\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [950][55000]\t Training Loss 8.5613\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [1000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1050][55000]\t Training Loss 0.0269\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1100][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1150][55000]\t Training Loss 0.0463\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1250][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1300][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1350][55000]\t Training Loss 0.0306\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1450][55000]\t Training Loss 0.0024\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1550][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1700][55000]\t Training Loss 6.2022\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [1750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1800][55000]\t Training Loss 0.2239\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1850][55000]\t Training Loss 0.2704\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1900][55000]\t Training Loss 1.2639\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [1950][55000]\t Training Loss 0.0287\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2000][55000]\t Training Loss 11.3281\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [2050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2150][55000]\t Training Loss 0.0114\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2300][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2450][55000]\t Training Loss 1.5637\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [2500][55000]\t Training Loss 0.0306\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8][10]\t Batch [2550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2600][55000]\t Training Loss 0.0694\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2650][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2850][55000]\t Training Loss 0.0064\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3250][55000]\t Training Loss 0.0050\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3350][55000]\t Training Loss 1.6881\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [3400][55000]\t Training Loss 1.0568\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [3450][55000]\t Training Loss 12.1110\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [3500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3550][55000]\t Training Loss 0.0057\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3650][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3700][55000]\t Training Loss 0.1715\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3750][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3800][55000]\t Training Loss 2.6823\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [3850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [3950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4100][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4150][55000]\t Training Loss 4.8324\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [4200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4650][55000]\t Training Loss 0.0057\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4700][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4800][55000]\t Training Loss 0.3373\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4850][55000]\t Training Loss 0.0052\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [4900][55000]\t Training Loss 1.4561\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [4950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5200][55000]\t Training Loss 0.0217\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5250][55000]\t Training Loss 0.0120\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5350][55000]\t Training Loss 2.6778\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [5400][55000]\t Training Loss 0.0840\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5600][55000]\t Training Loss 2.4991\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [5650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5800][55000]\t Training Loss 0.0971\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [5950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6150][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6200][55000]\t Training Loss 0.0069\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6450][55000]\t Training Loss 0.1046\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6700][55000]\t Training Loss 0.0216\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6750][55000]\t Training Loss 0.1005\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [6950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7200][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7350][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7400][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7450][55000]\t Training Loss 1.1566\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [7500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7650][55000]\t Training Loss 0.0146\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7750][55000]\t Training Loss 0.0366\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7850][55000]\t Training Loss 0.0078\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7900][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [7950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8300][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8400][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8650][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8700][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8][10]\t Batch [8750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8850][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8900][55000]\t Training Loss 0.0088\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [8950][55000]\t Training Loss 2.3660\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [9000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9050][55000]\t Training Loss 0.1077\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9100][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9150][55000]\t Training Loss 0.3415\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9200][55000]\t Training Loss 9.2744\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [9250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9300][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9350][55000]\t Training Loss 0.0089\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9400][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9450][55000]\t Training Loss 0.0048\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9750][55000]\t Training Loss 2.3995\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [9800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [9950][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10150][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10450][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10500][55000]\t Training Loss 0.0045\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10650][55000]\t Training Loss 10.8819\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [10700][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10750][55000]\t Training Loss 2.8609\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [10800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [10900][55000]\t Training Loss 13.0638\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [10950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11000][55000]\t Training Loss 0.0090\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11100][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11150][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11200][55000]\t Training Loss 19.3809\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [11250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11350][55000]\t Training Loss 0.0074\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11400][55000]\t Training Loss 0.0057\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11450][55000]\t Training Loss 0.0060\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11550][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11650][55000]\t Training Loss 0.1768\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11700][55000]\t Training Loss 0.0027\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11750][55000]\t Training Loss 6.5129\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [11800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11850][55000]\t Training Loss 0.1812\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11900][55000]\t Training Loss 0.1830\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [11950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12000][55000]\t Training Loss 13.6215\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [12050][55000]\t Training Loss 0.1551\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12100][55000]\t Training Loss 0.0154\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12250][55000]\t Training Loss 0.0131\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12350][55000]\t Training Loss 0.0394\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12400][55000]\t Training Loss 1.7995\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [12450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12650][55000]\t Training Loss 0.0569\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12700][55000]\t Training Loss 0.4651\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12800][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12900][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [12950][55000]\t Training Loss 0.1016\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13000][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13050][55000]\t Training Loss 0.0078\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13100][55000]\t Training Loss 2.3467\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [13150][55000]\t Training Loss 16.4613\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [13200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13250][55000]\t Training Loss 8.8437\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [13300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13350][55000]\t Training Loss 0.0363\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13650][55000]\t Training Loss 0.3467\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13700][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [13950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14050][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14350][55000]\t Training Loss 0.0640\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14450][55000]\t Training Loss 3.5563\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [14500][55000]\t Training Loss 8.4942\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [14550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14700][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14800][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [14900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8][10]\t Batch [14950][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15100][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15200][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15250][55000]\t Training Loss 0.0168\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15350][55000]\t Training Loss 0.6388\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15550][55000]\t Training Loss 1.1007\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [15600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15650][55000]\t Training Loss 1.6175\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [15700][55000]\t Training Loss 0.2163\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15900][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [15950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16100][55000]\t Training Loss 1.2595\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [16150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16250][55000]\t Training Loss 11.3335\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [16300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16550][55000]\t Training Loss 0.0409\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16600][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16750][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16850][55000]\t Training Loss 0.0038\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [16900][55000]\t Training Loss 3.7330\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [16950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17150][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17200][55000]\t Training Loss 0.0069\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17250][55000]\t Training Loss 0.0082\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17350][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17400][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17450][55000]\t Training Loss 0.0342\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17500][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17800][55000]\t Training Loss 0.0047\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17850][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17900][55000]\t Training Loss 0.5248\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [17950][55000]\t Training Loss 0.7578\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18000][55000]\t Training Loss 0.0054\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18150][55000]\t Training Loss 0.0190\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18450][55000]\t Training Loss 0.0108\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18600][55000]\t Training Loss 0.5314\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18650][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18700][55000]\t Training Loss 9.0200\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [18750][55000]\t Training Loss 0.0139\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18850][55000]\t Training Loss 0.5012\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [18900][55000]\t Training Loss 2.6441\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [18950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19050][55000]\t Training Loss 0.2525\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19100][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19400][55000]\t Training Loss 0.0040\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19550][55000]\t Training Loss 0.8796\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [19600][55000]\t Training Loss 5.5852\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [19650][55000]\t Training Loss 0.0048\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19700][55000]\t Training Loss 0.0060\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19850][55000]\t Training Loss 2.3615\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [19900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [19950][55000]\t Training Loss 0.6742\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20050][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20300][55000]\t Training Loss 2.3862\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [20350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20400][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20450][55000]\t Training Loss 0.6021\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20750][55000]\t Training Loss 11.0455\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [20800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20850][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [20950][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21000][55000]\t Training Loss 3.6059\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [21050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21100][55000]\t Training Loss 0.2576\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21150][55000]\t Training Loss 0.4164\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8][10]\t Batch [21200][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21500][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21550][55000]\t Training Loss 1.1960\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [21600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21650][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21750][55000]\t Training Loss 0.0055\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21850][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [21950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [22000][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [22050][55000]\t Training Loss 2.9335\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [22100][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [22150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [22200][55000]\t Training Loss 9.5024\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [22250][55000]\t Training Loss 19.1947\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [22300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [22350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [22400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [22450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [22500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [22550][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [22600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [22650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [22700][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [22750][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [22800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [22850][55000]\t Training Loss 13.3914\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [22900][55000]\t Training Loss 4.8268\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [22950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23050][55000]\t Training Loss 10.6119\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [23100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23150][55000]\t Training Loss 0.2661\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23250][55000]\t Training Loss 0.3891\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23300][55000]\t Training Loss 0.0738\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23350][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23400][55000]\t Training Loss 0.0057\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23800][55000]\t Training Loss 3.0481\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [23850][55000]\t Training Loss 4.4995\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [23900][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [23950][55000]\t Training Loss 0.0139\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24000][55000]\t Training Loss 0.0053\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24050][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24150][55000]\t Training Loss 1.0227\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [24200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24350][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24750][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [24950][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25050][55000]\t Training Loss 1.0059\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25100][55000]\t Training Loss 0.1982\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25200][55000]\t Training Loss 0.8971\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [25250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25350][55000]\t Training Loss 0.0140\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25500][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25600][55000]\t Training Loss 0.1619\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25750][55000]\t Training Loss 0.0045\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25850][55000]\t Training Loss 14.1281\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [25900][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [25950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26050][55000]\t Training Loss 5.4255\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [26100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26850][55000]\t Training Loss 0.0384\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [26950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27100][55000]\t Training Loss 5.4234\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [27150][55000]\t Training Loss 0.3738\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27200][55000]\t Training Loss 3.1795\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [27250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27300][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8][10]\t Batch [27350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27450][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27500][55000]\t Training Loss 0.0054\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27650][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27750][55000]\t Training Loss 0.0062\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27850][55000]\t Training Loss 0.0798\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [27950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28100][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28200][55000]\t Training Loss 1.0048\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [28250][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28300][55000]\t Training Loss 0.0106\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28400][55000]\t Training Loss 0.4123\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28500][55000]\t Training Loss 0.0083\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28850][55000]\t Training Loss 0.1704\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28900][55000]\t Training Loss 0.8234\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [28950][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29000][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29050][55000]\t Training Loss 0.7305\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29250][55000]\t Training Loss 1.7310\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [29300][55000]\t Training Loss 0.2946\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29400][55000]\t Training Loss 0.0067\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29500][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29550][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29600][55000]\t Training Loss 1.0727\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [29650][55000]\t Training Loss 0.1371\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29800][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29850][55000]\t Training Loss 3.3635\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [29900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [29950][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30150][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30250][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30400][55000]\t Training Loss 0.3418\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30450][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30500][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30700][55000]\t Training Loss 0.0058\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30750][55000]\t Training Loss 2.0156\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [30800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [30950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31100][55000]\t Training Loss 0.0859\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31500][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31600][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31700][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [31950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32000][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32050][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32100][55000]\t Training Loss 4.9565\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [32150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32250][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32350][55000]\t Training Loss 2.3595\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [32400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32500][55000]\t Training Loss 0.0396\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32750][55000]\t Training Loss 31.2962\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [32800][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32900][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [32950][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33000][55000]\t Training Loss 0.0193\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33200][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33300][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33400][55000]\t Training Loss 0.0058\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33450][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33500][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8][10]\t Batch [33550][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33600][55000]\t Training Loss 0.0373\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33800][55000]\t Training Loss 0.0386\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [33950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34000][55000]\t Training Loss 12.0898\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [34050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34400][55000]\t Training Loss 5.1590\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [34450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34750][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34800][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34850][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [34950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35100][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35200][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35250][55000]\t Training Loss 0.0145\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35350][55000]\t Training Loss 0.0040\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35400][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35550][55000]\t Training Loss 6.2735\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [35600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35750][55000]\t Training Loss 1.3171\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [35800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35850][55000]\t Training Loss 24.2162\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [35900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [35950][55000]\t Training Loss 0.7411\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [36000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36100][55000]\t Training Loss 0.0061\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36150][55000]\t Training Loss 0.1269\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36200][55000]\t Training Loss 0.0069\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36350][55000]\t Training Loss 0.0042\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36400][55000]\t Training Loss 0.1037\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36450][55000]\t Training Loss 0.0063\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36600][55000]\t Training Loss 0.8964\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [36650][55000]\t Training Loss 12.2214\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [36700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [36950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37000][55000]\t Training Loss 0.9555\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [37050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37100][55000]\t Training Loss 0.0521\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37150][55000]\t Training Loss 0.0132\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37200][55000]\t Training Loss 0.0126\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37250][55000]\t Training Loss 1.2275\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [37300][55000]\t Training Loss 0.0749\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37450][55000]\t Training Loss 4.1827\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [37500][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37600][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37650][55000]\t Training Loss 0.0644\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [37950][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38050][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38250][55000]\t Training Loss 0.0059\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38450][55000]\t Training Loss 9.4324\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [38500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38800][55000]\t Training Loss 0.0111\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38850][55000]\t Training Loss 0.0615\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [38950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39000][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39050][55000]\t Training Loss 3.6682\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [39100][55000]\t Training Loss 20.7697\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [39150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39400][55000]\t Training Loss 9.1807\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [39450][55000]\t Training Loss 0.0056\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39550][55000]\t Training Loss 0.1036\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39600][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39650][55000]\t Training Loss 0.0050\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8][10]\t Batch [39750][55000]\t Training Loss 0.0210\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [39950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40150][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40200][55000]\t Training Loss 0.0280\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40250][55000]\t Training Loss 0.0033\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40350][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40500][55000]\t Training Loss 7.5002\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [40550][55000]\t Training Loss 3.8910\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [40600][55000]\t Training Loss 0.0228\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40700][55000]\t Training Loss 9.9115\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [40750][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [40950][55000]\t Training Loss 1.1639\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [41000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [41050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [41100][55000]\t Training Loss 0.0139\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [41150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [41200][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [41250][55000]\t Training Loss 1.4564\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [41300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [41350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [41400][55000]\t Training Loss 0.0108\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [41450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [41500][55000]\t Training Loss 8.5378\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [41550][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [41600][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [41650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [41700][55000]\t Training Loss 0.3662\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [41750][55000]\t Training Loss 13.9307\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [41800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [41850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [41900][55000]\t Training Loss 8.0646\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [41950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [42000][55000]\t Training Loss 1.0565\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [42050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [42100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [42150][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [42200][55000]\t Training Loss 2.4750\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [42250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [42300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [42350][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [42400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [42450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [42500][55000]\t Training Loss 31.9281\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [42550][55000]\t Training Loss 0.1777\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [42600][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [42650][55000]\t Training Loss 0.9166\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [42700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [42750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [42800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [42850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [42900][55000]\t Training Loss 5.5543\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [42950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43050][55000]\t Training Loss 0.1704\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43100][55000]\t Training Loss 0.1569\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43150][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43400][55000]\t Training Loss 0.0027\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43650][55000]\t Training Loss 0.0052\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43700][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43750][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43850][55000]\t Training Loss 0.0199\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [43950][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44000][55000]\t Training Loss 26.8928\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [44050][55000]\t Training Loss 0.0322\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44100][55000]\t Training Loss 0.0569\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44150][55000]\t Training Loss 0.0229\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44300][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44400][55000]\t Training Loss 0.1947\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44850][55000]\t Training Loss 0.0034\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [44950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45000][55000]\t Training Loss 0.3463\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45100][55000]\t Training Loss 0.0754\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45250][55000]\t Training Loss 5.6966\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [45300][55000]\t Training Loss 0.0060\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45350][55000]\t Training Loss 0.0290\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45550][55000]\t Training Loss 0.9595\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [45600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45650][55000]\t Training Loss 8.1564\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [45700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45800][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45900][55000]\t Training Loss 0.1146\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [45950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8][10]\t Batch [46000][55000]\t Training Loss 0.0077\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46050][55000]\t Training Loss 1.2749\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [46100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46250][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46300][55000]\t Training Loss 0.0809\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46400][55000]\t Training Loss 0.6027\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46600][55000]\t Training Loss 0.1037\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46650][55000]\t Training Loss 1.2636\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [46700][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [46950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47000][55000]\t Training Loss 0.0398\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47100][55000]\t Training Loss 0.0513\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47150][55000]\t Training Loss 0.0116\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47250][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47350][55000]\t Training Loss 0.0160\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47400][55000]\t Training Loss 0.0830\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47600][55000]\t Training Loss 4.4110\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [47650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47700][55000]\t Training Loss 1.3491\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [47750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [47950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48000][55000]\t Training Loss 1.7786\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [48050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48150][55000]\t Training Loss 0.0031\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48200][55000]\t Training Loss 0.0242\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48300][55000]\t Training Loss 0.0112\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48400][55000]\t Training Loss 2.7802\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [48450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48500][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48800][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [48950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49050][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49100][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49150][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49250][55000]\t Training Loss 3.1687\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [49300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49400][55000]\t Training Loss 0.1053\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49450][55000]\t Training Loss 0.0081\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49500][55000]\t Training Loss 6.8665\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [49550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49600][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49800][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49850][55000]\t Training Loss 0.0053\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49900][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [49950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50150][55000]\t Training Loss 0.0034\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50200][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50400][55000]\t Training Loss 0.0958\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50600][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50850][55000]\t Training Loss 0.2351\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [50950][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51200][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51250][55000]\t Training Loss 0.8737\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [51300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51400][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51500][55000]\t Training Loss 0.5475\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51600][55000]\t Training Loss 23.4282\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [51650][55000]\t Training Loss 4.6838\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [51700][55000]\t Training Loss 0.0027\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51800][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51900][55000]\t Training Loss 0.0037\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [51950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52000][55000]\t Training Loss 0.0033\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52150][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8][10]\t Batch [52250][55000]\t Training Loss 14.3143\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [52300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52700][55000]\t Training Loss 0.0075\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52750][55000]\t Training Loss 0.0126\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [52900][55000]\t Training Loss 2.3339\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [52950][55000]\t Training Loss 1.1847\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [53000][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53050][55000]\t Training Loss 8.3756\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [53100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53250][55000]\t Training Loss 0.0370\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53300][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53350][55000]\t Training Loss 0.2589\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53450][55000]\t Training Loss 0.0489\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53650][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53700][55000]\t Training Loss 4.7759\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [53750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53800][55000]\t Training Loss 0.0055\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [53950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [54000][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [54050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [54100][55000]\t Training Loss 0.0202\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [54150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [54200][55000]\t Training Loss 14.1740\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [54250][55000]\t Training Loss 5.5563\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [54300][55000]\t Training Loss 17.0375\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [54350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [54400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [54450][55000]\t Training Loss 0.0180\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [54500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [54550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [54600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [54650][55000]\t Training Loss 0.1075\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [54700][55000]\t Training Loss 0.0139\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [54750][55000]\t Training Loss 4.2929\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [54800][55000]\t Training Loss 8.2727\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [54850][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [54900][55000]\t Training Loss 1.7820\t Accuracy 0.0000\n",
      "Epoch [8][10]\t Batch [54950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "\n",
      "Epoch [8]\t Average training loss 0.7093\t Average training accuracy 0.8879\n",
      "Epoch [8]\t Average validation loss 0.5901\t Average validation accuracy 0.9098\n",
      "\n",
      "Epoch [9][10]\t Batch [0][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [100][55000]\t Training Loss 0.0109\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [200][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [250][55000]\t Training Loss 0.2736\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [300][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [500][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [550][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [600][55000]\t Training Loss 14.2708\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [650][55000]\t Training Loss 1.4325\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [750][55000]\t Training Loss 0.9403\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [850][55000]\t Training Loss 3.3139\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [900][55000]\t Training Loss 0.0081\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1050][55000]\t Training Loss 0.0111\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1350][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1400][55000]\t Training Loss 0.0856\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1450][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1600][55000]\t Training Loss 4.5809\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [1650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1750][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1850][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2350][55000]\t Training Loss 22.4779\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [2400][55000]\t Training Loss 0.2620\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2500][55000]\t Training Loss 1.9056\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [2550][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2900][55000]\t Training Loss 0.0243\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3150][55000]\t Training Loss 0.0174\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3200][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3250][55000]\t Training Loss 0.0882\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3300][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3400][55000]\t Training Loss 1.0969\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [3450][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3500][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3650][55000]\t Training Loss 0.1351\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3900][55000]\t Training Loss 0.0682\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [3950][55000]\t Training Loss 0.0569\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4000][55000]\t Training Loss 0.7720\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4050][55000]\t Training Loss 0.0031\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4150][55000]\t Training Loss 1.2306\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [4200][55000]\t Training Loss 3.3966\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [4250][55000]\t Training Loss 0.0031\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4350][55000]\t Training Loss 0.0477\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4500][55000]\t Training Loss 0.0357\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4600][55000]\t Training Loss 0.0166\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4650][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4800][55000]\t Training Loss 6.5249\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [4850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4900][55000]\t Training Loss 0.0155\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [4950][55000]\t Training Loss 0.1350\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5050][55000]\t Training Loss 0.2305\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5100][55000]\t Training Loss 0.6515\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5350][55000]\t Training Loss 0.0130\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5450][55000]\t Training Loss 2.9185\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [5500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9][10]\t Batch [5650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5700][55000]\t Training Loss 17.3603\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [5750][55000]\t Training Loss 0.0081\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [5950][55000]\t Training Loss 0.7223\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [6000][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6050][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6100][55000]\t Training Loss 0.0292\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6150][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6200][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6250][55000]\t Training Loss 0.0064\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6400][55000]\t Training Loss 0.2234\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6450][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6600][55000]\t Training Loss 1.2627\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [6650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6700][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6850][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [6950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7050][55000]\t Training Loss 0.0029\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7150][55000]\t Training Loss 0.0074\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7300][55000]\t Training Loss 9.2737\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [7350][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7400][55000]\t Training Loss 2.8985\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [7450][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7500][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7550][55000]\t Training Loss 0.0926\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7650][55000]\t Training Loss 4.0906\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [7700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7800][55000]\t Training Loss 0.5157\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [7950][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8050][55000]\t Training Loss 0.0167\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8200][55000]\t Training Loss 0.9287\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [8250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8450][55000]\t Training Loss 0.0192\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8500][55000]\t Training Loss 0.0021\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8650][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8700][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8850][55000]\t Training Loss 0.1628\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [8950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9200][55000]\t Training Loss 0.0040\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9350][55000]\t Training Loss 19.1562\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [9400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9550][55000]\t Training Loss 3.8317\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [9600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9700][55000]\t Training Loss 0.0065\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9850][55000]\t Training Loss 0.1731\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [9900][55000]\t Training Loss 9.7262\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [9950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10250][55000]\t Training Loss 0.0028\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10350][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10500][55000]\t Training Loss 0.0045\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10650][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10700][55000]\t Training Loss 5.9597\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [10750][55000]\t Training Loss 0.1902\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [10950][55000]\t Training Loss 0.1199\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11200][55000]\t Training Loss 0.0514\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11400][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11450][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11500][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11700][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9][10]\t Batch [11800][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [11950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12050][55000]\t Training Loss 1.9780\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [12100][55000]\t Training Loss 6.4913\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [12150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12200][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12300][55000]\t Training Loss 2.6679\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [12350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12700][55000]\t Training Loss 10.1638\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [12750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12800][55000]\t Training Loss 0.0081\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [12950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13000][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13150][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13250][55000]\t Training Loss 0.7286\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [13300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13400][55000]\t Training Loss 0.0064\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13500][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13650][55000]\t Training Loss 0.0212\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13750][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13800][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [13950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14000][55000]\t Training Loss 0.0030\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14150][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14250][55000]\t Training Loss 0.6060\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14400][55000]\t Training Loss 0.0020\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14500][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14600][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14650][55000]\t Training Loss 3.9235\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [14700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [14950][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15150][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15450][55000]\t Training Loss 1.0302\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [15500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15550][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [15950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16000][55000]\t Training Loss 6.4761\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [16050][55000]\t Training Loss 0.0516\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16200][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16400][55000]\t Training Loss 0.0196\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16450][55000]\t Training Loss 11.4433\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [16500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16750][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16850][55000]\t Training Loss 9.2769\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [16900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [16950][55000]\t Training Loss 0.0052\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17050][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17100][55000]\t Training Loss 7.7900\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [17150][55000]\t Training Loss 0.2379\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17250][55000]\t Training Loss 0.2510\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17450][55000]\t Training Loss 0.0103\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17600][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17750][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17800][55000]\t Training Loss 0.0066\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17850][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17900][55000]\t Training Loss 0.3370\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [17950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9][10]\t Batch [18100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18250][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18400][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18450][55000]\t Training Loss 0.0157\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18500][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18550][55000]\t Training Loss 0.3388\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18650][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18700][55000]\t Training Loss 0.8328\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [18750][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [18950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19050][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19250][55000]\t Training Loss 1.2108\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [19300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19350][55000]\t Training Loss 0.3510\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19400][55000]\t Training Loss 0.0106\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19600][55000]\t Training Loss 1.9869\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [19650][55000]\t Training Loss 0.0071\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19850][55000]\t Training Loss 0.0060\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19900][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [19950][55000]\t Training Loss 0.1635\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20000][55000]\t Training Loss 0.0065\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20050][55000]\t Training Loss 0.7407\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [20100][55000]\t Training Loss 7.6328\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [20150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20300][55000]\t Training Loss 0.1694\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20350][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20400][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20550][55000]\t Training Loss 0.0049\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20600][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [20950][55000]\t Training Loss 0.0318\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21050][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21250][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21350][55000]\t Training Loss 5.0638\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [21400][55000]\t Training Loss 0.1285\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21450][55000]\t Training Loss 0.0668\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21500][55000]\t Training Loss 0.3229\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21700][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [21950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22000][55000]\t Training Loss 0.0413\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22250][55000]\t Training Loss 22.0430\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [22300][55000]\t Training Loss 10.5335\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [22350][55000]\t Training Loss 0.0040\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22500][55000]\t Training Loss 2.0907\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [22550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22650][55000]\t Training Loss 2.8160\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [22700][55000]\t Training Loss 0.6608\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22750][55000]\t Training Loss 0.0268\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22900][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [22950][55000]\t Training Loss 0.0331\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23050][55000]\t Training Loss 0.1867\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23200][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23300][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23500][55000]\t Training Loss 21.9439\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [23550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23600][55000]\t Training Loss 0.0017\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23650][55000]\t Training Loss 0.0024\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23700][55000]\t Training Loss 0.1607\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23800][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [23950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24150][55000]\t Training Loss 0.0145\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9][10]\t Batch [24300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24550][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24650][55000]\t Training Loss 0.0050\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24750][55000]\t Training Loss 0.0921\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24900][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [24950][55000]\t Training Loss 12.1719\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [25000][55000]\t Training Loss 0.0007\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [25050][55000]\t Training Loss 0.0198\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [25100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [25150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [25200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [25250][55000]\t Training Loss 0.0027\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [25300][55000]\t Training Loss 0.9103\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [25350][55000]\t Training Loss 8.2733\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [25400][55000]\t Training Loss 0.0329\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [25450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [25500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [25550][55000]\t Training Loss 1.9574\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [25600][55000]\t Training Loss 0.3401\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [25650][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [25700][55000]\t Training Loss 0.0329\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [25750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [25800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [25850][55000]\t Training Loss 6.5992\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [25900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [25950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26000][55000]\t Training Loss 0.0023\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26050][55000]\t Training Loss 0.0841\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26200][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26250][55000]\t Training Loss 0.4927\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26350][55000]\t Training Loss 12.5254\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [26400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26450][55000]\t Training Loss 0.0042\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26650][55000]\t Training Loss 1.3015\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [26700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26750][55000]\t Training Loss 6.6263\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [26800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26850][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [26950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27200][55000]\t Training Loss 2.3795\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [27250][55000]\t Training Loss 0.0909\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27300][55000]\t Training Loss 0.0052\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27400][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27450][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27650][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27700][55000]\t Training Loss 0.4707\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27850][55000]\t Training Loss 0.0274\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27900][55000]\t Training Loss 0.0062\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [27950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [28000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [28050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [28100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [28150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [28200][55000]\t Training Loss 2.8444\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [28250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [28300][55000]\t Training Loss 0.0048\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [28350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [28400][55000]\t Training Loss 1.9243\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [28450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [28500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [28550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [28600][55000]\t Training Loss 1.7854\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [28650][55000]\t Training Loss 1.4047\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [28700][55000]\t Training Loss 0.0163\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [28750][55000]\t Training Loss 0.0807\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [28800][55000]\t Training Loss 0.0108\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [28850][55000]\t Training Loss 6.9434\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [28900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [28950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29000][55000]\t Training Loss 1.4521\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [29050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29200][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29250][55000]\t Training Loss 0.0032\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29350][55000]\t Training Loss 4.7185\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [29400][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29450][55000]\t Training Loss 0.0181\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29500][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29600][55000]\t Training Loss 0.0011\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29800][55000]\t Training Loss 0.0091\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [29950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30250][55000]\t Training Loss 4.9935\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [30300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30350][55000]\t Training Loss 0.0176\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30450][55000]\t Training Loss 0.0070\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9][10]\t Batch [30500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30650][55000]\t Training Loss 1.4543\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [30700][55000]\t Training Loss 0.0055\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30850][55000]\t Training Loss 0.6157\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [30950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31000][55000]\t Training Loss 5.7286\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [31050][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31100][55000]\t Training Loss 0.0167\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31150][55000]\t Training Loss 0.0047\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31400][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31450][55000]\t Training Loss 0.0566\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31700][55000]\t Training Loss 0.4593\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [31850][55000]\t Training Loss 5.8076\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [31900][55000]\t Training Loss 1.8639\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [31950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32000][55000]\t Training Loss 0.0034\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32250][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32350][55000]\t Training Loss 1.3377\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [32400][55000]\t Training Loss 0.0045\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32500][55000]\t Training Loss 0.5974\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32550][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32600][55000]\t Training Loss 21.1152\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [32650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32750][55000]\t Training Loss 0.0525\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32800][55000]\t Training Loss 0.7709\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [32850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [32950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33000][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33150][55000]\t Training Loss 0.7092\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [33200][55000]\t Training Loss 0.5534\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33250][55000]\t Training Loss 0.0014\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33300][55000]\t Training Loss 2.3372\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [33350][55000]\t Training Loss 0.9693\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33400][55000]\t Training Loss 0.3566\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33500][55000]\t Training Loss 0.1122\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33550][55000]\t Training Loss 1.2049\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [33600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33650][55000]\t Training Loss 11.4905\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [33700][55000]\t Training Loss 0.0013\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [33950][55000]\t Training Loss 0.0133\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34050][55000]\t Training Loss 0.1982\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34150][55000]\t Training Loss 10.1132\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [34200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34250][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34300][55000]\t Training Loss 10.3826\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [34350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34450][55000]\t Training Loss 0.0049\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34500][55000]\t Training Loss 6.4181\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [34550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34700][55000]\t Training Loss 0.4705\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34900][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [34950][55000]\t Training Loss 0.1522\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35150][55000]\t Training Loss 0.1653\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35200][55000]\t Training Loss 0.0113\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35350][55000]\t Training Loss 0.1102\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35450][55000]\t Training Loss 0.0083\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35700][55000]\t Training Loss 0.0022\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [35950][55000]\t Training Loss 0.0170\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36150][55000]\t Training Loss 0.0278\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36200][55000]\t Training Loss 0.0059\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36250][55000]\t Training Loss 6.3467\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [36300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36350][55000]\t Training Loss 0.0045\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36700][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36750][55000]\t Training Loss 0.0070\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9][10]\t Batch [36800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [36950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37000][55000]\t Training Loss 0.3113\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37100][55000]\t Training Loss 6.4212\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [37150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37200][55000]\t Training Loss 0.0004\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37300][55000]\t Training Loss 0.0142\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37350][55000]\t Training Loss 0.0035\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37400][55000]\t Training Loss 2.2306\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [37450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37500][55000]\t Training Loss 0.0985\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [37900][55000]\t Training Loss 3.4606\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [37950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38050][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38150][55000]\t Training Loss 9.3887\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [38200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38250][55000]\t Training Loss 0.0081\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38300][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38350][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38400][55000]\t Training Loss 0.0107\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38600][55000]\t Training Loss 7.8033\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [38650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38750][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38800][55000]\t Training Loss 0.3001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38850][55000]\t Training Loss 0.1721\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [38950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39000][55000]\t Training Loss 0.0010\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39050][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39100][55000]\t Training Loss 0.0202\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39200][55000]\t Training Loss 1.4109\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [39250][55000]\t Training Loss 0.0116\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39350][55000]\t Training Loss 0.7894\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [39400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39650][55000]\t Training Loss 7.7888\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [39700][55000]\t Training Loss 0.0036\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39750][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39850][55000]\t Training Loss 0.4274\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [39950][55000]\t Training Loss 0.0024\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40250][55000]\t Training Loss 0.0296\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40300][55000]\t Training Loss 45.1937\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [40350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40400][55000]\t Training Loss 6.1477\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [40450][55000]\t Training Loss 11.1804\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [40500][55000]\t Training Loss 1.5839\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [40550][55000]\t Training Loss 0.2091\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40650][55000]\t Training Loss 0.1132\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40850][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40900][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [40950][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41250][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41300][55000]\t Training Loss 0.9512\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [41350][55000]\t Training Loss 0.0766\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41400][55000]\t Training Loss 0.8066\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41500][55000]\t Training Loss 0.0102\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41550][55000]\t Training Loss 0.0988\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41600][55000]\t Training Loss 0.0787\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41700][55000]\t Training Loss 0.0703\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41850][55000]\t Training Loss 0.0908\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41900][55000]\t Training Loss 0.0207\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [41950][55000]\t Training Loss 0.0088\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42000][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42100][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42250][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42300][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42400][55000]\t Training Loss 0.0656\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42900][55000]\t Training Loss 0.0488\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [42950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9][10]\t Batch [43000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43050][55000]\t Training Loss 0.0132\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43100][55000]\t Training Loss 0.0065\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43250][55000]\t Training Loss 0.0151\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43300][55000]\t Training Loss 0.0012\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43450][55000]\t Training Loss 0.0872\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43700][55000]\t Training Loss 3.1773\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [43750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [43950][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44050][55000]\t Training Loss 13.5338\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [44100][55000]\t Training Loss 0.1197\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44500][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44550][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44650][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44800][55000]\t Training Loss 20.9808\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [44850][55000]\t Training Loss 0.0028\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [44950][55000]\t Training Loss 12.4834\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [45000][55000]\t Training Loss 0.1187\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45150][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45200][55000]\t Training Loss 0.3808\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45250][55000]\t Training Loss 0.1022\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45300][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45550][55000]\t Training Loss 0.0363\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45850][55000]\t Training Loss 0.3964\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45900][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [45950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [46000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [46050][55000]\t Training Loss 24.2215\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [46100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [46150][55000]\t Training Loss 1.7237\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [46200][55000]\t Training Loss 2.8677\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [46250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [46300][55000]\t Training Loss 0.0192\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [46350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [46400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [46450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [46500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [46550][55000]\t Training Loss 10.1577\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [46600][55000]\t Training Loss 1.9961\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [46650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [46700][55000]\t Training Loss 3.8014\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [46750][55000]\t Training Loss 10.5825\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [46800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [46850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [46900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [46950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47050][55000]\t Training Loss 0.0031\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47200][55000]\t Training Loss 0.0078\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47250][55000]\t Training Loss 0.2693\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47300][55000]\t Training Loss 11.5779\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [47350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47450][55000]\t Training Loss 0.2368\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47550][55000]\t Training Loss 0.0015\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47700][55000]\t Training Loss 1.3920\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [47750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47800][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47850][55000]\t Training Loss 0.1150\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47900][55000]\t Training Loss 0.0019\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [47950][55000]\t Training Loss 0.1986\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48200][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48400][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48450][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48650][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48750][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48850][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [48950][55000]\t Training Loss 2.7940\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [49000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49100][55000]\t Training Loss 0.0076\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9][10]\t Batch [49200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49400][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49450][55000]\t Training Loss 0.0604\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49600][55000]\t Training Loss 10.8765\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [49650][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49800][55000]\t Training Loss 0.0186\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49850][55000]\t Training Loss 0.0281\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [49950][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50000][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50050][55000]\t Training Loss 0.0005\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50100][55000]\t Training Loss 7.6552\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [50150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50250][55000]\t Training Loss 0.5044\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50300][55000]\t Training Loss 0.0324\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50350][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50400][55000]\t Training Loss 0.0090\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50500][55000]\t Training Loss 0.3231\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50550][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50650][55000]\t Training Loss 0.2384\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50700][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [50950][55000]\t Training Loss 11.1330\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [51000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51100][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51200][55000]\t Training Loss 0.0110\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51250][55000]\t Training Loss 0.0009\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51400][55000]\t Training Loss 0.0026\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51450][55000]\t Training Loss 0.4623\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51550][55000]\t Training Loss 0.0006\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51600][55000]\t Training Loss 0.0327\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51650][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51750][55000]\t Training Loss 3.3527\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [51800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51850][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [51900][55000]\t Training Loss 13.4042\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [51950][55000]\t Training Loss 12.3931\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [52000][55000]\t Training Loss 0.0191\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52050][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52100][55000]\t Training Loss 0.0025\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52250][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52350][55000]\t Training Loss 0.0255\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52400][55000]\t Training Loss 0.2063\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52500][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52550][55000]\t Training Loss 0.0029\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52650][55000]\t Training Loss 0.0169\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52700][55000]\t Training Loss 0.0100\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52750][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52850][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52900][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [52950][55000]\t Training Loss 0.0016\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53050][55000]\t Training Loss 0.1452\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53100][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53150][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53250][55000]\t Training Loss 0.0062\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53400][55000]\t Training Loss 17.0217\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [53450][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53500][55000]\t Training Loss 0.0199\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53550][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53650][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53700][55000]\t Training Loss 0.0002\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53800][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [53850][55000]\t Training Loss 3.8343\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [53900][55000]\t Training Loss 0.9908\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [53950][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [54000][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [54050][55000]\t Training Loss 0.0443\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [54100][55000]\t Training Loss 1.0633\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [54150][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [54200][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [54250][55000]\t Training Loss 0.0001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [54300][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [54350][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [54400][55000]\t Training Loss 0.0003\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [54450][55000]\t Training Loss 5.2803\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [54500][55000]\t Training Loss 0.7763\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [54550][55000]\t Training Loss 2.8884\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [54600][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [54650][55000]\t Training Loss 0.0018\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [54700][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [54750][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [54800][55000]\t Training Loss 46.2835\t Accuracy 0.0000\n",
      "Epoch [9][10]\t Batch [54850][55000]\t Training Loss 0.0008\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [54900][55000]\t Training Loss 0.0000\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [54950][55000]\t Training Loss 1.4640\t Accuracy 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [9]\t Average training loss 0.7100\t Average training accuracy 0.8886\n",
      "Epoch [9]\t Average validation loss 0.6420\t Average validation accuracy 0.9016\n",
      "\n",
      "Epoch [0][10]\t Batch [0][2750]\t Training Loss 2.3732\t Accuracy 0.2000\n",
      "Epoch [0][10]\t Batch [50][2750]\t Training Loss 0.7135\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [100][2750]\t Training Loss 0.6845\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [150][2750]\t Training Loss 0.9727\t Accuracy 0.6500\n",
      "Epoch [0][10]\t Batch [200][2750]\t Training Loss 0.6092\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [250][2750]\t Training Loss 0.5778\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [300][2750]\t Training Loss 0.5698\t Accuracy 0.7000\n",
      "Epoch [0][10]\t Batch [350][2750]\t Training Loss 0.5969\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [400][2750]\t Training Loss 0.4450\t Accuracy 0.8000\n",
      "Epoch [0][10]\t Batch [450][2750]\t Training Loss 0.1458\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [500][2750]\t Training Loss 0.4135\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [550][2750]\t Training Loss 0.2773\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [600][2750]\t Training Loss 0.3861\t Accuracy 0.8000\n",
      "Epoch [0][10]\t Batch [650][2750]\t Training Loss 0.3345\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [700][2750]\t Training Loss 0.3790\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [750][2750]\t Training Loss 0.3213\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [800][2750]\t Training Loss 0.3099\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [850][2750]\t Training Loss 0.3673\t Accuracy 0.9500\n",
      "Epoch [0][10]\t Batch [900][2750]\t Training Loss 0.1149\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [950][2750]\t Training Loss 0.2103\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1000][2750]\t Training Loss 0.5663\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [1050][2750]\t Training Loss 0.3141\t Accuracy 0.8000\n",
      "Epoch [0][10]\t Batch [1100][2750]\t Training Loss 0.1921\t Accuracy 0.9500\n",
      "Epoch [0][10]\t Batch [1150][2750]\t Training Loss 0.4899\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [1200][2750]\t Training Loss 0.1361\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1250][2750]\t Training Loss 0.3491\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [1300][2750]\t Training Loss 0.4704\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [1350][2750]\t Training Loss 0.2802\t Accuracy 0.9500\n",
      "Epoch [0][10]\t Batch [1400][2750]\t Training Loss 0.1479\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1450][2750]\t Training Loss 0.4817\t Accuracy 0.8000\n",
      "Epoch [0][10]\t Batch [1500][2750]\t Training Loss 0.2557\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [1550][2750]\t Training Loss 0.3339\t Accuracy 0.9500\n",
      "Epoch [0][10]\t Batch [1600][2750]\t Training Loss 0.3311\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [1650][2750]\t Training Loss 0.1421\t Accuracy 1.0000\n",
      "Epoch [0][10]\t Batch [1700][2750]\t Training Loss 0.6107\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [1750][2750]\t Training Loss 0.3079\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [1800][2750]\t Training Loss 0.2252\t Accuracy 0.9500\n",
      "Epoch [0][10]\t Batch [1850][2750]\t Training Loss 0.2588\t Accuracy 0.9500\n",
      "Epoch [0][10]\t Batch [1900][2750]\t Training Loss 0.2379\t Accuracy 0.9500\n",
      "Epoch [0][10]\t Batch [1950][2750]\t Training Loss 0.4264\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [2000][2750]\t Training Loss 0.1189\t Accuracy 0.9500\n",
      "Epoch [0][10]\t Batch [2050][2750]\t Training Loss 0.2973\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [2100][2750]\t Training Loss 0.2679\t Accuracy 0.9500\n",
      "Epoch [0][10]\t Batch [2150][2750]\t Training Loss 0.3195\t Accuracy 0.8000\n",
      "Epoch [0][10]\t Batch [2200][2750]\t Training Loss 0.6877\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [2250][2750]\t Training Loss 0.3518\t Accuracy 0.9500\n",
      "Epoch [0][10]\t Batch [2300][2750]\t Training Loss 0.1720\t Accuracy 0.9500\n",
      "Epoch [0][10]\t Batch [2350][2750]\t Training Loss 0.2661\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [2400][2750]\t Training Loss 0.2106\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [2450][2750]\t Training Loss 0.3256\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [2500][2750]\t Training Loss 0.4736\t Accuracy 0.8000\n",
      "Epoch [0][10]\t Batch [2550][2750]\t Training Loss 0.7660\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [2600][2750]\t Training Loss 0.2989\t Accuracy 0.9500\n",
      "Epoch [0][10]\t Batch [2650][2750]\t Training Loss 0.3104\t Accuracy 0.8500\n",
      "Epoch [0][10]\t Batch [2700][2750]\t Training Loss 0.2511\t Accuracy 0.9500\n",
      "\n",
      "Epoch [0]\t Average training loss 0.4074\t Average training accuracy 0.8841\n",
      "Epoch [0]\t Average validation loss 0.2593\t Average validation accuracy 0.9320\n",
      "\n",
      "Epoch [1][10]\t Batch [0][2750]\t Training Loss 0.4962\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [50][2750]\t Training Loss 0.1840\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [100][2750]\t Training Loss 0.2515\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [150][2750]\t Training Loss 0.6624\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [200][2750]\t Training Loss 0.1487\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [250][2750]\t Training Loss 0.6295\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [300][2750]\t Training Loss 0.1233\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [350][2750]\t Training Loss 0.3560\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [400][2750]\t Training Loss 0.9922\t Accuracy 0.8000\n",
      "Epoch [1][10]\t Batch [450][2750]\t Training Loss 0.3528\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [500][2750]\t Training Loss 0.3716\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [550][2750]\t Training Loss 0.1569\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [600][2750]\t Training Loss 0.5532\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [650][2750]\t Training Loss 0.4525\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [700][2750]\t Training Loss 0.3405\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [750][2750]\t Training Loss 0.1716\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [800][2750]\t Training Loss 0.0960\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [850][2750]\t Training Loss 0.2122\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [900][2750]\t Training Loss 0.1299\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [950][2750]\t Training Loss 0.0671\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1000][2750]\t Training Loss 0.4779\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [1050][2750]\t Training Loss 0.6346\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [1100][2750]\t Training Loss 0.5313\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [1150][2750]\t Training Loss 0.2648\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [1200][2750]\t Training Loss 0.2600\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [1250][2750]\t Training Loss 0.4324\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [1300][2750]\t Training Loss 0.8895\t Accuracy 0.8000\n",
      "Epoch [1][10]\t Batch [1350][2750]\t Training Loss 0.5409\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [1400][2750]\t Training Loss 0.2177\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [1450][2750]\t Training Loss 0.2836\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [1500][2750]\t Training Loss 0.1102\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [1550][2750]\t Training Loss 0.4735\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [1600][2750]\t Training Loss 0.1812\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1650][2750]\t Training Loss 0.4937\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [1700][2750]\t Training Loss 0.3002\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [1750][2750]\t Training Loss 0.2079\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [1800][2750]\t Training Loss 0.0796\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1850][2750]\t Training Loss 0.6181\t Accuracy 0.8000\n",
      "Epoch [1][10]\t Batch [1900][2750]\t Training Loss 0.1435\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [1950][2750]\t Training Loss 0.1516\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [2000][2750]\t Training Loss 0.0923\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [2050][2750]\t Training Loss 0.1402\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2100][2750]\t Training Loss 0.0724\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2150][2750]\t Training Loss 0.3286\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [2200][2750]\t Training Loss 0.8939\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [2250][2750]\t Training Loss 0.4676\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [2300][2750]\t Training Loss 0.3752\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [2350][2750]\t Training Loss 0.2015\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [2400][2750]\t Training Loss 0.0507\t Accuracy 1.0000\n",
      "Epoch [1][10]\t Batch [2450][2750]\t Training Loss 0.6394\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [2500][2750]\t Training Loss 0.1706\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [2550][2750]\t Training Loss 0.5702\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [2600][2750]\t Training Loss 0.8130\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [2650][2750]\t Training Loss 0.6690\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [2700][2750]\t Training Loss 0.5484\t Accuracy 0.7500\n",
      "\n",
      "Epoch [1]\t Average training loss 0.3192\t Average training accuracy 0.9105\n",
      "Epoch [1]\t Average validation loss 0.2452\t Average validation accuracy 0.9310\n",
      "\n",
      "Epoch [2][10]\t Batch [0][2750]\t Training Loss 0.1554\t Accuracy 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2][10]\t Batch [50][2750]\t Training Loss 0.0819\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [100][2750]\t Training Loss 0.0917\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [150][2750]\t Training Loss 0.1488\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [200][2750]\t Training Loss 0.1989\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [250][2750]\t Training Loss 0.6336\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [300][2750]\t Training Loss 0.2782\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [350][2750]\t Training Loss 0.2128\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [400][2750]\t Training Loss 0.5562\t Accuracy 0.8000\n",
      "Epoch [2][10]\t Batch [450][2750]\t Training Loss 0.2435\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [500][2750]\t Training Loss 0.4278\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [550][2750]\t Training Loss 0.2326\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [600][2750]\t Training Loss 0.5053\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [650][2750]\t Training Loss 0.0655\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [700][2750]\t Training Loss 0.4074\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [750][2750]\t Training Loss 0.4058\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [800][2750]\t Training Loss 0.1953\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [850][2750]\t Training Loss 0.3344\t Accuracy 0.8500\n",
      "Epoch [2][10]\t Batch [900][2750]\t Training Loss 0.3639\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [950][2750]\t Training Loss 0.1452\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [1000][2750]\t Training Loss 0.2035\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [1050][2750]\t Training Loss 0.2102\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [1100][2750]\t Training Loss 0.4948\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [1150][2750]\t Training Loss 0.5944\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [1200][2750]\t Training Loss 0.4811\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [1250][2750]\t Training Loss 0.6911\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [1300][2750]\t Training Loss 0.4532\t Accuracy 0.8500\n",
      "Epoch [2][10]\t Batch [1350][2750]\t Training Loss 0.4030\t Accuracy 0.8500\n",
      "Epoch [2][10]\t Batch [1400][2750]\t Training Loss 0.1722\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [1450][2750]\t Training Loss 0.6462\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [1500][2750]\t Training Loss 0.0821\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [1550][2750]\t Training Loss 0.6153\t Accuracy 0.8000\n",
      "Epoch [2][10]\t Batch [1600][2750]\t Training Loss 0.2785\t Accuracy 0.8500\n",
      "Epoch [2][10]\t Batch [1650][2750]\t Training Loss 0.5062\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [1700][2750]\t Training Loss 0.1135\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [1750][2750]\t Training Loss 0.3455\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [1800][2750]\t Training Loss 0.5994\t Accuracy 0.8000\n",
      "Epoch [2][10]\t Batch [1850][2750]\t Training Loss 0.4033\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [1900][2750]\t Training Loss 0.1509\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [1950][2750]\t Training Loss 0.1437\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [2000][2750]\t Training Loss 0.2524\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [2050][2750]\t Training Loss 0.2047\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [2100][2750]\t Training Loss 0.1633\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2150][2750]\t Training Loss 0.3038\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [2200][2750]\t Training Loss 0.4046\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [2250][2750]\t Training Loss 0.1108\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [2300][2750]\t Training Loss 0.7940\t Accuracy 0.8000\n",
      "Epoch [2][10]\t Batch [2350][2750]\t Training Loss 0.3082\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [2400][2750]\t Training Loss 0.1592\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [2450][2750]\t Training Loss 0.2956\t Accuracy 0.9500\n",
      "Epoch [2][10]\t Batch [2500][2750]\t Training Loss 0.5815\t Accuracy 0.8500\n",
      "Epoch [2][10]\t Batch [2550][2750]\t Training Loss 0.1483\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2600][2750]\t Training Loss 0.3074\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [2650][2750]\t Training Loss 0.0638\t Accuracy 1.0000\n",
      "Epoch [2][10]\t Batch [2700][2750]\t Training Loss 0.6373\t Accuracy 0.8500\n",
      "\n",
      "Epoch [2]\t Average training loss 0.3046\t Average training accuracy 0.9145\n",
      "Epoch [2]\t Average validation loss 0.2370\t Average validation accuracy 0.9354\n",
      "\n",
      "Epoch [3][10]\t Batch [0][2750]\t Training Loss 0.1120\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [50][2750]\t Training Loss 0.2344\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [100][2750]\t Training Loss 0.1668\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [150][2750]\t Training Loss 0.8880\t Accuracy 0.8000\n",
      "Epoch [3][10]\t Batch [200][2750]\t Training Loss 0.4439\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [250][2750]\t Training Loss 0.6088\t Accuracy 0.8500\n",
      "Epoch [3][10]\t Batch [300][2750]\t Training Loss 0.2202\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [350][2750]\t Training Loss 0.3466\t Accuracy 0.8500\n",
      "Epoch [3][10]\t Batch [400][2750]\t Training Loss 0.4482\t Accuracy 0.8500\n",
      "Epoch [3][10]\t Batch [450][2750]\t Training Loss 0.6522\t Accuracy 0.7500\n",
      "Epoch [3][10]\t Batch [500][2750]\t Training Loss 0.3065\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [550][2750]\t Training Loss 0.3957\t Accuracy 0.8500\n",
      "Epoch [3][10]\t Batch [600][2750]\t Training Loss 0.3701\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [650][2750]\t Training Loss 0.2317\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [700][2750]\t Training Loss 0.0909\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [750][2750]\t Training Loss 0.1629\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [800][2750]\t Training Loss 0.1142\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [850][2750]\t Training Loss 0.3401\t Accuracy 0.8500\n",
      "Epoch [3][10]\t Batch [900][2750]\t Training Loss 0.2533\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [950][2750]\t Training Loss 0.0920\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [1000][2750]\t Training Loss 0.0747\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1050][2750]\t Training Loss 0.1768\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [1100][2750]\t Training Loss 0.1253\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [1150][2750]\t Training Loss 0.0997\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1200][2750]\t Training Loss 0.1561\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [1250][2750]\t Training Loss 0.2338\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [1300][2750]\t Training Loss 0.1660\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [1350][2750]\t Training Loss 0.4349\t Accuracy 0.8500\n",
      "Epoch [3][10]\t Batch [1400][2750]\t Training Loss 0.4193\t Accuracy 0.8000\n",
      "Epoch [3][10]\t Batch [1450][2750]\t Training Loss 0.2401\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [1500][2750]\t Training Loss 0.1948\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [1550][2750]\t Training Loss 0.2560\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [1600][2750]\t Training Loss 0.1710\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [1650][2750]\t Training Loss 0.2149\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [1700][2750]\t Training Loss 0.1524\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [1750][2750]\t Training Loss 0.1002\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1800][2750]\t Training Loss 0.3994\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [1850][2750]\t Training Loss 0.1114\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [1900][2750]\t Training Loss 0.3672\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [1950][2750]\t Training Loss 0.2184\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [2000][2750]\t Training Loss 0.0826\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2050][2750]\t Training Loss 0.5951\t Accuracy 0.8000\n",
      "Epoch [3][10]\t Batch [2100][2750]\t Training Loss 0.2020\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [2150][2750]\t Training Loss 0.0779\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2200][2750]\t Training Loss 0.2288\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [2250][2750]\t Training Loss 0.7164\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [2300][2750]\t Training Loss 0.4169\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [2350][2750]\t Training Loss 0.5266\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [2400][2750]\t Training Loss 0.1179\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2450][2750]\t Training Loss 0.1682\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [2500][2750]\t Training Loss 0.1310\t Accuracy 0.9500\n",
      "Epoch [3][10]\t Batch [2550][2750]\t Training Loss 0.0579\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [2600][2750]\t Training Loss 0.3013\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [2650][2750]\t Training Loss 0.2511\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [2700][2750]\t Training Loss 0.4517\t Accuracy 0.9500\n",
      "\n",
      "Epoch [3]\t Average training loss 0.2967\t Average training accuracy 0.9185\n",
      "Epoch [3]\t Average validation loss 0.2363\t Average validation accuracy 0.9362\n",
      "\n",
      "Epoch [4][10]\t Batch [0][2750]\t Training Loss 0.3496\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [50][2750]\t Training Loss 0.2494\t Accuracy 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4][10]\t Batch [100][2750]\t Training Loss 0.1654\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [150][2750]\t Training Loss 0.2735\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [200][2750]\t Training Loss 0.3818\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [250][2750]\t Training Loss 0.2009\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [300][2750]\t Training Loss 0.2225\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [350][2750]\t Training Loss 0.2488\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [400][2750]\t Training Loss 0.3974\t Accuracy 0.8500\n",
      "Epoch [4][10]\t Batch [450][2750]\t Training Loss 0.2374\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [500][2750]\t Training Loss 0.4208\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [550][2750]\t Training Loss 0.2258\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [600][2750]\t Training Loss 0.2363\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [650][2750]\t Training Loss 0.2317\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [700][2750]\t Training Loss 0.3673\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [750][2750]\t Training Loss 0.7258\t Accuracy 0.8000\n",
      "Epoch [4][10]\t Batch [800][2750]\t Training Loss 0.3524\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [850][2750]\t Training Loss 0.0551\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [900][2750]\t Training Loss 0.3050\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [950][2750]\t Training Loss 0.4112\t Accuracy 0.8500\n",
      "Epoch [4][10]\t Batch [1000][2750]\t Training Loss 0.1770\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [1050][2750]\t Training Loss 0.0927\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1100][2750]\t Training Loss 0.8007\t Accuracy 0.8500\n",
      "Epoch [4][10]\t Batch [1150][2750]\t Training Loss 0.2950\t Accuracy 0.8500\n",
      "Epoch [4][10]\t Batch [1200][2750]\t Training Loss 0.5760\t Accuracy 0.8500\n",
      "Epoch [4][10]\t Batch [1250][2750]\t Training Loss 0.1970\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [1300][2750]\t Training Loss 0.4402\t Accuracy 0.8500\n",
      "Epoch [4][10]\t Batch [1350][2750]\t Training Loss 0.1303\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1400][2750]\t Training Loss 0.3023\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [1450][2750]\t Training Loss 0.4449\t Accuracy 0.8500\n",
      "Epoch [4][10]\t Batch [1500][2750]\t Training Loss 0.0684\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1550][2750]\t Training Loss 0.2526\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [1600][2750]\t Training Loss 0.2161\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [1650][2750]\t Training Loss 0.1046\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1700][2750]\t Training Loss 0.1579\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [1750][2750]\t Training Loss 0.3371\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [1800][2750]\t Training Loss 0.7792\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [1850][2750]\t Training Loss 0.1962\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [1900][2750]\t Training Loss 0.0867\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [1950][2750]\t Training Loss 0.2366\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [2000][2750]\t Training Loss 0.3855\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [2050][2750]\t Training Loss 0.5057\t Accuracy 0.8000\n",
      "Epoch [4][10]\t Batch [2100][2750]\t Training Loss 0.0744\t Accuracy 1.0000\n",
      "Epoch [4][10]\t Batch [2150][2750]\t Training Loss 0.1661\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [2200][2750]\t Training Loss 0.2368\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [2250][2750]\t Training Loss 0.1824\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [2300][2750]\t Training Loss 1.0780\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [2350][2750]\t Training Loss 0.1280\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [2400][2750]\t Training Loss 0.1511\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [2450][2750]\t Training Loss 0.6666\t Accuracy 0.7500\n",
      "Epoch [4][10]\t Batch [2500][2750]\t Training Loss 0.3468\t Accuracy 0.8500\n",
      "Epoch [4][10]\t Batch [2550][2750]\t Training Loss 0.2810\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [2600][2750]\t Training Loss 0.9537\t Accuracy 0.8000\n",
      "Epoch [4][10]\t Batch [2650][2750]\t Training Loss 0.1365\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [2700][2750]\t Training Loss 0.4950\t Accuracy 0.8000\n",
      "\n",
      "Epoch [4]\t Average training loss 0.2911\t Average training accuracy 0.9192\n",
      "Epoch [4]\t Average validation loss 0.2355\t Average validation accuracy 0.9370\n",
      "\n",
      "Epoch [5][10]\t Batch [0][2750]\t Training Loss 0.1636\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [50][2750]\t Training Loss 0.2223\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [100][2750]\t Training Loss 0.3605\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [150][2750]\t Training Loss 0.2065\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [200][2750]\t Training Loss 0.8908\t Accuracy 0.7500\n",
      "Epoch [5][10]\t Batch [250][2750]\t Training Loss 0.2351\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [300][2750]\t Training Loss 0.3072\t Accuracy 0.8500\n",
      "Epoch [5][10]\t Batch [350][2750]\t Training Loss 0.0497\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [400][2750]\t Training Loss 0.2985\t Accuracy 0.9500\n",
      "Epoch [5][10]\t Batch [450][2750]\t Training Loss 0.4765\t Accuracy 0.8000\n",
      "Epoch [5][10]\t Batch [500][2750]\t Training Loss 0.2817\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [550][2750]\t Training Loss 0.0968\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [600][2750]\t Training Loss 0.1770\t Accuracy 0.9500\n",
      "Epoch [5][10]\t Batch [650][2750]\t Training Loss 0.3946\t Accuracy 0.8500\n",
      "Epoch [5][10]\t Batch [700][2750]\t Training Loss 0.0603\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [750][2750]\t Training Loss 0.5787\t Accuracy 0.8000\n",
      "Epoch [5][10]\t Batch [800][2750]\t Training Loss 0.1746\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [850][2750]\t Training Loss 0.2787\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [900][2750]\t Training Loss 0.9748\t Accuracy 0.8000\n",
      "Epoch [5][10]\t Batch [950][2750]\t Training Loss 0.1804\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [1000][2750]\t Training Loss 0.0833\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1050][2750]\t Training Loss 0.0579\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1100][2750]\t Training Loss 0.4265\t Accuracy 0.8500\n",
      "Epoch [5][10]\t Batch [1150][2750]\t Training Loss 0.1242\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1200][2750]\t Training Loss 0.1706\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [1250][2750]\t Training Loss 0.0589\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1300][2750]\t Training Loss 0.8053\t Accuracy 0.7500\n",
      "Epoch [5][10]\t Batch [1350][2750]\t Training Loss 0.3940\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [1400][2750]\t Training Loss 0.6489\t Accuracy 0.9500\n",
      "Epoch [5][10]\t Batch [1450][2750]\t Training Loss 0.1345\t Accuracy 0.9500\n",
      "Epoch [5][10]\t Batch [1500][2750]\t Training Loss 0.1417\t Accuracy 0.9500\n",
      "Epoch [5][10]\t Batch [1550][2750]\t Training Loss 0.3112\t Accuracy 0.8500\n",
      "Epoch [5][10]\t Batch [1600][2750]\t Training Loss 0.1777\t Accuracy 0.9500\n",
      "Epoch [5][10]\t Batch [1650][2750]\t Training Loss 0.8609\t Accuracy 0.9500\n",
      "Epoch [5][10]\t Batch [1700][2750]\t Training Loss 0.1097\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [1750][2750]\t Training Loss 0.3603\t Accuracy 0.8500\n",
      "Epoch [5][10]\t Batch [1800][2750]\t Training Loss 0.1578\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [1850][2750]\t Training Loss 0.5359\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [1900][2750]\t Training Loss 0.9470\t Accuracy 0.8000\n",
      "Epoch [5][10]\t Batch [1950][2750]\t Training Loss 0.1293\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2000][2750]\t Training Loss 0.1963\t Accuracy 0.9500\n",
      "Epoch [5][10]\t Batch [2050][2750]\t Training Loss 0.4097\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [2100][2750]\t Training Loss 0.3102\t Accuracy 0.8500\n",
      "Epoch [5][10]\t Batch [2150][2750]\t Training Loss 0.2932\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [2200][2750]\t Training Loss 0.1788\t Accuracy 0.9500\n",
      "Epoch [5][10]\t Batch [2250][2750]\t Training Loss 0.3635\t Accuracy 0.8500\n",
      "Epoch [5][10]\t Batch [2300][2750]\t Training Loss 0.1185\t Accuracy 0.9500\n",
      "Epoch [5][10]\t Batch [2350][2750]\t Training Loss 0.1703\t Accuracy 0.9500\n",
      "Epoch [5][10]\t Batch [2400][2750]\t Training Loss 0.1625\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2450][2750]\t Training Loss 0.1642\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2500][2750]\t Training Loss 0.4373\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [2550][2750]\t Training Loss 0.4376\t Accuracy 0.8500\n",
      "Epoch [5][10]\t Batch [2600][2750]\t Training Loss 0.3516\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [2650][2750]\t Training Loss 0.0742\t Accuracy 1.0000\n",
      "Epoch [5][10]\t Batch [2700][2750]\t Training Loss 0.3523\t Accuracy 0.8000\n",
      "\n",
      "Epoch [5]\t Average training loss 0.2873\t Average training accuracy 0.9205\n",
      "Epoch [5]\t Average validation loss 0.2279\t Average validation accuracy 0.9394\n",
      "\n",
      "Epoch [6][10]\t Batch [0][2750]\t Training Loss 0.0328\t Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6][10]\t Batch [50][2750]\t Training Loss 0.4405\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [100][2750]\t Training Loss 0.2916\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [150][2750]\t Training Loss 0.1898\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [200][2750]\t Training Loss 0.1386\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [250][2750]\t Training Loss 0.5574\t Accuracy 0.8000\n",
      "Epoch [6][10]\t Batch [300][2750]\t Training Loss 0.2094\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [350][2750]\t Training Loss 0.3113\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [400][2750]\t Training Loss 0.4378\t Accuracy 0.8000\n",
      "Epoch [6][10]\t Batch [450][2750]\t Training Loss 0.0877\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [500][2750]\t Training Loss 0.1745\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [550][2750]\t Training Loss 0.2561\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [600][2750]\t Training Loss 0.2222\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [650][2750]\t Training Loss 0.4474\t Accuracy 0.7500\n",
      "Epoch [6][10]\t Batch [700][2750]\t Training Loss 0.0871\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [750][2750]\t Training Loss 0.0715\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [800][2750]\t Training Loss 0.1436\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [850][2750]\t Training Loss 0.0917\t Accuracy 1.0000\n",
      "Epoch [6][10]\t Batch [900][2750]\t Training Loss 0.1794\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [950][2750]\t Training Loss 0.3316\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [1000][2750]\t Training Loss 0.2136\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [1050][2750]\t Training Loss 0.4242\t Accuracy 0.8500\n",
      "Epoch [6][10]\t Batch [1100][2750]\t Training Loss 0.1776\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [1150][2750]\t Training Loss 0.5492\t Accuracy 0.8500\n",
      "Epoch [6][10]\t Batch [1200][2750]\t Training Loss 0.1136\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [1250][2750]\t Training Loss 0.2032\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [1300][2750]\t Training Loss 0.1879\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [1350][2750]\t Training Loss 0.3064\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [1400][2750]\t Training Loss 0.1548\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [1450][2750]\t Training Loss 0.2672\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [1500][2750]\t Training Loss 0.6083\t Accuracy 0.8500\n",
      "Epoch [6][10]\t Batch [1550][2750]\t Training Loss 0.0915\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [1600][2750]\t Training Loss 0.3459\t Accuracy 0.8500\n",
      "Epoch [6][10]\t Batch [1650][2750]\t Training Loss 0.2261\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [1700][2750]\t Training Loss 0.5585\t Accuracy 0.8000\n",
      "Epoch [6][10]\t Batch [1750][2750]\t Training Loss 0.2942\t Accuracy 0.8000\n",
      "Epoch [6][10]\t Batch [1800][2750]\t Training Loss 0.6241\t Accuracy 0.8500\n",
      "Epoch [6][10]\t Batch [1850][2750]\t Training Loss 0.1184\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [1900][2750]\t Training Loss 0.2428\t Accuracy 0.8500\n",
      "Epoch [6][10]\t Batch [1950][2750]\t Training Loss 0.2251\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [2000][2750]\t Training Loss 0.1341\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [2050][2750]\t Training Loss 0.1610\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [2100][2750]\t Training Loss 0.5524\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [2150][2750]\t Training Loss 0.3228\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [2200][2750]\t Training Loss 0.1958\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [2250][2750]\t Training Loss 0.3230\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [2300][2750]\t Training Loss 0.4923\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [2350][2750]\t Training Loss 0.0775\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [2400][2750]\t Training Loss 0.0848\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [2450][2750]\t Training Loss 0.2336\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [2500][2750]\t Training Loss 0.1061\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [2550][2750]\t Training Loss 0.2721\t Accuracy 0.9500\n",
      "Epoch [6][10]\t Batch [2600][2750]\t Training Loss 0.2061\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [2650][2750]\t Training Loss 0.3470\t Accuracy 0.8500\n",
      "Epoch [6][10]\t Batch [2700][2750]\t Training Loss 0.5488\t Accuracy 0.9000\n",
      "\n",
      "Epoch [6]\t Average training loss 0.2837\t Average training accuracy 0.9217\n",
      "Epoch [6]\t Average validation loss 0.2338\t Average validation accuracy 0.9366\n",
      "\n",
      "Epoch [7][10]\t Batch [0][2750]\t Training Loss 0.0576\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [50][2750]\t Training Loss 0.3004\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [100][2750]\t Training Loss 0.5773\t Accuracy 0.8000\n",
      "Epoch [7][10]\t Batch [150][2750]\t Training Loss 0.5261\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [200][2750]\t Training Loss 0.0943\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [250][2750]\t Training Loss 0.1262\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [300][2750]\t Training Loss 0.3015\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [350][2750]\t Training Loss 0.4108\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [400][2750]\t Training Loss 0.1297\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [450][2750]\t Training Loss 0.1562\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [500][2750]\t Training Loss 0.0660\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [550][2750]\t Training Loss 0.1908\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [600][2750]\t Training Loss 0.2465\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [650][2750]\t Training Loss 0.1871\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [700][2750]\t Training Loss 0.1867\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [750][2750]\t Training Loss 0.3631\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [800][2750]\t Training Loss 0.2783\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [850][2750]\t Training Loss 0.3401\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [900][2750]\t Training Loss 0.2082\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [950][2750]\t Training Loss 0.2814\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [1000][2750]\t Training Loss 0.1494\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [1050][2750]\t Training Loss 0.4715\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [1100][2750]\t Training Loss 0.1848\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [1150][2750]\t Training Loss 0.4457\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [1200][2750]\t Training Loss 1.0208\t Accuracy 0.8500\n",
      "Epoch [7][10]\t Batch [1250][2750]\t Training Loss 0.1828\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [1300][2750]\t Training Loss 0.4553\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [1350][2750]\t Training Loss 0.4856\t Accuracy 0.8500\n",
      "Epoch [7][10]\t Batch [1400][2750]\t Training Loss 0.7250\t Accuracy 0.8500\n",
      "Epoch [7][10]\t Batch [1450][2750]\t Training Loss 0.5997\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [1500][2750]\t Training Loss 0.0773\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1550][2750]\t Training Loss 0.1399\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [1600][2750]\t Training Loss 0.1603\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1650][2750]\t Training Loss 0.2044\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [1700][2750]\t Training Loss 0.6079\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [1750][2750]\t Training Loss 0.5393\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [1800][2750]\t Training Loss 0.0953\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [1850][2750]\t Training Loss 0.2467\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [1900][2750]\t Training Loss 0.1896\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [1950][2750]\t Training Loss 0.0933\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [2000][2750]\t Training Loss 0.3161\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [2050][2750]\t Training Loss 0.9355\t Accuracy 0.8500\n",
      "Epoch [7][10]\t Batch [2100][2750]\t Training Loss 0.0800\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2150][2750]\t Training Loss 0.1900\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [2200][2750]\t Training Loss 0.2879\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [2250][2750]\t Training Loss 0.0738\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2300][2750]\t Training Loss 0.5849\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [2350][2750]\t Training Loss 0.1635\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [2400][2750]\t Training Loss 0.3486\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [2450][2750]\t Training Loss 0.5644\t Accuracy 0.8500\n",
      "Epoch [7][10]\t Batch [2500][2750]\t Training Loss 0.1997\t Accuracy 0.9500\n",
      "Epoch [7][10]\t Batch [2550][2750]\t Training Loss 0.8334\t Accuracy 0.8500\n",
      "Epoch [7][10]\t Batch [2600][2750]\t Training Loss 0.1803\t Accuracy 1.0000\n",
      "Epoch [7][10]\t Batch [2650][2750]\t Training Loss 0.1511\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [2700][2750]\t Training Loss 0.6180\t Accuracy 0.8500\n",
      "\n",
      "Epoch [7]\t Average training loss 0.2812\t Average training accuracy 0.9222\n",
      "Epoch [7]\t Average validation loss 0.2318\t Average validation accuracy 0.9372\n",
      "\n",
      "Epoch [8][10]\t Batch [0][2750]\t Training Loss 0.5422\t Accuracy 0.8000\n",
      "Epoch [8][10]\t Batch [50][2750]\t Training Loss 0.1698\t Accuracy 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8][10]\t Batch [100][2750]\t Training Loss 0.1543\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [150][2750]\t Training Loss 0.2273\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [200][2750]\t Training Loss 0.0653\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [250][2750]\t Training Loss 0.1548\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [300][2750]\t Training Loss 0.1510\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [350][2750]\t Training Loss 0.3996\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [400][2750]\t Training Loss 0.1459\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [450][2750]\t Training Loss 0.1145\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [500][2750]\t Training Loss 0.3888\t Accuracy 0.8500\n",
      "Epoch [8][10]\t Batch [550][2750]\t Training Loss 0.4927\t Accuracy 0.8500\n",
      "Epoch [8][10]\t Batch [600][2750]\t Training Loss 0.0447\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [650][2750]\t Training Loss 0.3783\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [700][2750]\t Training Loss 0.2032\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [750][2750]\t Training Loss 0.0367\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [800][2750]\t Training Loss 0.0900\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [850][2750]\t Training Loss 0.3633\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [900][2750]\t Training Loss 0.5162\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [950][2750]\t Training Loss 0.2410\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [1000][2750]\t Training Loss 0.1468\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [1050][2750]\t Training Loss 0.1036\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1100][2750]\t Training Loss 0.2178\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [1150][2750]\t Training Loss 0.2832\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [1200][2750]\t Training Loss 0.3102\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [1250][2750]\t Training Loss 0.2339\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [1300][2750]\t Training Loss 0.3140\t Accuracy 0.8500\n",
      "Epoch [8][10]\t Batch [1350][2750]\t Training Loss 0.1468\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1400][2750]\t Training Loss 0.2146\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [1450][2750]\t Training Loss 0.2950\t Accuracy 0.8500\n",
      "Epoch [8][10]\t Batch [1500][2750]\t Training Loss 0.2957\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [1550][2750]\t Training Loss 0.2177\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [1600][2750]\t Training Loss 0.0862\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1650][2750]\t Training Loss 0.0200\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [1700][2750]\t Training Loss 0.1349\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [1750][2750]\t Training Loss 0.7163\t Accuracy 0.8500\n",
      "Epoch [8][10]\t Batch [1800][2750]\t Training Loss 0.3757\t Accuracy 0.8000\n",
      "Epoch [8][10]\t Batch [1850][2750]\t Training Loss 0.1962\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [1900][2750]\t Training Loss 0.2468\t Accuracy 0.8500\n",
      "Epoch [8][10]\t Batch [1950][2750]\t Training Loss 0.0965\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2000][2750]\t Training Loss 0.2857\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [2050][2750]\t Training Loss 0.4006\t Accuracy 0.8500\n",
      "Epoch [8][10]\t Batch [2100][2750]\t Training Loss 0.1184\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [2150][2750]\t Training Loss 0.3636\t Accuracy 0.8500\n",
      "Epoch [8][10]\t Batch [2200][2750]\t Training Loss 0.2034\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [2250][2750]\t Training Loss 0.1861\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [2300][2750]\t Training Loss 0.2814\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [2350][2750]\t Training Loss 0.1025\t Accuracy 0.9500\n",
      "Epoch [8][10]\t Batch [2400][2750]\t Training Loss 0.0714\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2450][2750]\t Training Loss 0.4570\t Accuracy 0.8500\n",
      "Epoch [8][10]\t Batch [2500][2750]\t Training Loss 0.3463\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [2550][2750]\t Training Loss 0.2521\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [2600][2750]\t Training Loss 0.3768\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [2650][2750]\t Training Loss 0.0957\t Accuracy 1.0000\n",
      "Epoch [8][10]\t Batch [2700][2750]\t Training Loss 0.0960\t Accuracy 0.9500\n",
      "\n",
      "Epoch [8]\t Average training loss 0.2787\t Average training accuracy 0.9230\n",
      "Epoch [8]\t Average validation loss 0.2307\t Average validation accuracy 0.9368\n",
      "\n",
      "Epoch [9][10]\t Batch [0][2750]\t Training Loss 0.1064\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [50][2750]\t Training Loss 0.4717\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [100][2750]\t Training Loss 0.3343\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [150][2750]\t Training Loss 0.0896\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [200][2750]\t Training Loss 0.1796\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [250][2750]\t Training Loss 0.3691\t Accuracy 0.8500\n",
      "Epoch [9][10]\t Batch [300][2750]\t Training Loss 0.1339\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [350][2750]\t Training Loss 0.1804\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [400][2750]\t Training Loss 0.2578\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [450][2750]\t Training Loss 0.3790\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [500][2750]\t Training Loss 0.0822\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [550][2750]\t Training Loss 0.1001\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [600][2750]\t Training Loss 0.2949\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [650][2750]\t Training Loss 0.0338\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [700][2750]\t Training Loss 0.4667\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [750][2750]\t Training Loss 0.0903\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [800][2750]\t Training Loss 0.3803\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [850][2750]\t Training Loss 0.1101\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [900][2750]\t Training Loss 0.2392\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [950][2750]\t Training Loss 0.2818\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [1000][2750]\t Training Loss 0.0283\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1050][2750]\t Training Loss 0.1487\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [1100][2750]\t Training Loss 0.0826\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [1150][2750]\t Training Loss 0.4288\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [1200][2750]\t Training Loss 0.0565\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1250][2750]\t Training Loss 0.0762\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1300][2750]\t Training Loss 0.6246\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [1350][2750]\t Training Loss 0.7649\t Accuracy 0.8500\n",
      "Epoch [9][10]\t Batch [1400][2750]\t Training Loss 0.1694\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [1450][2750]\t Training Loss 0.0781\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1500][2750]\t Training Loss 0.4356\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [1550][2750]\t Training Loss 0.2037\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [1600][2750]\t Training Loss 0.3940\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [1650][2750]\t Training Loss 0.1806\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [1700][2750]\t Training Loss 0.2800\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [1750][2750]\t Training Loss 0.0773\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [1800][2750]\t Training Loss 0.7082\t Accuracy 0.8000\n",
      "Epoch [9][10]\t Batch [1850][2750]\t Training Loss 0.2205\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [1900][2750]\t Training Loss 0.5197\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [1950][2750]\t Training Loss 0.4834\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [2000][2750]\t Training Loss 0.0948\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [2050][2750]\t Training Loss 0.0961\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2100][2750]\t Training Loss 0.1165\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [2150][2750]\t Training Loss 0.1734\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [2200][2750]\t Training Loss 0.2693\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [2250][2750]\t Training Loss 0.3801\t Accuracy 0.8500\n",
      "Epoch [9][10]\t Batch [2300][2750]\t Training Loss 0.2005\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [2350][2750]\t Training Loss 0.2526\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [2400][2750]\t Training Loss 0.2651\t Accuracy 0.8500\n",
      "Epoch [9][10]\t Batch [2450][2750]\t Training Loss 0.0822\t Accuracy 1.0000\n",
      "Epoch [9][10]\t Batch [2500][2750]\t Training Loss 0.2518\t Accuracy 0.8500\n",
      "Epoch [9][10]\t Batch [2550][2750]\t Training Loss 0.4260\t Accuracy 0.8500\n",
      "Epoch [9][10]\t Batch [2600][2750]\t Training Loss 0.4313\t Accuracy 0.9500\n",
      "Epoch [9][10]\t Batch [2650][2750]\t Training Loss 0.3888\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [2700][2750]\t Training Loss 0.0963\t Accuracy 1.0000\n",
      "\n",
      "Epoch [9]\t Average training loss 0.2777\t Average training accuracy 0.9227\n",
      "Epoch [9]\t Average validation loss 0.2289\t Average validation accuracy 0.9396\n",
      "\n",
      "Epoch [0][10]\t Batch [0][1100]\t Training Loss 2.4735\t Accuracy 0.1200\n",
      "Epoch [0][10]\t Batch [50][1100]\t Training Loss 0.8907\t Accuracy 0.7600\n",
      "Epoch [0][10]\t Batch [100][1100]\t Training Loss 0.7608\t Accuracy 0.7600\n",
      "Epoch [0][10]\t Batch [150][1100]\t Training Loss 0.4146\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [200][1100]\t Training Loss 0.4685\t Accuracy 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][10]\t Batch [250][1100]\t Training Loss 0.4893\t Accuracy 0.8600\n",
      "Epoch [0][10]\t Batch [300][1100]\t Training Loss 0.3407\t Accuracy 0.9200\n",
      "Epoch [0][10]\t Batch [350][1100]\t Training Loss 0.4157\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [400][1100]\t Training Loss 0.4450\t Accuracy 0.8400\n",
      "Epoch [0][10]\t Batch [450][1100]\t Training Loss 0.6347\t Accuracy 0.8600\n",
      "Epoch [0][10]\t Batch [500][1100]\t Training Loss 0.6606\t Accuracy 0.8200\n",
      "Epoch [0][10]\t Batch [550][1100]\t Training Loss 0.5338\t Accuracy 0.8800\n",
      "Epoch [0][10]\t Batch [600][1100]\t Training Loss 0.2267\t Accuracy 0.9200\n",
      "Epoch [0][10]\t Batch [650][1100]\t Training Loss 0.2469\t Accuracy 0.9600\n",
      "Epoch [0][10]\t Batch [700][1100]\t Training Loss 0.2976\t Accuracy 0.9400\n",
      "Epoch [0][10]\t Batch [750][1100]\t Training Loss 0.3436\t Accuracy 0.8600\n",
      "Epoch [0][10]\t Batch [800][1100]\t Training Loss 0.2535\t Accuracy 0.9200\n",
      "Epoch [0][10]\t Batch [850][1100]\t Training Loss 0.4640\t Accuracy 0.8600\n",
      "Epoch [0][10]\t Batch [900][1100]\t Training Loss 0.5284\t Accuracy 0.8000\n",
      "Epoch [0][10]\t Batch [950][1100]\t Training Loss 0.5852\t Accuracy 0.8600\n",
      "Epoch [0][10]\t Batch [1000][1100]\t Training Loss 0.2705\t Accuracy 0.9400\n",
      "Epoch [0][10]\t Batch [1050][1100]\t Training Loss 0.2865\t Accuracy 0.9200\n",
      "\n",
      "Epoch [0]\t Average training loss 0.4830\t Average training accuracy 0.8659\n",
      "Epoch [0]\t Average validation loss 0.2866\t Average validation accuracy 0.9226\n",
      "\n",
      "Epoch [1][10]\t Batch [0][1100]\t Training Loss 0.5944\t Accuracy 0.8400\n",
      "Epoch [1][10]\t Batch [50][1100]\t Training Loss 0.4912\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [100][1100]\t Training Loss 0.3501\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [150][1100]\t Training Loss 0.1749\t Accuracy 0.9600\n",
      "Epoch [1][10]\t Batch [200][1100]\t Training Loss 0.2842\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [250][1100]\t Training Loss 0.4938\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [300][1100]\t Training Loss 0.2638\t Accuracy 0.9200\n",
      "Epoch [1][10]\t Batch [350][1100]\t Training Loss 0.1968\t Accuracy 0.9400\n",
      "Epoch [1][10]\t Batch [400][1100]\t Training Loss 0.3377\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [450][1100]\t Training Loss 0.4573\t Accuracy 0.8600\n",
      "Epoch [1][10]\t Batch [500][1100]\t Training Loss 0.4426\t Accuracy 0.8600\n",
      "Epoch [1][10]\t Batch [550][1100]\t Training Loss 0.3747\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [600][1100]\t Training Loss 0.3525\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [650][1100]\t Training Loss 0.2868\t Accuracy 0.9200\n",
      "Epoch [1][10]\t Batch [700][1100]\t Training Loss 0.3022\t Accuracy 0.9400\n",
      "Epoch [1][10]\t Batch [750][1100]\t Training Loss 0.2795\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [800][1100]\t Training Loss 0.3492\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [850][1100]\t Training Loss 0.5254\t Accuracy 0.8600\n",
      "Epoch [1][10]\t Batch [900][1100]\t Training Loss 0.3965\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [950][1100]\t Training Loss 0.3215\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [1000][1100]\t Training Loss 0.4033\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [1050][1100]\t Training Loss 0.2853\t Accuracy 0.9000\n",
      "\n",
      "Epoch [1]\t Average training loss 0.3438\t Average training accuracy 0.9038\n",
      "Epoch [1]\t Average validation loss 0.2630\t Average validation accuracy 0.9292\n",
      "\n",
      "Epoch [2][10]\t Batch [0][1100]\t Training Loss 0.1265\t Accuracy 0.9600\n",
      "Epoch [2][10]\t Batch [50][1100]\t Training Loss 0.3035\t Accuracy 0.8600\n",
      "Epoch [2][10]\t Batch [100][1100]\t Training Loss 0.7200\t Accuracy 0.7600\n",
      "Epoch [2][10]\t Batch [150][1100]\t Training Loss 0.2003\t Accuracy 0.9800\n",
      "Epoch [2][10]\t Batch [200][1100]\t Training Loss 0.4192\t Accuracy 0.8800\n",
      "Epoch [2][10]\t Batch [250][1100]\t Training Loss 0.5038\t Accuracy 0.8800\n",
      "Epoch [2][10]\t Batch [300][1100]\t Training Loss 0.1694\t Accuracy 0.9600\n",
      "Epoch [2][10]\t Batch [350][1100]\t Training Loss 0.1627\t Accuracy 0.9800\n",
      "Epoch [2][10]\t Batch [400][1100]\t Training Loss 0.3401\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [450][1100]\t Training Loss 0.4740\t Accuracy 0.8800\n",
      "Epoch [2][10]\t Batch [500][1100]\t Training Loss 0.2620\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [550][1100]\t Training Loss 0.3514\t Accuracy 0.8600\n",
      "Epoch [2][10]\t Batch [600][1100]\t Training Loss 0.1812\t Accuracy 0.9800\n",
      "Epoch [2][10]\t Batch [650][1100]\t Training Loss 0.1605\t Accuracy 0.9600\n",
      "Epoch [2][10]\t Batch [700][1100]\t Training Loss 0.4409\t Accuracy 0.8400\n",
      "Epoch [2][10]\t Batch [750][1100]\t Training Loss 0.2935\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [800][1100]\t Training Loss 0.4659\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [850][1100]\t Training Loss 0.1731\t Accuracy 0.9600\n",
      "Epoch [2][10]\t Batch [900][1100]\t Training Loss 0.2361\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [950][1100]\t Training Loss 0.3846\t Accuracy 0.8800\n",
      "Epoch [2][10]\t Batch [1000][1100]\t Training Loss 0.1792\t Accuracy 0.9400\n",
      "Epoch [2][10]\t Batch [1050][1100]\t Training Loss 0.3598\t Accuracy 0.8800\n",
      "\n",
      "Epoch [2]\t Average training loss 0.3228\t Average training accuracy 0.9097\n",
      "Epoch [2]\t Average validation loss 0.2535\t Average validation accuracy 0.9300\n",
      "\n",
      "Epoch [3][10]\t Batch [0][1100]\t Training Loss 0.2648\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [50][1100]\t Training Loss 0.4464\t Accuracy 0.8600\n",
      "Epoch [3][10]\t Batch [100][1100]\t Training Loss 0.2699\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [150][1100]\t Training Loss 0.3049\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [200][1100]\t Training Loss 0.1624\t Accuracy 0.9600\n",
      "Epoch [3][10]\t Batch [250][1100]\t Training Loss 0.3080\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [300][1100]\t Training Loss 0.4490\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [350][1100]\t Training Loss 0.1341\t Accuracy 0.9600\n",
      "Epoch [3][10]\t Batch [400][1100]\t Training Loss 0.4393\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [450][1100]\t Training Loss 0.1590\t Accuracy 0.9600\n",
      "Epoch [3][10]\t Batch [500][1100]\t Training Loss 0.2087\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [550][1100]\t Training Loss 0.3493\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [600][1100]\t Training Loss 0.3663\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [650][1100]\t Training Loss 0.0748\t Accuracy 1.0000\n",
      "Epoch [3][10]\t Batch [700][1100]\t Training Loss 0.2468\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [750][1100]\t Training Loss 0.3129\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [800][1100]\t Training Loss 0.3950\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [850][1100]\t Training Loss 0.3705\t Accuracy 0.8800\n",
      "Epoch [3][10]\t Batch [900][1100]\t Training Loss 0.2537\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [950][1100]\t Training Loss 0.3111\t Accuracy 0.9000\n",
      "Epoch [3][10]\t Batch [1000][1100]\t Training Loss 0.3302\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [1050][1100]\t Training Loss 0.2661\t Accuracy 0.9000\n",
      "\n",
      "Epoch [3]\t Average training loss 0.3123\t Average training accuracy 0.9126\n",
      "Epoch [3]\t Average validation loss 0.2470\t Average validation accuracy 0.9334\n",
      "\n",
      "Epoch [4][10]\t Batch [0][1100]\t Training Loss 0.2777\t Accuracy 0.9400\n",
      "Epoch [4][10]\t Batch [50][1100]\t Training Loss 0.1234\t Accuracy 0.9800\n",
      "Epoch [4][10]\t Batch [100][1100]\t Training Loss 0.2018\t Accuracy 0.9400\n",
      "Epoch [4][10]\t Batch [150][1100]\t Training Loss 0.4084\t Accuracy 0.8800\n",
      "Epoch [4][10]\t Batch [200][1100]\t Training Loss 0.3026\t Accuracy 0.9200\n",
      "Epoch [4][10]\t Batch [250][1100]\t Training Loss 0.1557\t Accuracy 0.9800\n",
      "Epoch [4][10]\t Batch [300][1100]\t Training Loss 0.6147\t Accuracy 0.8000\n",
      "Epoch [4][10]\t Batch [350][1100]\t Training Loss 0.2487\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [400][1100]\t Training Loss 0.4168\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [450][1100]\t Training Loss 0.4008\t Accuracy 0.8600\n",
      "Epoch [4][10]\t Batch [500][1100]\t Training Loss 0.2584\t Accuracy 0.9600\n",
      "Epoch [4][10]\t Batch [550][1100]\t Training Loss 0.2538\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [600][1100]\t Training Loss 0.2372\t Accuracy 0.9400\n",
      "Epoch [4][10]\t Batch [650][1100]\t Training Loss 0.2035\t Accuracy 0.9400\n",
      "Epoch [4][10]\t Batch [700][1100]\t Training Loss 0.4276\t Accuracy 0.9400\n",
      "Epoch [4][10]\t Batch [750][1100]\t Training Loss 0.2538\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [800][1100]\t Training Loss 0.2519\t Accuracy 0.9200\n",
      "Epoch [4][10]\t Batch [850][1100]\t Training Loss 0.2921\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [900][1100]\t Training Loss 0.2444\t Accuracy 0.9600\n",
      "Epoch [4][10]\t Batch [950][1100]\t Training Loss 0.2580\t Accuracy 0.9200\n",
      "Epoch [4][10]\t Batch [1000][1100]\t Training Loss 0.5144\t Accuracy 0.8600\n",
      "Epoch [4][10]\t Batch [1050][1100]\t Training Loss 0.4274\t Accuracy 0.8600\n",
      "\n",
      "Epoch [4]\t Average training loss 0.3048\t Average training accuracy 0.9150\n",
      "Epoch [4]\t Average validation loss 0.2449\t Average validation accuracy 0.9346\n",
      "\n",
      "Epoch [5][10]\t Batch [0][1100]\t Training Loss 0.1497\t Accuracy 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5][10]\t Batch [50][1100]\t Training Loss 0.6235\t Accuracy 0.8800\n",
      "Epoch [5][10]\t Batch [100][1100]\t Training Loss 0.1267\t Accuracy 0.9800\n",
      "Epoch [5][10]\t Batch [150][1100]\t Training Loss 0.3234\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [200][1100]\t Training Loss 0.2466\t Accuracy 0.9600\n",
      "Epoch [5][10]\t Batch [250][1100]\t Training Loss 0.3011\t Accuracy 0.9400\n",
      "Epoch [5][10]\t Batch [300][1100]\t Training Loss 0.4159\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [350][1100]\t Training Loss 0.5693\t Accuracy 0.8600\n",
      "Epoch [5][10]\t Batch [400][1100]\t Training Loss 0.1613\t Accuracy 0.9800\n",
      "Epoch [5][10]\t Batch [450][1100]\t Training Loss 0.2907\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [500][1100]\t Training Loss 0.1572\t Accuracy 0.9400\n",
      "Epoch [5][10]\t Batch [550][1100]\t Training Loss 0.1616\t Accuracy 0.9400\n",
      "Epoch [5][10]\t Batch [600][1100]\t Training Loss 0.2656\t Accuracy 0.9200\n",
      "Epoch [5][10]\t Batch [650][1100]\t Training Loss 0.4160\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [700][1100]\t Training Loss 0.3784\t Accuracy 0.9400\n",
      "Epoch [5][10]\t Batch [750][1100]\t Training Loss 0.2358\t Accuracy 0.9400\n",
      "Epoch [5][10]\t Batch [800][1100]\t Training Loss 0.2972\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [850][1100]\t Training Loss 0.1488\t Accuracy 0.9800\n",
      "Epoch [5][10]\t Batch [900][1100]\t Training Loss 0.1898\t Accuracy 0.9400\n",
      "Epoch [5][10]\t Batch [950][1100]\t Training Loss 0.1985\t Accuracy 0.9200\n",
      "Epoch [5][10]\t Batch [1000][1100]\t Training Loss 0.0823\t Accuracy 0.9800\n",
      "Epoch [5][10]\t Batch [1050][1100]\t Training Loss 0.2844\t Accuracy 0.9000\n",
      "\n",
      "Epoch [5]\t Average training loss 0.2999\t Average training accuracy 0.9169\n",
      "Epoch [5]\t Average validation loss 0.2400\t Average validation accuracy 0.9352\n",
      "\n",
      "Epoch [6][10]\t Batch [0][1100]\t Training Loss 0.1841\t Accuracy 0.9600\n",
      "Epoch [6][10]\t Batch [50][1100]\t Training Loss 0.2943\t Accuracy 0.8600\n",
      "Epoch [6][10]\t Batch [100][1100]\t Training Loss 0.1712\t Accuracy 0.9600\n",
      "Epoch [6][10]\t Batch [150][1100]\t Training Loss 0.1729\t Accuracy 0.9200\n",
      "Epoch [6][10]\t Batch [200][1100]\t Training Loss 0.2276\t Accuracy 0.9200\n",
      "Epoch [6][10]\t Batch [250][1100]\t Training Loss 0.1493\t Accuracy 0.9400\n",
      "Epoch [6][10]\t Batch [300][1100]\t Training Loss 0.4010\t Accuracy 0.8800\n",
      "Epoch [6][10]\t Batch [350][1100]\t Training Loss 0.2824\t Accuracy 0.9400\n",
      "Epoch [6][10]\t Batch [400][1100]\t Training Loss 0.1634\t Accuracy 0.9800\n",
      "Epoch [6][10]\t Batch [450][1100]\t Training Loss 0.1483\t Accuracy 0.9600\n",
      "Epoch [6][10]\t Batch [500][1100]\t Training Loss 0.1779\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [550][1100]\t Training Loss 0.2277\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [600][1100]\t Training Loss 0.1200\t Accuracy 0.9800\n",
      "Epoch [6][10]\t Batch [650][1100]\t Training Loss 0.2485\t Accuracy 0.9200\n",
      "Epoch [6][10]\t Batch [700][1100]\t Training Loss 0.4355\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [750][1100]\t Training Loss 0.4164\t Accuracy 0.8600\n",
      "Epoch [6][10]\t Batch [800][1100]\t Training Loss 0.3000\t Accuracy 0.9200\n",
      "Epoch [6][10]\t Batch [850][1100]\t Training Loss 0.5308\t Accuracy 0.8200\n",
      "Epoch [6][10]\t Batch [900][1100]\t Training Loss 0.3558\t Accuracy 0.8800\n",
      "Epoch [6][10]\t Batch [950][1100]\t Training Loss 0.4634\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [1000][1100]\t Training Loss 0.2682\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [1050][1100]\t Training Loss 0.3781\t Accuracy 0.8800\n",
      "\n",
      "Epoch [6]\t Average training loss 0.2957\t Average training accuracy 0.9172\n",
      "Epoch [6]\t Average validation loss 0.2380\t Average validation accuracy 0.9380\n",
      "\n",
      "Epoch [7][10]\t Batch [0][1100]\t Training Loss 0.2533\t Accuracy 0.8600\n",
      "Epoch [7][10]\t Batch [50][1100]\t Training Loss 0.2068\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [100][1100]\t Training Loss 0.1787\t Accuracy 0.9600\n",
      "Epoch [7][10]\t Batch [150][1100]\t Training Loss 0.2528\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [200][1100]\t Training Loss 0.1902\t Accuracy 0.9200\n",
      "Epoch [7][10]\t Batch [250][1100]\t Training Loss 0.1402\t Accuracy 0.9600\n",
      "Epoch [7][10]\t Batch [300][1100]\t Training Loss 0.2198\t Accuracy 0.9800\n",
      "Epoch [7][10]\t Batch [350][1100]\t Training Loss 0.3227\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [400][1100]\t Training Loss 0.4740\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [450][1100]\t Training Loss 0.3643\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [500][1100]\t Training Loss 0.4165\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [550][1100]\t Training Loss 0.1763\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [600][1100]\t Training Loss 0.3332\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [650][1100]\t Training Loss 0.4612\t Accuracy 0.8600\n",
      "Epoch [7][10]\t Batch [700][1100]\t Training Loss 0.5016\t Accuracy 0.8400\n",
      "Epoch [7][10]\t Batch [750][1100]\t Training Loss 0.2345\t Accuracy 0.9200\n",
      "Epoch [7][10]\t Batch [800][1100]\t Training Loss 0.4288\t Accuracy 0.8800\n",
      "Epoch [7][10]\t Batch [850][1100]\t Training Loss 0.2521\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [900][1100]\t Training Loss 0.4916\t Accuracy 0.8600\n",
      "Epoch [7][10]\t Batch [950][1100]\t Training Loss 0.3638\t Accuracy 0.8600\n",
      "Epoch [7][10]\t Batch [1000][1100]\t Training Loss 0.3284\t Accuracy 0.9200\n",
      "Epoch [7][10]\t Batch [1050][1100]\t Training Loss 0.3150\t Accuracy 0.8800\n",
      "\n",
      "Epoch [7]\t Average training loss 0.2924\t Average training accuracy 0.9184\n",
      "Epoch [7]\t Average validation loss 0.2367\t Average validation accuracy 0.9346\n",
      "\n",
      "Epoch [8][10]\t Batch [0][1100]\t Training Loss 0.1905\t Accuracy 0.9600\n",
      "Epoch [8][10]\t Batch [50][1100]\t Training Loss 0.3194\t Accuracy 0.8800\n",
      "Epoch [8][10]\t Batch [100][1100]\t Training Loss 0.4041\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [150][1100]\t Training Loss 0.1979\t Accuracy 0.9400\n",
      "Epoch [8][10]\t Batch [200][1100]\t Training Loss 0.1264\t Accuracy 0.9600\n",
      "Epoch [8][10]\t Batch [250][1100]\t Training Loss 0.2163\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [300][1100]\t Training Loss 0.3527\t Accuracy 0.9200\n",
      "Epoch [8][10]\t Batch [350][1100]\t Training Loss 0.1803\t Accuracy 0.9400\n",
      "Epoch [8][10]\t Batch [400][1100]\t Training Loss 0.4967\t Accuracy 0.8800\n",
      "Epoch [8][10]\t Batch [450][1100]\t Training Loss 0.3485\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [500][1100]\t Training Loss 0.2339\t Accuracy 0.9400\n",
      "Epoch [8][10]\t Batch [550][1100]\t Training Loss 0.0928\t Accuracy 0.9800\n",
      "Epoch [8][10]\t Batch [600][1100]\t Training Loss 0.2145\t Accuracy 0.9400\n",
      "Epoch [8][10]\t Batch [650][1100]\t Training Loss 0.1478\t Accuracy 0.9600\n",
      "Epoch [8][10]\t Batch [700][1100]\t Training Loss 0.4441\t Accuracy 0.8600\n",
      "Epoch [8][10]\t Batch [750][1100]\t Training Loss 0.2785\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [800][1100]\t Training Loss 0.2957\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [850][1100]\t Training Loss 0.2725\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [900][1100]\t Training Loss 0.1890\t Accuracy 0.9600\n",
      "Epoch [8][10]\t Batch [950][1100]\t Training Loss 0.5084\t Accuracy 0.8600\n",
      "Epoch [8][10]\t Batch [1000][1100]\t Training Loss 0.4577\t Accuracy 0.8400\n",
      "Epoch [8][10]\t Batch [1050][1100]\t Training Loss 0.3770\t Accuracy 0.9400\n",
      "\n",
      "Epoch [8]\t Average training loss 0.2896\t Average training accuracy 0.9196\n",
      "Epoch [8]\t Average validation loss 0.2347\t Average validation accuracy 0.9384\n",
      "\n",
      "Epoch [9][10]\t Batch [0][1100]\t Training Loss 0.1762\t Accuracy 0.9400\n",
      "Epoch [9][10]\t Batch [50][1100]\t Training Loss 0.2518\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [100][1100]\t Training Loss 0.4382\t Accuracy 0.8800\n",
      "Epoch [9][10]\t Batch [150][1100]\t Training Loss 0.1337\t Accuracy 0.9600\n",
      "Epoch [9][10]\t Batch [200][1100]\t Training Loss 0.1732\t Accuracy 0.9600\n",
      "Epoch [9][10]\t Batch [250][1100]\t Training Loss 0.2772\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [300][1100]\t Training Loss 0.6612\t Accuracy 0.8600\n",
      "Epoch [9][10]\t Batch [350][1100]\t Training Loss 0.4951\t Accuracy 0.8800\n",
      "Epoch [9][10]\t Batch [400][1100]\t Training Loss 0.2540\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [450][1100]\t Training Loss 0.4273\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [500][1100]\t Training Loss 0.3090\t Accuracy 0.8600\n",
      "Epoch [9][10]\t Batch [550][1100]\t Training Loss 0.3068\t Accuracy 0.9400\n",
      "Epoch [9][10]\t Batch [600][1100]\t Training Loss 0.3138\t Accuracy 0.9400\n",
      "Epoch [9][10]\t Batch [650][1100]\t Training Loss 0.3459\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [700][1100]\t Training Loss 0.1907\t Accuracy 0.9400\n",
      "Epoch [9][10]\t Batch [750][1100]\t Training Loss 0.2764\t Accuracy 0.9400\n",
      "Epoch [9][10]\t Batch [800][1100]\t Training Loss 0.2180\t Accuracy 0.9800\n",
      "Epoch [9][10]\t Batch [850][1100]\t Training Loss 0.3596\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [900][1100]\t Training Loss 0.3402\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [950][1100]\t Training Loss 0.1979\t Accuracy 0.9800\n",
      "Epoch [9][10]\t Batch [1000][1100]\t Training Loss 0.2464\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [1050][1100]\t Training Loss 0.2165\t Accuracy 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [9]\t Average training loss 0.2871\t Average training accuracy 0.9205\n",
      "Epoch [9]\t Average validation loss 0.2355\t Average validation accuracy 0.9380\n",
      "\n",
      "Epoch [0][10]\t Batch [0][550]\t Training Loss 2.4085\t Accuracy 0.1100\n",
      "Epoch [0][10]\t Batch [50][550]\t Training Loss 0.8753\t Accuracy 0.7300\n",
      "Epoch [0][10]\t Batch [100][550]\t Training Loss 0.7577\t Accuracy 0.8000\n",
      "Epoch [0][10]\t Batch [150][550]\t Training Loss 0.4669\t Accuracy 0.9100\n",
      "Epoch [0][10]\t Batch [200][550]\t Training Loss 0.5846\t Accuracy 0.8300\n",
      "Epoch [0][10]\t Batch [250][550]\t Training Loss 0.3764\t Accuracy 0.9100\n",
      "Epoch [0][10]\t Batch [300][550]\t Training Loss 0.3704\t Accuracy 0.9200\n",
      "Epoch [0][10]\t Batch [350][550]\t Training Loss 0.2760\t Accuracy 0.9400\n",
      "Epoch [0][10]\t Batch [400][550]\t Training Loss 0.4877\t Accuracy 0.8700\n",
      "Epoch [0][10]\t Batch [450][550]\t Training Loss 0.4047\t Accuracy 0.9000\n",
      "Epoch [0][10]\t Batch [500][550]\t Training Loss 0.4242\t Accuracy 0.8400\n",
      "\n",
      "Epoch [0]\t Average training loss 0.5848\t Average training accuracy 0.8404\n",
      "Epoch [0]\t Average validation loss 0.3159\t Average validation accuracy 0.9164\n",
      "\n",
      "Epoch [1][10]\t Batch [0][550]\t Training Loss 0.4537\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [50][550]\t Training Loss 0.4227\t Accuracy 0.8500\n",
      "Epoch [1][10]\t Batch [100][550]\t Training Loss 0.4186\t Accuracy 0.8800\n",
      "Epoch [1][10]\t Batch [150][550]\t Training Loss 0.3079\t Accuracy 0.9100\n",
      "Epoch [1][10]\t Batch [200][550]\t Training Loss 0.2701\t Accuracy 0.9400\n",
      "Epoch [1][10]\t Batch [250][550]\t Training Loss 0.5980\t Accuracy 0.8600\n",
      "Epoch [1][10]\t Batch [300][550]\t Training Loss 0.3384\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [350][550]\t Training Loss 0.2612\t Accuracy 0.9200\n",
      "Epoch [1][10]\t Batch [400][550]\t Training Loss 0.3672\t Accuracy 0.8700\n",
      "Epoch [1][10]\t Batch [450][550]\t Training Loss 0.2431\t Accuracy 0.9500\n",
      "Epoch [1][10]\t Batch [500][550]\t Training Loss 0.2246\t Accuracy 0.9800\n",
      "\n",
      "Epoch [1]\t Average training loss 0.3784\t Average training accuracy 0.8947\n",
      "Epoch [1]\t Average validation loss 0.2809\t Average validation accuracy 0.9240\n",
      "\n",
      "Epoch [2][10]\t Batch [0][550]\t Training Loss 0.4233\t Accuracy 0.8700\n",
      "Epoch [2][10]\t Batch [50][550]\t Training Loss 0.3879\t Accuracy 0.8700\n",
      "Epoch [2][10]\t Batch [100][550]\t Training Loss 0.3562\t Accuracy 0.9200\n",
      "Epoch [2][10]\t Batch [150][550]\t Training Loss 0.4998\t Accuracy 0.8500\n",
      "Epoch [2][10]\t Batch [200][550]\t Training Loss 0.3383\t Accuracy 0.9300\n",
      "Epoch [2][10]\t Batch [250][550]\t Training Loss 0.2759\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [300][550]\t Training Loss 0.2558\t Accuracy 0.9300\n",
      "Epoch [2][10]\t Batch [350][550]\t Training Loss 0.3879\t Accuracy 0.9000\n",
      "Epoch [2][10]\t Batch [400][550]\t Training Loss 0.2991\t Accuracy 0.9400\n",
      "Epoch [2][10]\t Batch [450][550]\t Training Loss 0.2729\t Accuracy 0.9400\n",
      "Epoch [2][10]\t Batch [500][550]\t Training Loss 0.4437\t Accuracy 0.9100\n",
      "\n",
      "Epoch [2]\t Average training loss 0.3489\t Average training accuracy 0.9019\n",
      "Epoch [2]\t Average validation loss 0.2650\t Average validation accuracy 0.9288\n",
      "\n",
      "Epoch [3][10]\t Batch [0][550]\t Training Loss 0.2937\t Accuracy 0.9100\n",
      "Epoch [3][10]\t Batch [50][550]\t Training Loss 0.3447\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [100][550]\t Training Loss 0.3155\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [150][550]\t Training Loss 0.3303\t Accuracy 0.9200\n",
      "Epoch [3][10]\t Batch [200][550]\t Training Loss 0.2996\t Accuracy 0.9300\n",
      "Epoch [3][10]\t Batch [250][550]\t Training Loss 0.2690\t Accuracy 0.9100\n",
      "Epoch [3][10]\t Batch [300][550]\t Training Loss 0.4829\t Accuracy 0.8500\n",
      "Epoch [3][10]\t Batch [350][550]\t Training Loss 0.3412\t Accuracy 0.9100\n",
      "Epoch [3][10]\t Batch [400][550]\t Training Loss 0.3053\t Accuracy 0.8700\n",
      "Epoch [3][10]\t Batch [450][550]\t Training Loss 0.3929\t Accuracy 0.9100\n",
      "Epoch [3][10]\t Batch [500][550]\t Training Loss 0.5079\t Accuracy 0.8500\n",
      "\n",
      "Epoch [3]\t Average training loss 0.3331\t Average training accuracy 0.9062\n",
      "Epoch [3]\t Average validation loss 0.2571\t Average validation accuracy 0.9314\n",
      "\n",
      "Epoch [4][10]\t Batch [0][550]\t Training Loss 0.3416\t Accuracy 0.9000\n",
      "Epoch [4][10]\t Batch [50][550]\t Training Loss 0.1155\t Accuracy 0.9900\n",
      "Epoch [4][10]\t Batch [100][550]\t Training Loss 0.2326\t Accuracy 0.9300\n",
      "Epoch [4][10]\t Batch [150][550]\t Training Loss 0.2818\t Accuracy 0.9600\n",
      "Epoch [4][10]\t Batch [200][550]\t Training Loss 0.3022\t Accuracy 0.9100\n",
      "Epoch [4][10]\t Batch [250][550]\t Training Loss 0.3399\t Accuracy 0.9100\n",
      "Epoch [4][10]\t Batch [300][550]\t Training Loss 0.2698\t Accuracy 0.9500\n",
      "Epoch [4][10]\t Batch [350][550]\t Training Loss 0.5004\t Accuracy 0.8900\n",
      "Epoch [4][10]\t Batch [400][550]\t Training Loss 0.3125\t Accuracy 0.8800\n",
      "Epoch [4][10]\t Batch [450][550]\t Training Loss 0.3966\t Accuracy 0.8900\n",
      "Epoch [4][10]\t Batch [500][550]\t Training Loss 0.1971\t Accuracy 0.9600\n",
      "\n",
      "Epoch [4]\t Average training loss 0.3236\t Average training accuracy 0.9087\n",
      "Epoch [4]\t Average validation loss 0.2510\t Average validation accuracy 0.9324\n",
      "\n",
      "Epoch [5][10]\t Batch [0][550]\t Training Loss 0.3290\t Accuracy 0.9200\n",
      "Epoch [5][10]\t Batch [50][550]\t Training Loss 0.2630\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [100][550]\t Training Loss 0.4206\t Accuracy 0.8800\n",
      "Epoch [5][10]\t Batch [150][550]\t Training Loss 0.3359\t Accuracy 0.9400\n",
      "Epoch [5][10]\t Batch [200][550]\t Training Loss 0.3797\t Accuracy 0.9100\n",
      "Epoch [5][10]\t Batch [250][550]\t Training Loss 0.2864\t Accuracy 0.9100\n",
      "Epoch [5][10]\t Batch [300][550]\t Training Loss 0.2667\t Accuracy 0.9000\n",
      "Epoch [5][10]\t Batch [350][550]\t Training Loss 0.3380\t Accuracy 0.9200\n",
      "Epoch [5][10]\t Batch [400][550]\t Training Loss 0.2249\t Accuracy 0.9400\n",
      "Epoch [5][10]\t Batch [450][550]\t Training Loss 0.4541\t Accuracy 0.9100\n",
      "Epoch [5][10]\t Batch [500][550]\t Training Loss 0.2426\t Accuracy 0.9100\n",
      "\n",
      "Epoch [5]\t Average training loss 0.3164\t Average training accuracy 0.9109\n",
      "Epoch [5]\t Average validation loss 0.2473\t Average validation accuracy 0.9328\n",
      "\n",
      "Epoch [6][10]\t Batch [0][550]\t Training Loss 0.4698\t Accuracy 0.8800\n",
      "Epoch [6][10]\t Batch [50][550]\t Training Loss 0.1865\t Accuracy 0.9600\n",
      "Epoch [6][10]\t Batch [100][550]\t Training Loss 0.2849\t Accuracy 0.9400\n",
      "Epoch [6][10]\t Batch [150][550]\t Training Loss 0.3439\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [200][550]\t Training Loss 0.3813\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [250][550]\t Training Loss 0.2561\t Accuracy 0.9400\n",
      "Epoch [6][10]\t Batch [300][550]\t Training Loss 0.3272\t Accuracy 0.8800\n",
      "Epoch [6][10]\t Batch [350][550]\t Training Loss 0.2772\t Accuracy 0.9000\n",
      "Epoch [6][10]\t Batch [400][550]\t Training Loss 0.3917\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [450][550]\t Training Loss 0.2333\t Accuracy 0.9300\n",
      "Epoch [6][10]\t Batch [500][550]\t Training Loss 0.2251\t Accuracy 0.9500\n",
      "\n",
      "Epoch [6]\t Average training loss 0.3113\t Average training accuracy 0.9127\n",
      "Epoch [6]\t Average validation loss 0.2442\t Average validation accuracy 0.9338\n",
      "\n",
      "Epoch [7][10]\t Batch [0][550]\t Training Loss 0.2274\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [50][550]\t Training Loss 0.3785\t Accuracy 0.9200\n",
      "Epoch [7][10]\t Batch [100][550]\t Training Loss 0.2366\t Accuracy 0.9100\n",
      "Epoch [7][10]\t Batch [150][550]\t Training Loss 0.3085\t Accuracy 0.8800\n",
      "Epoch [7][10]\t Batch [200][550]\t Training Loss 0.2644\t Accuracy 0.9200\n",
      "Epoch [7][10]\t Batch [250][550]\t Training Loss 0.4107\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [300][550]\t Training Loss 0.4545\t Accuracy 0.8900\n",
      "Epoch [7][10]\t Batch [350][550]\t Training Loss 0.2533\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [400][550]\t Training Loss 0.2612\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [450][550]\t Training Loss 0.3457\t Accuracy 0.9000\n",
      "Epoch [7][10]\t Batch [500][550]\t Training Loss 0.3008\t Accuracy 0.9200\n",
      "\n",
      "Epoch [7]\t Average training loss 0.3068\t Average training accuracy 0.9143\n",
      "Epoch [7]\t Average validation loss 0.2435\t Average validation accuracy 0.9342\n",
      "\n",
      "Epoch [8][10]\t Batch [0][550]\t Training Loss 0.5057\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [50][550]\t Training Loss 0.3055\t Accuracy 0.9300\n",
      "Epoch [8][10]\t Batch [100][550]\t Training Loss 0.2727\t Accuracy 0.9100\n",
      "Epoch [8][10]\t Batch [150][550]\t Training Loss 0.2322\t Accuracy 0.9100\n",
      "Epoch [8][10]\t Batch [200][550]\t Training Loss 0.2514\t Accuracy 0.9100\n",
      "Epoch [8][10]\t Batch [250][550]\t Training Loss 0.3358\t Accuracy 0.8900\n",
      "Epoch [8][10]\t Batch [300][550]\t Training Loss 0.4220\t Accuracy 0.9000\n",
      "Epoch [8][10]\t Batch [350][550]\t Training Loss 0.2151\t Accuracy 0.9400\n",
      "Epoch [8][10]\t Batch [400][550]\t Training Loss 0.3039\t Accuracy 0.9300\n",
      "Epoch [8][10]\t Batch [450][550]\t Training Loss 0.2883\t Accuracy 0.9100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8][10]\t Batch [500][550]\t Training Loss 0.3759\t Accuracy 0.8900\n",
      "\n",
      "Epoch [8]\t Average training loss 0.3030\t Average training accuracy 0.9153\n",
      "Epoch [8]\t Average validation loss 0.2398\t Average validation accuracy 0.9360\n",
      "\n",
      "Epoch [9][10]\t Batch [0][550]\t Training Loss 0.2754\t Accuracy 0.9200\n",
      "Epoch [9][10]\t Batch [50][550]\t Training Loss 0.2758\t Accuracy 0.9100\n",
      "Epoch [9][10]\t Batch [100][550]\t Training Loss 0.3185\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [150][550]\t Training Loss 0.3061\t Accuracy 0.8800\n",
      "Epoch [9][10]\t Batch [200][550]\t Training Loss 0.3304\t Accuracy 0.8800\n",
      "Epoch [9][10]\t Batch [250][550]\t Training Loss 0.3358\t Accuracy 0.9100\n",
      "Epoch [9][10]\t Batch [300][550]\t Training Loss 0.3160\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [350][550]\t Training Loss 0.3068\t Accuracy 0.9100\n",
      "Epoch [9][10]\t Batch [400][550]\t Training Loss 0.1705\t Accuracy 0.9400\n",
      "Epoch [9][10]\t Batch [450][550]\t Training Loss 0.3103\t Accuracy 0.9100\n",
      "Epoch [9][10]\t Batch [500][550]\t Training Loss 0.2565\t Accuracy 0.9300\n",
      "\n",
      "Epoch [9]\t Average training loss 0.3002\t Average training accuracy 0.9164\n",
      "Epoch [9]\t Average validation loss 0.2384\t Average validation accuracy 0.9344\n",
      "\n",
      "Epoch [0][10]\t Batch [0][275]\t Training Loss 2.5044\t Accuracy 0.1250\n",
      "Epoch [0][10]\t Batch [50][275]\t Training Loss 0.9025\t Accuracy 0.7650\n",
      "Epoch [0][10]\t Batch [100][275]\t Training Loss 0.6494\t Accuracy 0.8200\n",
      "Epoch [0][10]\t Batch [150][275]\t Training Loss 0.5910\t Accuracy 0.8350\n",
      "Epoch [0][10]\t Batch [200][275]\t Training Loss 0.4316\t Accuracy 0.8950\n",
      "Epoch [0][10]\t Batch [250][275]\t Training Loss 0.4728\t Accuracy 0.8650\n",
      "\n",
      "Epoch [0]\t Average training loss 0.7411\t Average training accuracy 0.7958\n",
      "Epoch [0]\t Average validation loss 0.3742\t Average validation accuracy 0.9070\n",
      "\n",
      "Epoch [1][10]\t Batch [0][275]\t Training Loss 0.4459\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [50][275]\t Training Loss 0.5121\t Accuracy 0.8650\n",
      "Epoch [1][10]\t Batch [100][275]\t Training Loss 0.3993\t Accuracy 0.9000\n",
      "Epoch [1][10]\t Batch [150][275]\t Training Loss 0.4578\t Accuracy 0.8600\n",
      "Epoch [1][10]\t Batch [200][275]\t Training Loss 0.4756\t Accuracy 0.8650\n",
      "Epoch [1][10]\t Batch [250][275]\t Training Loss 0.4274\t Accuracy 0.8800\n",
      "\n",
      "Epoch [1]\t Average training loss 0.4297\t Average training accuracy 0.8825\n",
      "Epoch [1]\t Average validation loss 0.3171\t Average validation accuracy 0.9166\n",
      "\n",
      "Epoch [2][10]\t Batch [0][275]\t Training Loss 0.4605\t Accuracy 0.8400\n",
      "Epoch [2][10]\t Batch [50][275]\t Training Loss 0.4881\t Accuracy 0.8600\n",
      "Epoch [2][10]\t Batch [100][275]\t Training Loss 0.3854\t Accuracy 0.8950\n",
      "Epoch [2][10]\t Batch [150][275]\t Training Loss 0.4109\t Accuracy 0.8750\n",
      "Epoch [2][10]\t Batch [200][275]\t Training Loss 0.3652\t Accuracy 0.9150\n",
      "Epoch [2][10]\t Batch [250][275]\t Training Loss 0.3066\t Accuracy 0.9250\n",
      "\n",
      "Epoch [2]\t Average training loss 0.3877\t Average training accuracy 0.8927\n",
      "Epoch [2]\t Average validation loss 0.2948\t Average validation accuracy 0.9212\n",
      "\n",
      "Epoch [3][10]\t Batch [0][275]\t Training Loss 0.4591\t Accuracy 0.8750\n",
      "Epoch [3][10]\t Batch [50][275]\t Training Loss 0.4069\t Accuracy 0.8850\n",
      "Epoch [3][10]\t Batch [100][275]\t Training Loss 0.3263\t Accuracy 0.9150\n",
      "Epoch [3][10]\t Batch [150][275]\t Training Loss 0.2425\t Accuracy 0.9400\n",
      "Epoch [3][10]\t Batch [200][275]\t Training Loss 0.3529\t Accuracy 0.8850\n",
      "Epoch [3][10]\t Batch [250][275]\t Training Loss 0.3407\t Accuracy 0.9000\n",
      "\n",
      "Epoch [3]\t Average training loss 0.3661\t Average training accuracy 0.8986\n",
      "Epoch [3]\t Average validation loss 0.2820\t Average validation accuracy 0.9246\n",
      "\n",
      "Epoch [4][10]\t Batch [0][275]\t Training Loss 0.3758\t Accuracy 0.8550\n",
      "Epoch [4][10]\t Batch [50][275]\t Training Loss 0.4066\t Accuracy 0.8950\n",
      "Epoch [4][10]\t Batch [100][275]\t Training Loss 0.4023\t Accuracy 0.9100\n",
      "Epoch [4][10]\t Batch [150][275]\t Training Loss 0.2960\t Accuracy 0.9250\n",
      "Epoch [4][10]\t Batch [200][275]\t Training Loss 0.3931\t Accuracy 0.8750\n",
      "Epoch [4][10]\t Batch [250][275]\t Training Loss 0.2907\t Accuracy 0.9300\n",
      "\n",
      "Epoch [4]\t Average training loss 0.3524\t Average training accuracy 0.9018\n",
      "Epoch [4]\t Average validation loss 0.2724\t Average validation accuracy 0.9292\n",
      "\n",
      "Epoch [5][10]\t Batch [0][275]\t Training Loss 0.3278\t Accuracy 0.9250\n",
      "Epoch [5][10]\t Batch [50][275]\t Training Loss 0.3513\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [100][275]\t Training Loss 0.3819\t Accuracy 0.8900\n",
      "Epoch [5][10]\t Batch [150][275]\t Training Loss 0.5077\t Accuracy 0.8750\n",
      "Epoch [5][10]\t Batch [200][275]\t Training Loss 0.2857\t Accuracy 0.9100\n",
      "Epoch [5][10]\t Batch [250][275]\t Training Loss 0.3782\t Accuracy 0.9000\n",
      "\n",
      "Epoch [5]\t Average training loss 0.3429\t Average training accuracy 0.9036\n",
      "Epoch [5]\t Average validation loss 0.2673\t Average validation accuracy 0.9308\n",
      "\n",
      "Epoch [6][10]\t Batch [0][275]\t Training Loss 0.3691\t Accuracy 0.8950\n",
      "Epoch [6][10]\t Batch [50][275]\t Training Loss 0.3210\t Accuracy 0.9100\n",
      "Epoch [6][10]\t Batch [100][275]\t Training Loss 0.3748\t Accuracy 0.8900\n",
      "Epoch [6][10]\t Batch [150][275]\t Training Loss 0.4044\t Accuracy 0.8800\n",
      "Epoch [6][10]\t Batch [200][275]\t Training Loss 0.2918\t Accuracy 0.9200\n",
      "Epoch [6][10]\t Batch [250][275]\t Training Loss 0.2645\t Accuracy 0.9250\n",
      "\n",
      "Epoch [6]\t Average training loss 0.3355\t Average training accuracy 0.9056\n",
      "Epoch [6]\t Average validation loss 0.2622\t Average validation accuracy 0.9302\n",
      "\n",
      "Epoch [7][10]\t Batch [0][275]\t Training Loss 0.2668\t Accuracy 0.9400\n",
      "Epoch [7][10]\t Batch [50][275]\t Training Loss 0.3605\t Accuracy 0.8800\n",
      "Epoch [7][10]\t Batch [100][275]\t Training Loss 0.3204\t Accuracy 0.9150\n",
      "Epoch [7][10]\t Batch [150][275]\t Training Loss 0.2817\t Accuracy 0.9350\n",
      "Epoch [7][10]\t Batch [200][275]\t Training Loss 0.3477\t Accuracy 0.9150\n",
      "Epoch [7][10]\t Batch [250][275]\t Training Loss 0.3288\t Accuracy 0.8850\n",
      "\n",
      "Epoch [7]\t Average training loss 0.3296\t Average training accuracy 0.9078\n",
      "Epoch [7]\t Average validation loss 0.2585\t Average validation accuracy 0.9306\n",
      "\n",
      "Epoch [8][10]\t Batch [0][275]\t Training Loss 0.3045\t Accuracy 0.9250\n",
      "Epoch [8][10]\t Batch [50][275]\t Training Loss 0.3116\t Accuracy 0.9150\n",
      "Epoch [8][10]\t Batch [100][275]\t Training Loss 0.3880\t Accuracy 0.8750\n",
      "Epoch [8][10]\t Batch [150][275]\t Training Loss 0.3190\t Accuracy 0.9450\n",
      "Epoch [8][10]\t Batch [200][275]\t Training Loss 0.3434\t Accuracy 0.9100\n",
      "Epoch [8][10]\t Batch [250][275]\t Training Loss 0.3635\t Accuracy 0.8900\n",
      "\n",
      "Epoch [8]\t Average training loss 0.3248\t Average training accuracy 0.9093\n",
      "Epoch [8]\t Average validation loss 0.2555\t Average validation accuracy 0.9314\n",
      "\n",
      "Epoch [9][10]\t Batch [0][275]\t Training Loss 0.3496\t Accuracy 0.8900\n",
      "Epoch [9][10]\t Batch [50][275]\t Training Loss 0.2982\t Accuracy 0.9150\n",
      "Epoch [9][10]\t Batch [100][275]\t Training Loss 0.3905\t Accuracy 0.8900\n",
      "Epoch [9][10]\t Batch [150][275]\t Training Loss 0.3643\t Accuracy 0.9000\n",
      "Epoch [9][10]\t Batch [200][275]\t Training Loss 0.4028\t Accuracy 0.8900\n",
      "Epoch [9][10]\t Batch [250][275]\t Training Loss 0.2612\t Accuracy 0.9400\n",
      "\n",
      "Epoch [9]\t Average training loss 0.3209\t Average training accuracy 0.9103\n",
      "Epoch [9]\t Average validation loss 0.2525\t Average validation accuracy 0.9330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    'data_root': 'data',\n",
    "    'max_epoch': 10,\n",
    "    'batch_size': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'momentum': 0.9,\n",
    "    'display_freq': 50,\n",
    "}\n",
    "batch_sizes = [1, 20, 50, 100, 200]\n",
    "accuracys = []\n",
    "for bz in batch_sizes:\n",
    "    cfg['batch_size'] = bz\n",
    "    runner = Solver(cfg)\n",
    "    runner.train()\n",
    "    test_loss, test_acc = runner.test()\n",
    "    accuracys.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.89, 0.9221, 0.9229, 0.9194000000000001, 0.9167000000000001]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][30]\t Batch [0][275]\t Training Loss 2.4267\t Accuracy 0.1550\n",
      "Epoch [0][30]\t Batch [50][275]\t Training Loss 0.7825\t Accuracy 0.8200\n",
      "Epoch [0][30]\t Batch [100][275]\t Training Loss 0.5664\t Accuracy 0.8750\n",
      "Epoch [0][30]\t Batch [150][275]\t Training Loss 0.5168\t Accuracy 0.8850\n",
      "Epoch [0][30]\t Batch [200][275]\t Training Loss 0.5456\t Accuracy 0.8550\n",
      "Epoch [0][30]\t Batch [250][275]\t Training Loss 0.4801\t Accuracy 0.8700\n",
      "\n",
      "Epoch [0]\t Average training loss 0.7258\t Average training accuracy 0.8048\n",
      "Epoch [0]\t Average validation loss 0.3721\t Average validation accuracy 0.9094\n",
      "\n",
      "Epoch [1][30]\t Batch [0][275]\t Training Loss 0.4424\t Accuracy 0.8700\n",
      "Epoch [1][30]\t Batch [50][275]\t Training Loss 0.4632\t Accuracy 0.8550\n",
      "Epoch [1][30]\t Batch [100][275]\t Training Loss 0.3941\t Accuracy 0.8900\n",
      "Epoch [1][30]\t Batch [150][275]\t Training Loss 0.3918\t Accuracy 0.9000\n",
      "Epoch [1][30]\t Batch [200][275]\t Training Loss 0.4679\t Accuracy 0.8600\n",
      "Epoch [1][30]\t Batch [250][275]\t Training Loss 0.4303\t Accuracy 0.9100\n",
      "\n",
      "Epoch [1]\t Average training loss 0.4284\t Average training accuracy 0.8832\n",
      "Epoch [1]\t Average validation loss 0.3171\t Average validation accuracy 0.9176\n",
      "\n",
      "Epoch [2][30]\t Batch [0][275]\t Training Loss 0.3314\t Accuracy 0.9400\n",
      "Epoch [2][30]\t Batch [50][275]\t Training Loss 0.4028\t Accuracy 0.8950\n",
      "Epoch [2][30]\t Batch [100][275]\t Training Loss 0.4090\t Accuracy 0.8950\n",
      "Epoch [2][30]\t Batch [150][275]\t Training Loss 0.3611\t Accuracy 0.8750\n",
      "Epoch [2][30]\t Batch [200][275]\t Training Loss 0.4688\t Accuracy 0.8750\n",
      "Epoch [2][30]\t Batch [250][275]\t Training Loss 0.4176\t Accuracy 0.8700\n",
      "\n",
      "Epoch [2]\t Average training loss 0.3863\t Average training accuracy 0.8927\n",
      "Epoch [2]\t Average validation loss 0.2950\t Average validation accuracy 0.9238\n",
      "\n",
      "Epoch [3][30]\t Batch [0][275]\t Training Loss 0.4027\t Accuracy 0.8950\n",
      "Epoch [3][30]\t Batch [50][275]\t Training Loss 0.3660\t Accuracy 0.9050\n",
      "Epoch [3][30]\t Batch [100][275]\t Training Loss 0.3874\t Accuracy 0.9000\n",
      "Epoch [3][30]\t Batch [150][275]\t Training Loss 0.3687\t Accuracy 0.9000\n",
      "Epoch [3][30]\t Batch [200][275]\t Training Loss 0.4014\t Accuracy 0.9050\n",
      "Epoch [3][30]\t Batch [250][275]\t Training Loss 0.3846\t Accuracy 0.8900\n",
      "\n",
      "Epoch [3]\t Average training loss 0.3650\t Average training accuracy 0.8979\n",
      "Epoch [3]\t Average validation loss 0.2818\t Average validation accuracy 0.9242\n",
      "\n",
      "Epoch [4][30]\t Batch [0][275]\t Training Loss 0.3423\t Accuracy 0.8950\n",
      "Epoch [4][30]\t Batch [50][275]\t Training Loss 0.3150\t Accuracy 0.9250\n",
      "Epoch [4][30]\t Batch [100][275]\t Training Loss 0.2599\t Accuracy 0.9250\n",
      "Epoch [4][30]\t Batch [150][275]\t Training Loss 0.3741\t Accuracy 0.9050\n",
      "Epoch [4][30]\t Batch [200][275]\t Training Loss 0.3725\t Accuracy 0.8850\n",
      "Epoch [4][30]\t Batch [250][275]\t Training Loss 0.3898\t Accuracy 0.9000\n",
      "\n",
      "Epoch [4]\t Average training loss 0.3514\t Average training accuracy 0.9014\n",
      "Epoch [4]\t Average validation loss 0.2739\t Average validation accuracy 0.9270\n",
      "\n",
      "Epoch [5][30]\t Batch [0][275]\t Training Loss 0.2598\t Accuracy 0.9250\n",
      "Epoch [5][30]\t Batch [50][275]\t Training Loss 0.3952\t Accuracy 0.8750\n",
      "Epoch [5][30]\t Batch [100][275]\t Training Loss 0.2869\t Accuracy 0.9300\n",
      "Epoch [5][30]\t Batch [150][275]\t Training Loss 0.3121\t Accuracy 0.9050\n",
      "Epoch [5][30]\t Batch [200][275]\t Training Loss 0.3085\t Accuracy 0.9150\n",
      "Epoch [5][30]\t Batch [250][275]\t Training Loss 0.2754\t Accuracy 0.9300\n",
      "\n",
      "Epoch [5]\t Average training loss 0.3419\t Average training accuracy 0.9034\n",
      "Epoch [5]\t Average validation loss 0.2674\t Average validation accuracy 0.9272\n",
      "\n",
      "Epoch [6][30]\t Batch [0][275]\t Training Loss 0.3852\t Accuracy 0.8950\n",
      "Epoch [6][30]\t Batch [50][275]\t Training Loss 0.3585\t Accuracy 0.8850\n",
      "Epoch [6][30]\t Batch [100][275]\t Training Loss 0.4078\t Accuracy 0.8750\n",
      "Epoch [6][30]\t Batch [150][275]\t Training Loss 0.2964\t Accuracy 0.9200\n",
      "Epoch [6][30]\t Batch [200][275]\t Training Loss 0.3222\t Accuracy 0.9100\n",
      "Epoch [6][30]\t Batch [250][275]\t Training Loss 0.3425\t Accuracy 0.8900\n",
      "\n",
      "Epoch [6]\t Average training loss 0.3344\t Average training accuracy 0.9061\n",
      "Epoch [6]\t Average validation loss 0.2621\t Average validation accuracy 0.9292\n",
      "\n",
      "Epoch [7][30]\t Batch [0][275]\t Training Loss 0.3127\t Accuracy 0.9250\n",
      "Epoch [7][30]\t Batch [50][275]\t Training Loss 0.2092\t Accuracy 0.9400\n",
      "Epoch [7][30]\t Batch [100][275]\t Training Loss 0.2860\t Accuracy 0.9150\n",
      "Epoch [7][30]\t Batch [150][275]\t Training Loss 0.4146\t Accuracy 0.8750\n",
      "Epoch [7][30]\t Batch [200][275]\t Training Loss 0.3589\t Accuracy 0.9050\n",
      "Epoch [7][30]\t Batch [250][275]\t Training Loss 0.3381\t Accuracy 0.9050\n",
      "\n",
      "Epoch [7]\t Average training loss 0.3285\t Average training accuracy 0.9075\n",
      "Epoch [7]\t Average validation loss 0.2593\t Average validation accuracy 0.9280\n",
      "\n",
      "Epoch [8][30]\t Batch [0][275]\t Training Loss 0.3397\t Accuracy 0.9000\n",
      "Epoch [8][30]\t Batch [50][275]\t Training Loss 0.3244\t Accuracy 0.9000\n",
      "Epoch [8][30]\t Batch [100][275]\t Training Loss 0.2589\t Accuracy 0.9250\n",
      "Epoch [8][30]\t Batch [150][275]\t Training Loss 0.2740\t Accuracy 0.9150\n",
      "Epoch [8][30]\t Batch [200][275]\t Training Loss 0.3144\t Accuracy 0.8900\n",
      "Epoch [8][30]\t Batch [250][275]\t Training Loss 0.3289\t Accuracy 0.9150\n",
      "\n",
      "Epoch [8]\t Average training loss 0.3237\t Average training accuracy 0.9095\n",
      "Epoch [8]\t Average validation loss 0.2560\t Average validation accuracy 0.9308\n",
      "\n",
      "Epoch [9][30]\t Batch [0][275]\t Training Loss 0.4534\t Accuracy 0.8750\n",
      "Epoch [9][30]\t Batch [50][275]\t Training Loss 0.3735\t Accuracy 0.9050\n",
      "Epoch [9][30]\t Batch [100][275]\t Training Loss 0.3668\t Accuracy 0.9050\n",
      "Epoch [9][30]\t Batch [150][275]\t Training Loss 0.3020\t Accuracy 0.9300\n",
      "Epoch [9][30]\t Batch [200][275]\t Training Loss 0.2343\t Accuracy 0.9250\n",
      "Epoch [9][30]\t Batch [250][275]\t Training Loss 0.3270\t Accuracy 0.8900\n",
      "\n",
      "Epoch [9]\t Average training loss 0.3197\t Average training accuracy 0.9104\n",
      "Epoch [9]\t Average validation loss 0.2531\t Average validation accuracy 0.9300\n",
      "\n",
      "Epoch [10][30]\t Batch [0][275]\t Training Loss 0.2706\t Accuracy 0.9350\n",
      "Epoch [10][30]\t Batch [50][275]\t Training Loss 0.3644\t Accuracy 0.9150\n",
      "Epoch [10][30]\t Batch [100][275]\t Training Loss 0.2449\t Accuracy 0.9350\n",
      "Epoch [10][30]\t Batch [150][275]\t Training Loss 0.3093\t Accuracy 0.9150\n",
      "Epoch [10][30]\t Batch [200][275]\t Training Loss 0.2631\t Accuracy 0.9200\n",
      "Epoch [10][30]\t Batch [250][275]\t Training Loss 0.2933\t Accuracy 0.9150\n",
      "\n",
      "Epoch [10]\t Average training loss 0.3163\t Average training accuracy 0.9117\n",
      "Epoch [10]\t Average validation loss 0.2509\t Average validation accuracy 0.9310\n",
      "\n",
      "Epoch [11][30]\t Batch [0][275]\t Training Loss 0.2884\t Accuracy 0.9100\n",
      "Epoch [11][30]\t Batch [50][275]\t Training Loss 0.2515\t Accuracy 0.9400\n",
      "Epoch [11][30]\t Batch [100][275]\t Training Loss 0.2710\t Accuracy 0.9350\n",
      "Epoch [11][30]\t Batch [150][275]\t Training Loss 0.2376\t Accuracy 0.9300\n",
      "Epoch [11][30]\t Batch [200][275]\t Training Loss 0.3169\t Accuracy 0.9050\n",
      "Epoch [11][30]\t Batch [250][275]\t Training Loss 0.3060\t Accuracy 0.9350\n",
      "\n",
      "Epoch [11]\t Average training loss 0.3133\t Average training accuracy 0.9123\n",
      "Epoch [11]\t Average validation loss 0.2492\t Average validation accuracy 0.9316\n",
      "\n",
      "Epoch [12][30]\t Batch [0][275]\t Training Loss 0.3913\t Accuracy 0.8950\n",
      "Epoch [12][30]\t Batch [50][275]\t Training Loss 0.2594\t Accuracy 0.9250\n",
      "Epoch [12][30]\t Batch [100][275]\t Training Loss 0.2280\t Accuracy 0.9350\n",
      "Epoch [12][30]\t Batch [150][275]\t Training Loss 0.3731\t Accuracy 0.9000\n",
      "Epoch [12][30]\t Batch [200][275]\t Training Loss 0.3256\t Accuracy 0.9200\n",
      "Epoch [12][30]\t Batch [250][275]\t Training Loss 0.2914\t Accuracy 0.9050\n",
      "\n",
      "Epoch [12]\t Average training loss 0.3106\t Average training accuracy 0.9130\n",
      "Epoch [12]\t Average validation loss 0.2472\t Average validation accuracy 0.9332\n",
      "\n",
      "Epoch [13][30]\t Batch [0][275]\t Training Loss 0.2573\t Accuracy 0.9450\n",
      "Epoch [13][30]\t Batch [50][275]\t Training Loss 0.3117\t Accuracy 0.9250\n",
      "Epoch [13][30]\t Batch [100][275]\t Training Loss 0.3404\t Accuracy 0.9150\n",
      "Epoch [13][30]\t Batch [150][275]\t Training Loss 0.2343\t Accuracy 0.9250\n",
      "Epoch [13][30]\t Batch [200][275]\t Training Loss 0.3717\t Accuracy 0.9000\n",
      "Epoch [13][30]\t Batch [250][275]\t Training Loss 0.3255\t Accuracy 0.9150\n",
      "\n",
      "Epoch [13]\t Average training loss 0.3082\t Average training accuracy 0.9141\n",
      "Epoch [13]\t Average validation loss 0.2464\t Average validation accuracy 0.9320\n",
      "\n",
      "Epoch [14][30]\t Batch [0][275]\t Training Loss 0.2580\t Accuracy 0.9150\n",
      "Epoch [14][30]\t Batch [50][275]\t Training Loss 0.3708\t Accuracy 0.8950\n",
      "Epoch [14][30]\t Batch [100][275]\t Training Loss 0.3027\t Accuracy 0.9050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14][30]\t Batch [150][275]\t Training Loss 0.2576\t Accuracy 0.9200\n",
      "Epoch [14][30]\t Batch [200][275]\t Training Loss 0.2918\t Accuracy 0.9150\n",
      "Epoch [14][30]\t Batch [250][275]\t Training Loss 0.4021\t Accuracy 0.8900\n",
      "\n",
      "Epoch [14]\t Average training loss 0.3062\t Average training accuracy 0.9141\n",
      "Epoch [14]\t Average validation loss 0.2451\t Average validation accuracy 0.9332\n",
      "\n",
      "Epoch [15][30]\t Batch [0][275]\t Training Loss 0.3220\t Accuracy 0.8850\n",
      "Epoch [15][30]\t Batch [50][275]\t Training Loss 0.2643\t Accuracy 0.9100\n",
      "Epoch [15][30]\t Batch [100][275]\t Training Loss 0.3713\t Accuracy 0.9350\n",
      "Epoch [15][30]\t Batch [150][275]\t Training Loss 0.2950\t Accuracy 0.9200\n",
      "Epoch [15][30]\t Batch [200][275]\t Training Loss 0.2494\t Accuracy 0.9300\n",
      "Epoch [15][30]\t Batch [250][275]\t Training Loss 0.3672\t Accuracy 0.9350\n",
      "\n",
      "Epoch [15]\t Average training loss 0.3042\t Average training accuracy 0.9145\n",
      "Epoch [15]\t Average validation loss 0.2436\t Average validation accuracy 0.9348\n",
      "\n",
      "Epoch [16][30]\t Batch [0][275]\t Training Loss 0.2379\t Accuracy 0.9500\n",
      "Epoch [16][30]\t Batch [50][275]\t Training Loss 0.2681\t Accuracy 0.9400\n",
      "Epoch [16][30]\t Batch [100][275]\t Training Loss 0.3224\t Accuracy 0.9000\n",
      "Epoch [16][30]\t Batch [150][275]\t Training Loss 0.3020\t Accuracy 0.9150\n",
      "Epoch [16][30]\t Batch [200][275]\t Training Loss 0.3489\t Accuracy 0.9100\n",
      "Epoch [16][30]\t Batch [250][275]\t Training Loss 0.2898\t Accuracy 0.9050\n",
      "\n",
      "Epoch [16]\t Average training loss 0.3023\t Average training accuracy 0.9157\n",
      "Epoch [16]\t Average validation loss 0.2428\t Average validation accuracy 0.9348\n",
      "\n",
      "Epoch [17][30]\t Batch [0][275]\t Training Loss 0.2393\t Accuracy 0.9250\n",
      "Epoch [17][30]\t Batch [50][275]\t Training Loss 0.2156\t Accuracy 0.9250\n",
      "Epoch [17][30]\t Batch [100][275]\t Training Loss 0.3198\t Accuracy 0.9000\n",
      "Epoch [17][30]\t Batch [150][275]\t Training Loss 0.4793\t Accuracy 0.8750\n",
      "Epoch [17][30]\t Batch [200][275]\t Training Loss 0.3250\t Accuracy 0.9050\n",
      "Epoch [17][30]\t Batch [250][275]\t Training Loss 0.2441\t Accuracy 0.9400\n",
      "\n",
      "Epoch [17]\t Average training loss 0.3008\t Average training accuracy 0.9159\n",
      "Epoch [17]\t Average validation loss 0.2417\t Average validation accuracy 0.9346\n",
      "\n",
      "Epoch [18][30]\t Batch [0][275]\t Training Loss 0.2786\t Accuracy 0.9400\n",
      "Epoch [18][30]\t Batch [50][275]\t Training Loss 0.3117\t Accuracy 0.9050\n",
      "Epoch [18][30]\t Batch [100][275]\t Training Loss 0.3674\t Accuracy 0.9100\n",
      "Epoch [18][30]\t Batch [150][275]\t Training Loss 0.2280\t Accuracy 0.9350\n",
      "Epoch [18][30]\t Batch [200][275]\t Training Loss 0.2993\t Accuracy 0.9350\n",
      "Epoch [18][30]\t Batch [250][275]\t Training Loss 0.3656\t Accuracy 0.8950\n",
      "\n",
      "Epoch [18]\t Average training loss 0.2994\t Average training accuracy 0.9163\n",
      "Epoch [18]\t Average validation loss 0.2407\t Average validation accuracy 0.9340\n",
      "\n",
      "Epoch [19][30]\t Batch [0][275]\t Training Loss 0.3067\t Accuracy 0.9100\n",
      "Epoch [19][30]\t Batch [50][275]\t Training Loss 0.2808\t Accuracy 0.9150\n",
      "Epoch [19][30]\t Batch [100][275]\t Training Loss 0.3492\t Accuracy 0.9000\n",
      "Epoch [19][30]\t Batch [150][275]\t Training Loss 0.1930\t Accuracy 0.9450\n",
      "Epoch [19][30]\t Batch [200][275]\t Training Loss 0.3389\t Accuracy 0.9050\n",
      "Epoch [19][30]\t Batch [250][275]\t Training Loss 0.3281\t Accuracy 0.9050\n",
      "\n",
      "Epoch [19]\t Average training loss 0.2979\t Average training accuracy 0.9166\n",
      "Epoch [19]\t Average validation loss 0.2402\t Average validation accuracy 0.9362\n",
      "\n",
      "Epoch [20][30]\t Batch [0][275]\t Training Loss 0.2745\t Accuracy 0.9200\n",
      "Epoch [20][30]\t Batch [50][275]\t Training Loss 0.2910\t Accuracy 0.9100\n",
      "Epoch [20][30]\t Batch [100][275]\t Training Loss 0.2181\t Accuracy 0.9550\n",
      "Epoch [20][30]\t Batch [150][275]\t Training Loss 0.2973\t Accuracy 0.9100\n",
      "Epoch [20][30]\t Batch [200][275]\t Training Loss 0.2458\t Accuracy 0.9250\n",
      "Epoch [20][30]\t Batch [250][275]\t Training Loss 0.2437\t Accuracy 0.9400\n",
      "\n",
      "Epoch [20]\t Average training loss 0.2965\t Average training accuracy 0.9175\n",
      "Epoch [20]\t Average validation loss 0.2387\t Average validation accuracy 0.9356\n",
      "\n",
      "Epoch [21][30]\t Batch [0][275]\t Training Loss 0.3207\t Accuracy 0.9000\n",
      "Epoch [21][30]\t Batch [50][275]\t Training Loss 0.2222\t Accuracy 0.9500\n",
      "Epoch [21][30]\t Batch [100][275]\t Training Loss 0.2777\t Accuracy 0.9200\n",
      "Epoch [21][30]\t Batch [150][275]\t Training Loss 0.3396\t Accuracy 0.8800\n",
      "Epoch [21][30]\t Batch [200][275]\t Training Loss 0.2604\t Accuracy 0.9400\n",
      "Epoch [21][30]\t Batch [250][275]\t Training Loss 0.3923\t Accuracy 0.9000\n",
      "\n",
      "Epoch [21]\t Average training loss 0.2954\t Average training accuracy 0.9181\n",
      "Epoch [21]\t Average validation loss 0.2383\t Average validation accuracy 0.9368\n",
      "\n",
      "Epoch [22][30]\t Batch [0][275]\t Training Loss 0.3085\t Accuracy 0.9150\n",
      "Epoch [22][30]\t Batch [50][275]\t Training Loss 0.2947\t Accuracy 0.9100\n",
      "Epoch [22][30]\t Batch [100][275]\t Training Loss 0.2961\t Accuracy 0.9100\n",
      "Epoch [22][30]\t Batch [150][275]\t Training Loss 0.2362\t Accuracy 0.9250\n",
      "Epoch [22][30]\t Batch [200][275]\t Training Loss 0.2622\t Accuracy 0.9400\n",
      "Epoch [22][30]\t Batch [250][275]\t Training Loss 0.3075\t Accuracy 0.8850\n",
      "\n",
      "Epoch [22]\t Average training loss 0.2941\t Average training accuracy 0.9175\n",
      "Epoch [22]\t Average validation loss 0.2379\t Average validation accuracy 0.9360\n",
      "\n",
      "Epoch [23][30]\t Batch [0][275]\t Training Loss 0.3685\t Accuracy 0.9200\n",
      "Epoch [23][30]\t Batch [50][275]\t Training Loss 0.2693\t Accuracy 0.9200\n",
      "Epoch [23][30]\t Batch [100][275]\t Training Loss 0.2880\t Accuracy 0.9100\n",
      "Epoch [23][30]\t Batch [150][275]\t Training Loss 0.2438\t Accuracy 0.9450\n",
      "Epoch [23][30]\t Batch [200][275]\t Training Loss 0.3371\t Accuracy 0.9150\n",
      "Epoch [23][30]\t Batch [250][275]\t Training Loss 0.2733\t Accuracy 0.9400\n",
      "\n",
      "Epoch [23]\t Average training loss 0.2931\t Average training accuracy 0.9184\n",
      "Epoch [23]\t Average validation loss 0.2367\t Average validation accuracy 0.9362\n",
      "\n",
      "Epoch [24][30]\t Batch [0][275]\t Training Loss 0.3058\t Accuracy 0.9050\n",
      "Epoch [24][30]\t Batch [50][275]\t Training Loss 0.3063\t Accuracy 0.9150\n",
      "Epoch [24][30]\t Batch [100][275]\t Training Loss 0.2606\t Accuracy 0.9100\n",
      "Epoch [24][30]\t Batch [150][275]\t Training Loss 0.3077\t Accuracy 0.9150\n",
      "Epoch [24][30]\t Batch [200][275]\t Training Loss 0.2814\t Accuracy 0.9150\n",
      "Epoch [24][30]\t Batch [250][275]\t Training Loss 0.3901\t Accuracy 0.9050\n",
      "\n",
      "Epoch [24]\t Average training loss 0.2920\t Average training accuracy 0.9190\n",
      "Epoch [24]\t Average validation loss 0.2368\t Average validation accuracy 0.9372\n",
      "\n",
      "Epoch [25][30]\t Batch [0][275]\t Training Loss 0.2412\t Accuracy 0.9150\n",
      "Epoch [25][30]\t Batch [50][275]\t Training Loss 0.2262\t Accuracy 0.9350\n",
      "Epoch [25][30]\t Batch [100][275]\t Training Loss 0.2084\t Accuracy 0.9450\n",
      "Epoch [25][30]\t Batch [150][275]\t Training Loss 0.2246\t Accuracy 0.9450\n",
      "Epoch [25][30]\t Batch [200][275]\t Training Loss 0.3396\t Accuracy 0.9000\n",
      "Epoch [25][30]\t Batch [250][275]\t Training Loss 0.1902\t Accuracy 0.9550\n",
      "\n",
      "Epoch [25]\t Average training loss 0.2913\t Average training accuracy 0.9187\n",
      "Epoch [25]\t Average validation loss 0.2359\t Average validation accuracy 0.9378\n",
      "\n",
      "Epoch [26][30]\t Batch [0][275]\t Training Loss 0.2531\t Accuracy 0.9400\n",
      "Epoch [26][30]\t Batch [50][275]\t Training Loss 0.3374\t Accuracy 0.9100\n",
      "Epoch [26][30]\t Batch [100][275]\t Training Loss 0.3150\t Accuracy 0.9000\n",
      "Epoch [26][30]\t Batch [150][275]\t Training Loss 0.3617\t Accuracy 0.9150\n",
      "Epoch [26][30]\t Batch [200][275]\t Training Loss 0.2818\t Accuracy 0.9350\n",
      "Epoch [26][30]\t Batch [250][275]\t Training Loss 0.4030\t Accuracy 0.8850\n",
      "\n",
      "Epoch [26]\t Average training loss 0.2903\t Average training accuracy 0.9194\n",
      "Epoch [26]\t Average validation loss 0.2352\t Average validation accuracy 0.9368\n",
      "\n",
      "Epoch [27][30]\t Batch [0][275]\t Training Loss 0.1990\t Accuracy 0.9450\n",
      "Epoch [27][30]\t Batch [50][275]\t Training Loss 0.3197\t Accuracy 0.9100\n",
      "Epoch [27][30]\t Batch [100][275]\t Training Loss 0.2938\t Accuracy 0.9300\n",
      "Epoch [27][30]\t Batch [150][275]\t Training Loss 0.2664\t Accuracy 0.9350\n",
      "Epoch [27][30]\t Batch [200][275]\t Training Loss 0.3967\t Accuracy 0.8650\n",
      "Epoch [27][30]\t Batch [250][275]\t Training Loss 0.2099\t Accuracy 0.9600\n",
      "\n",
      "Epoch [27]\t Average training loss 0.2895\t Average training accuracy 0.9195\n",
      "Epoch [27]\t Average validation loss 0.2349\t Average validation accuracy 0.9372\n",
      "\n",
      "Epoch [28][30]\t Batch [0][275]\t Training Loss 0.2563\t Accuracy 0.9250\n",
      "Epoch [28][30]\t Batch [50][275]\t Training Loss 0.2877\t Accuracy 0.9200\n",
      "Epoch [28][30]\t Batch [100][275]\t Training Loss 0.2330\t Accuracy 0.9150\n",
      "Epoch [28][30]\t Batch [150][275]\t Training Loss 0.3218\t Accuracy 0.9300\n",
      "Epoch [28][30]\t Batch [200][275]\t Training Loss 0.2406\t Accuracy 0.9350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28][30]\t Batch [250][275]\t Training Loss 0.2070\t Accuracy 0.9450\n",
      "\n",
      "Epoch [28]\t Average training loss 0.2886\t Average training accuracy 0.9197\n",
      "Epoch [28]\t Average validation loss 0.2347\t Average validation accuracy 0.9378\n",
      "\n",
      "Epoch [29][30]\t Batch [0][275]\t Training Loss 0.2903\t Accuracy 0.9150\n",
      "Epoch [29][30]\t Batch [50][275]\t Training Loss 0.3301\t Accuracy 0.8950\n",
      "Epoch [29][30]\t Batch [100][275]\t Training Loss 0.3573\t Accuracy 0.9150\n",
      "Epoch [29][30]\t Batch [150][275]\t Training Loss 0.4235\t Accuracy 0.8750\n",
      "Epoch [29][30]\t Batch [200][275]\t Training Loss 0.2225\t Accuracy 0.9250\n",
      "Epoch [29][30]\t Batch [250][275]\t Training Loss 0.3128\t Accuracy 0.9100\n",
      "\n",
      "Epoch [29]\t Average training loss 0.2878\t Average training accuracy 0.9201\n",
      "Epoch [29]\t Average validation loss 0.2347\t Average validation accuracy 0.9374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    'data_root': 'data',\n",
    "    'max_epoch': 30,\n",
    "    'batch_size': 200,\n",
    "    'learning_rate': 0.01,\n",
    "    'momentum': 0.9,\n",
    "    'display_freq': 50,\n",
    "}\n",
    "runner = Solver(cfg)\n",
    "loss3, acc3 = runner.train()\n",
    "test_loss, test_acc = runner.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9228000000000001"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAk2ElEQVR4nO3deZxU9Znv8c/Ta3UD3RCaTZY0CooYFZ12xZnEaDLEjTiJIw5xzxBQ3DLX0cxkiInem7jM3BlHvUjUIIkb0cQVt2Ai406LjQGViLg1oDYoq9309tw/6nTbNFXV1V11KLrP9/169Ys65/zqV09zqurbv7OauyMiItGVl+sCREQktxQEIiIRpyAQEYk4BYGISMQpCEREIq4g1wV0V0VFhVdWVua6DBGRXuXVV1/d4O5DEi3rdUFQWVlJdXV1rssQEelVzOz9ZMu0aUhEJOIUBCIiEacgEBGJuF63j0BEsq+pqYna2loaGhpyXYpkKBaLMWrUKAoLC9N+TqhBYGZTgP8C8oHb3P0XnZaXA78BxgS13ODuvwqzJhHZVW1tLQMGDKCyshIzy3U50kPuzsaNG6mtrWXs2LFpPy+0TUNmlg/cDHwLmAicYWYTOzW7EHjD3Q8Gvgb8u5kVhVWTiCTW0NDA4MGDFQK9nJkxePDgbo/swtxHcDiw2t3XuHsjcC8wtVMbBwZY/N3XH/gUaA6xJhFJQiHQN/RkPYYZBCOBDztM1wbzOroJ2B9YB/wZuMTdWzt3ZGYzzKzazKrr6urCqldEJJLCDIJEsdT55gd/C9QAewGTgJvMrGyXJ7nPc/cqd68aMiThiXEiItJDYQZBLTC6w/Qo4n/5d3Qu8DuPWw28C0wIsSYRyVDVNU9TeeVju/xUXfN0Rv2+9957fOUrX0m7/fz581m3rvNXyq5tZs+enVFdc+bM4Q9/+ENGfSRSU1PDUUcdxQEHHMBBBx3Efffd177s3Xff5YgjjmD8+PGcfvrpNDY2AvGdwRdffDHjxo3joIMOYtmyZVmpJcwgWAqMN7OxwQ7gacDDndp8ABwHYGbDgP2ANSHWJCIZ2rCtsVvzw5JOEGTDz372M44//vis91taWsqCBQtYuXIlTzzxBJdeeimbNm0C4IorruCyyy7j7bffZtCgQdx+++0APP7447z99tu8/fbbzJs3j1mzZmWlltAOH3X3ZjObDTxJ/PDRO9x9pZnNDJbPBa4G5pvZn4lvSrrC3TeEVZOIdO2nj6zkjXVbevTc0299MeH8iXuV8ZOTD+jy+c3NzZx99tm89tpr7LvvvixYsIAbbriBRx55hPr6eo4++mhuvfVWHnjgAaqrq5k+fTolJSW8+OKLrFixgksuuYTt27dTXFzM4sWLAVi3bh1TpkzhnXfe4dRTT+W6665L+NotLS2cf/75VFdXY2acd955XHbZZZxzzjmcdNJJVFZW8v3vf7+97YoVK3B33nnnHS688ELq6uooLS3ll7/8JRMmdL1hY999921/vNdeezF06FDq6uooLy/nmWee4e677wbg7LPP5qqrrmLWrFk89NBDnHXWWZgZRx55JJs2bWL9+vWMGDGiy9dLJdTzCNx9EbCo07y5HR6vA74ZZg0i0nusWrWK22+/ncmTJ3Peeedxyy23MHv2bObMmQPAmWeeyaOPPsp3v/tdbrrpJm644QaqqqpobGzk9NNP57777uOwww5jy5YtlJSUAPFNMK+99hrFxcXst99+XHTRRYwePXqX166pqWHt2rWsWLECoP2v8zZVVVXU1NQAcPnllzNlyhQAZsyYwdy5cxk/fjwvv/wyF1xwAc888wx33XUX119//S6vM27cOO6///6d5r3yyis0Njayzz77sHHjRgYOHEhBQfzredSoUaxduxaAtWvX7lR727I9OghEpPfp6i/3yisfS7rsvh8cldFrjx49msmTJwPwve99jxtvvJGxY8dy3XXX8fnnn/Ppp59ywAEHcPLJJ+/0vFWrVjFixAgOO+wwAMrKvjjm5LjjjqO8vByAiRMn8v777ycMgr333ps1a9Zw0UUXceKJJ/LNbyb+G3XhwoUsW7aMp556im3btvHCCy9w2mmntS/fsWMHANOnT2f69Old/s7r16/nzDPP5M477yQvLw/3zsfUfHFIaKplmVAQiMgeo/OXmplxwQUXUF1dzejRo7nqqqsSnizl7km/EIuLi9sf5+fn09yc+FSlQYMGsXz5cp588kluvvlmFi5cyB133LFTm5UrV/KTn/yEJUuWkJ+fT2trKwMHDmwfKXSUzohgy5YtnHjiiVxzzTUceeSRAFRUVLBp0yaam5spKCigtraWvfbaC4iPAD788Iuj8jsuy4QuOici3VLRP/HJ/8nmd8cHH3zAiy/G9zPcc889HHPMMfG+KyrYtm3bTptUBgwYwNatWwGYMGEC69atY+nSpQBs3bo16Rd+Mhs2bKC1tZXvfOc7XH311bsckbN582amTZvGggULaDuMvaysjLFjx/Lb3/4WiAfS8uXLgfiIoKamZpeftt+hsbGRU089lbPOOmunEYWZceyxx7a3u/POO5k6NX4u7imnnMKCBQtwd1566SXKy8sz3iwEGhGISDdV//gbofW9//77c+edd/KDH/yA8ePHM2vWLD777DMOPPBAKisr2zf9AJxzzjnMnDmzfWfxfffdx0UXXUR9fT0lJSXdPuRz7dq1nHvuubS2xs9p/fnPf77T8gcffJD333+ff/zHf2yfV1NTw1133cWsWbO45ppraGpqYtq0aRx88MFdvt7ChQtZsmQJGzduZP78+UD8SKhJkyZx7bXXMm3aNH784x9zyCGHcP755wNwwgknsGjRIsaNG0dpaSm/+lV2Ls1mibY57cmqqqpcdygTya4333yT/fffP9dlSJYkWp9m9qq7VyVqr01DIiIRp01DIhI5RxxxRPvRPW1+/etfc+CBB+aootxSEIgIkPrIm77m5ZdfznUJoenJ5n5tGhIRYrEYGzdu7NGXiOw52m5ME4vFuvU8jQhEhFGjRlFbW4su8977td2qsjsUBCJCYWFht25tKH2LNg2JiEScgkBEJOIUBCIiEacgEBGJOAWBiEjE9bmjhqqueTrhLfMq+heFerEsEZHeqs+NCPaU+6mKiPQWfS4IRESkexQEIiIRpyAQEYk4BYGISMT1uSAI836qIiJ9UZ87fLTtENHH/7yeWXct47GLj+GAvcpzXJWIyJ6rz40I2gwrj1+P++MtDTmuRERkzxZqEJjZFDNbZWarzezKBMsvN7Oa4GeFmbWY2Zey8dojgiBYv1lBICKSSmhBYGb5wM3At4CJwBlmNrFjG3e/3t0nufsk4EfAs+7+aTZef0j/YvIMPlYQiIikFOaI4HBgtbuvcfdG4F5gaor2ZwD3ZOvFC/LzqOhfzEfaNCQiklKYQTAS+LDDdG0wbxdmVgpMAR5IsnyGmVWbWXV3bqU3vDzGR1t2pF+xiEgEhRkElmBesjtjnww8n2yzkLvPc/cqd68aMmRI2gUML4vx0eb6tNuLiERRmEFQC4zuMD0KWJek7TSyuFmozfDyGB9pH4GISEphBsFSYLyZjTWzIuJf9g93bmRm5cBXgYeyXcCwshhbGpqpb2zJdtciIn1GaEHg7s3AbOBJ4E1gobuvNLOZZjazQ9NTgafcfXu2axheFj+EVDuMRUSSC/XMYndfBCzqNG9up+n5wPwwXv+LcwnqGVvRL4yXEBHp9frsmcWgs4tFRNLRp4OgfdPQZh1CKiKSTJ8Ogn7FBQyIFegQUhGRFPp0EEBwLoE2DYmIJNX3g0BnF4uIpNTng2BYWUwXnhMRSaHPB8GI8hifbG2guaU116WIiOyR+nwQDCuL0eqwYVtjrksREdkj9fkg0NnFIiKp9f0gKG87l0BBICKSSISCQOcSiIgk0ueD4EulRRTmmw4hFRFJos8HQV6eMXRATNcbEhFJos8HAcQPIV2vTUMiIglFIgiGlcf4WJuGREQSikQQxO9d3IB7slsmi4hEV2SCoL6phS0NzbkuRURkjxONINC5BCIiSUUrCHTkkIjILqIRBMFlJnQVUhGRXUUiCIaWFQOwXkEgIrKLSARBcUE+g/sVadOQiEgCkQgCCG5QoyAQEdlFZIJgeHlMRw2JiCQQrSDQiEBEZBehBoGZTTGzVWa22syuTNLma2ZWY2YrzezZsGoZXhbj0+2N7GhuCeslRER6pdCCwMzygZuBbwETgTPMbGKnNgOBW4BT3P0A4LSw6mk7hPQTXXNIRGQnYY4IDgdWu/sad28E7gWmdmrzD8Dv3P0DAHf/JKxihumkMhGRhMIMgpHAhx2ma4N5He0LDDKzP5nZq2Z2VqKOzGyGmVWbWXVdXV2PihkRBIHOJRAR2VmYQWAJ5nW+/GcB8FfAicDfAv9mZvvu8iT3ee5e5e5VQ4YM6VExw3R2sYhIQgUh9l0LjO4wPQpYl6DNBnffDmw3syXAwcBfsl1MWayAksJ8bRoSEekkzBHBUmC8mY01syJgGvBwpzYPAX9tZgVmVgocAbwZRjFmxgidSyAisovQRgTu3mxms4EngXzgDndfaWYzg+Vz3f1NM3sCeB1oBW5z9xVh1TSsTOcSiIh0FuamIdx9EbCo07y5naavB64Ps442w8tjvPLup7vjpUREeo3InFkM8RHBJ1sbaG3VLStFRNpEKghGlMdoanE2bm/MdSkiInuMSAVB+yGk2k8gItIuUkGgexeLiOwqUkEwQpeZEBHZRaSCoKJ/Mfl5phGBiEgHkQqC/DxjSP9ijQhERDqIVBBA/Cqk2lksIvKFyAXBiLKYrkAqItJB5IJgeHlMVyAVEekgckEwrCzG1h3NbN/RnOtSRET2CJELguHlxYAOIRURaRO9ICgrAXRSmYhIm+gFgc4uFhHZSfSCoExnF4uIdBS5ICgpyqe8pFDnEoiIBCIXBBAfFehcAhGRuEgGgc4uFhH5QlpBYGb9zCwveLyvmZ1iZoXhlhae4WXF2lksIhJId0SwBIiZ2UhgMXAuMD+sosI2vLyEum07aGppzXUpIiI5l24QmLt/Dvwd8N/ufiowMbyywjW8LIY71G3dketSRERyLu0gMLOjgOnAY8G8gnBKCp/OLhYR+UK6QXAp8CPg9+6+0sz2Bv4YWlUhazu7WBefExFJ8696d38WeBYg2Gm8wd0vDrOwMLWdXaxDSEVE0j9q6G4zKzOzfsAbwCozuzzc0sIzqLSQooI8HUIqIkL6m4YmuvsW4NvAImAMcGZXTzKzKWa2ysxWm9mVCZZ/zcw2m1lN8DOnO8X3lJkxrEy3rBQRgfR3+BYG5w18G7jJ3ZvMzFM9wczygZuBbwC1wFIze9jd3+jU9H/c/aRu1p2xEWUlOpdARIT0RwS3Au8B/YAlZvZlYEsXzzkcWO3ua9y9EbgXmNrTQrNtWHlMIwIREdIMAne/0d1HuvsJHvc+cGwXTxsJfNhhujaY19lRZrbczB43swMSdWRmM8ys2syq6+rq0im5S21nF7unHNiIiPR56e4sLjez/2j7Mjazfyc+Okj5tATzOn/rLgO+7O4HA/8NPJioI3ef5+5V7l41ZMiQdEru0rCyGDuaW9lc35SV/kREeqt0Nw3dAWwF/j742QL8qovn1AKjO0yPAtZ1bODuW9x9W/B4EfF9ERVp1pSREeXxcwl0CKmIRF26QbCPu/8k2N6/xt1/CuzdxXOWAuPNbKyZFQHTgIc7NjCz4WZmwePDg3o2du9X6BmdXSwiEpfuUUP1ZnaMuz8HYGaTgfpUT3D3ZjObDTwJ5AN3BGclzwyWzwW+C8wys+agv2m+mzbaDwvuVKazi0Uk6tINgpnAAjMrD6Y/A87u6knB5p5FnebN7fD4JuCmNGvIqqEDYphpRCAiku4lJpYDB5tZWTC9xcwuBV4PsbZQFRXkMbif7ksgItKtO5QFO3fbzh/4YQj17FbDy3V2sYhIJreqTHR4aK8yvCymEYGIRF4mQdDrz8QarnsXi4ik3kdgZltJ/IVvQEkoFe1Gw8tifPZ5Ew1NLcQK83NdjohITqQMAncfsLsKyYX2Q0i3NPDlwV2dKC0i0jdlsmmo12u7QY32E4hIlEU6CEa0BYH2E4hIhEU6CNo2DWlEICJRFukgGBArpF9RvkYEIhJpkQ4C0CGkIiIKgvKYLkUtIpEW+SAYVhbTFUhFJNIiHwTDy2J8snUHra29/kRpEZEeiXwQjCiP0dzqbNi+I9eliIjkROSDQIeQikjUpXtjmj6p6pqn2bCtEYBTbnq+fX5F/yKqf/yNXJUlIrJbRXpE0BYC6c4XEemLIh0EIiKiIBARiTwFgYhIxCkIREQiLtJBUNG/KOH8Et2tTEQiJNKHjyY6RPTKB17n3qUf8se3PuHYCUNzUJWIyO4V6RFBIledcgAThg/ghwtrWLepPtfliIiELtQgMLMpZrbKzFab2ZUp2h1mZi1m9t0w60lHrDCfW6YfSmNzKxfd8xpNLa25LklEJFShBYGZ5QM3A98CJgJnmNnEJO2uBZ4Mq5bu2ntIf/7P3x3Iq+9/xg1Prsp1OSIioQpzRHA4sNrd17h7I3AvMDVBu4uAB4BPQqyl26ZOGsk/HDGGW5esYfGbH+e6HBGR0IQZBCOBDztM1wbz2pnZSOBUYG6qjsxshplVm1l1XV1d1gtNZs5JE5k4oowfLlzOWu0vEJE+KswgsATzOl/0/z+BK9y9JVVH7j7P3avcvWrIkCHZqq9LbfsLWlqd2Xcvo7FZ+wtEpO8J8/DRWmB0h+lRwLpObaqAe80MoAI4wcya3f3BEOvqlsqKflz7nYO48O5l7Pvjx3dZriuVikhvF+aIYCkw3szGmlkRMA14uGMDdx/r7pXuXgncD1ywJ4VAmxMPGpF0ma5UKiK9XWgjAndvNrPZxI8GygfucPeVZjYzWJ5yv4CIiOweoZ5Z7O6LgEWd5iUMAHc/J8xaREQkMZ1ZLCIScQqCLJj77Du0tHY+IEpEpHdQEKQp2ZVKi/Lz+MXjb/HduS/wTt223VyViEjmzL13/SVbVVXl1dXVuS6jnbvz8PJ1zHloJQ1NLRTkGdsbdz0tQoeZikgumdmr7l6VaJlGBBkyM6ZOGsnTl/0Nx4yrSBgCoMNMRWTPpSDIkqFlMW47O2HYiojs0RQEWRScIS0i0qsoCHajH95Xw/IPN+W6DBGRnUT6VpW725MrP+J3r63lkDEDOefoSq5+9I2E+w60Y1lEdieNCLIs2WGmFf2LeOlfjuMnJ0/ks+2NXHJvTdIdyNqxLCK7k0YEWdbVX/LnTh7L2UdV8uxf6jh3/tLdVJWISHIKghzIyzOOnTA0ZZvbn3uX4yYMpbKiHwBV1zytzUgiEgoFwR7q6kff4OpH32DvIf04fv9h2owkIqFREOyhllx+LIvf+phn3vqEXz3/bq7LEZE+TEGQQxX9i5Ju7hkzuJRzJ4/l3Mlj2drQxIFXPZW0n/nPv0tV5ZfYf0QZ+XmmzUgi0i0KghxK90t5QKww5fKrHnkDgP7FBRz65UHajCQi3aIg6AOeu+JYqt/7jKXvfUr1e5+lbLu5vonyki+CRaMHEVEQ9BKpNiONGlTKqEGlfPuQkQBUXvlY0n4O/ulTjBxYwv4jypi4V1naowcFhkjfpSDoJbL1ZfvPU/bjzfVbeWPdZp556+OUbd/6aAuVg/sRK8zX5iaRPkxBEDEXfG1c++P6xhb2n/NE0rZT/vN/MIORA0u69RoaPYj0LgqCPijVZqSOSoryU/bzX9MmsaZuO2s2bKf2s/qk7f7+1hcZPaiUUYNKGDWopFujB4WGSO4pCPqgbH2BTp00sv3xI8vXJW3n7jy/egMfb22gqxve3f7cuwwvizG8PMaI8phCQ2QPoCCIuHRHD6n8dubRAOxobmH9pga+dsOfkra9+tE30u73qZUfMWRAMUMGFFPRv1ihIRISBUHEpfulmE5gFBfkt18bKZmaOd9g/eYGPtrcwPrNDfzL7/+ctO2MX7+aVm0AT6z4iMH9ixjcr4jB3QiN7gSGwkX6KgWBpCVbX3QDS4sYWFrE/iPKAFIGwSOzj6FuWwN1W3dQt3UHNzz1l6RtZ/4m/dCY//y7DOpXxKDSxOEGiUcZGpFIXxVqEJjZFOC/gHzgNnf/RaflU4GrgVagGbjU3Z8LsyYJXzY2NwEcOKocKG+fThUEj150DBu3N/Lp9h1s3NbINY+9mbRt25nYXTnz9pcpixVSVlJAWRdndzc0tRAr/GLne1ihoYCRMIQWBGaWD9wMfAOoBZaa2cPu3vFTuBh42N3dzA4CFgITwqpJdo/ufCFlKzS+MrJ8p+lUQfDqj4/ns88b+ezzJk6b+2LSdlsamlm7qZ4t9c1saWhK+foT/u0JigryKIsVUl6S+mP1UM1aBsQKGBArZECsIJRRicJFuiPMEcHhwGp3XwNgZvcCU4H2IHD3bR3a9wO6OOZE+ppchMbg/sUM7l/cZbuHLpy803SqM7Yv/9v92NLQxJb6JjbXN/FO3fakbS+5tybtWk+b+wKlRQX0K86ntCj1x/XlNRvpV1xAaVH3TgDU6EXCDIKRwIcdpmuBIzo3MrNTgZ8DQ4ETQ6xHerlchEa6Ljx23E7TqUJj8T99la0NzWxtaGJrQzMX3LUsaduCvDw2fd7I2k0tfL6jOWUNp897Ka1ap978PKWF+fQrzqeki3D541ufUFKUT7+iAkqLcx8wCqJwhBkElmDeLn/xu/vvgd+b2d8Q319w/C4dmc0AZgCMGTMmy2VKX5TNo6F60jaVfYb0T7vtPTOO3Gk6VcDc/f0j2N7YwueNzSlHHeUlhdQ3NrNuUxP1TS0pX787t1M97t//RKwwn+KCvJ32lyRy+3PvUlqUT0lhfpeXMGloaqG4IA8zy3kQhdU216EVZhDUAqM7TI8Ckp6V5O5LzGwfM6tw9w2dls0D5gFUVVVp85FkTXc+ZHvyiATg6HEV7Y9TBcGC8w7faTpVuDx44WQ+39GcVsBMGF5GQ1MLO5pbaegiYLpzPsmEf4tfBqWoIC9lu/PmLyVWmEesIJ/iLoLogVdrKSzIoyjfKMzPSxkan25vpLggj+KCPAq6aJvOvETzc31EWphBsBQYb2ZjgbXANOAfOjYws3HAO8HO4kOBImBjiDWJ7BZhhcbuDphJowfuNJ0qCG6efuhO06kCZvmcb1LfFA+X+qYWTrwx+cGC/zxlP3Y0tdLQ3MKtz65J2u7jLQ3tIdTQ1Jq0HcA//XZ5yuUdHXr10+2P8/MSbej4wmlzX6CoII+i/DwK81MH1y1/Wk1RfjxgUnm9dhOF+Xnt/YZxAcjQgsDdm81sNvAk8cNH73D3lWY2M1g+F/gOcJaZNQH1wOnuXV2kQKRvCWNUsieHC0B5aSHlpD4kt03HCyWmCoLHLv7rnaZTBdGSy4+lsaWVpuDnlJueT9r2qpMn0tjSyo6mVnY0t3LTH1cnbVuQl0dDUytb6ptpakkdRtc9sSrl8japasuWUM8jcPdFwKJO8+Z2eHwtcG2YNYhE0Z6wySsXAZOuMYNL0257zuSxO02nCoLu7NN582dTaGxuZUdLC4f/78VJ2912VhVNLa00trTS2NzK5fe/nmbl6dOZxSKStlwHTF8JIohf/Td+BeDUI6PjJw7baVpBICJ9UrqhkesgCqttrkPLetsm+aqqKq+urs51GSIiOdHTo4bM7FV3r0q0TCMCEZFeJIzzClIftyQiIn2egkBEJOIUBCIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJxCgIRkYhTEIiIRJyCQEQk4hQEIiIRpyAQEYk4BYGISMSFGgRmNsXMVpnZajO7MsHy6Wb2evDzgpkdHGY9IiKyq9CCwMzygZuBbwETgTPMbGKnZu8CX3X3g4CrgXlh1SMiIomFOSI4HFjt7mvcvRG4F5jasYG7v+DunwWTLwGjQqxHREQSCDMIRgIfdpiuDeYlcz7weIj1iIhIAgUh9m0J5nnChmbHEg+CY5IsnwHMABgzZky26hMREcIdEdQCoztMjwLWdW5kZgcBtwFT3X1joo7cfZ67V7l71ZAhQ0IpVkQkqsIMgqXAeDMba2ZFwDTg4Y4NzGwM8DvgTHf/S4i1iIhIEqFtGnL3ZjObDTwJ5AN3uPtKM5sZLJ8LzAEGA7eYGUCzu1eFVZOIiOzK3BNutt9jmdlWYFUIXVcAG3pBn72tX9Xau/pVrb2r3+70+WV3T7htPcydxWFZFcaowcyqs91vGH32tn5Va+/qV7X2rn6z1acuMSEiEnEKAhGRiOuNQRDWZSjC6Lc31RpWv6q1d/WrWntXv1nps9ftLBYRkezqjSMCERHJIgWBiEjE9aog6Or+Bj3ob7SZ/dHM3jSzlWZ2STbq7NB/vpm9ZmaPZrHPgWZ2v5m9FdR9VBb6vCz4/VeY2T1mFuthP3eY2SdmtqLDvC+Z2dNm9nbw76As9Xt98H/wupn93swGZtpnh2X/y8zczCqyUWsw/6LgvbvSzK7LtE8zm2RmL5lZjZlVm9nhPag14fs/k3WWos9M11fKz2pP1lmqPjNcX8n+DzJaZ2YWM7NXzGx50O9Pg/kZf8Zw917xQ/zs5HeAvYEiYDkwMcM+RwCHBo8HAH/JtM9O/f8QuBt4NIt93gl8P3hcBAzMsL+RxO8LURJMLwTO6WFffwMcCqzoMO864Mrg8ZXAtVnq95tAQfD42u72m6jPYP5o4mfDvw9UZKnWY4E/AMXB9NAs9PkU8K3g8QnAn3pQa8L3fybrLEWfma6vpJ/Vnq6zFLVmur6S9ZvROiN+Ic/+weNC4GXgyGx8xnrTiKDL+xt0l7uvd/dlweOtwJukvlR22sxsFHAi8QvqZYWZlRH/UrgdwN0b3X1TFrouAErMrAAoJcHFAdPh7kuATzvNnko8vAj+/XY2+nX3p9y9OZjs9r0sktQK8H+BfybJlXJ72O8s4BfuviNo80kW+nSgLHhcTg/WWYr3f4/XWbI+s7C+Un1We7TOUvSZ6fpK1m9G68zjtgWThcGPk4XPWG8Kgu7e36BbzKwSOIR4ymbDfxJ/c7ZmqT+Ij4bqgF8Fm5xuM7N+mXTo7muBG4APgPXAZnd/KvNS2w1z9/XBa60Hhmax7zbnkYV7WZjZKcBad1+eeUk72Rf4azN72cyeNbPDstDnpcD1ZvYh8fX3o0w66/T+z8o6S/GZymh9dew3W+usU61ZW1+d+r2UDNeZxTc31wCfAE+7e1bWV28KgrTvb9Dtjs36Aw8Al7r7liz0dxLwibu/mnFxOysgvong/7n7IcB24kPBHgu2J04FxgJ7Af3M7HuZFrq7mNm/As3AXRn2Uwr8K/ELIWZbATCI+DD+cmChmSV6P3fHLOAydx8NXEYwSuyJbL//U/WZ6frq2G/QT8brLEGtWVlfCfrNeJ25e4u7TyI+ojrczL7S3T4S6U1BkNb9DbrLzAqJr6y73P13mfYXmAycYmbvEd+E9XUz+00W+q0FaoO/AgDuJx4MmTgeeNfd69y9ifhlwY/OsM+OPjazEQDBv90aZqdiZmcDJwHTPdhAmoF9iIfh8mC9jQKWmdnwDPuF+Hr7XTC0f4X4KLHbO6I7OZv4ugL4LfFNp92W5P2f0TpL9pnKdH0l6DfjdZak1ozXV5J+s7LOAIJNwn8CppCFz1hvCoIu72/QXUHK3w686e7/kYUaAXD3H7n7KHevJF7nM+6e8V/Z7v4R8KGZ7RfMOg54I8NuPwCONLPS4P/jOOLbNLPlYeIfAIJ/H8pGp2Y2BbgCOMXdP8+0P3f/s7sPdffKYL3VEt/h91GmfQMPAl8HMLN9ie/kz/QqlOuArwaPvw683d0OUrz/e7zOkvWZ6fpK1G+m6yzF7/8gGayvFP1mtM7MbEjb0VZmVkL8j7i3yMZnrLt7l3P5Q3xP+1+IHz30r1no7xjim5deB2qCnxOyXPPXyO5RQ5OA6qDmB4FBWejzp8EbagXwa4KjJXrQzz3E9zM0Ef9Qnk/8fhOLib/pFwNfylK/q4nvM2pbb3Mz7bPT8vfo2VFDiWotAn4T/P8uA76ehT6PAV4lfvTcy8BfZev9n8k6S9Fnpuury89qd9dZilozXV/J+s1onQEHAa8F/a4A5gTzM/6M6RITIiIR15s2DYmISAgUBCIiEacgEBGJOAWBiEjEKQhERCJOQSDSiZm1BFeIbPvJ+Eq3HfqutARXPBXJpYJcFyCyB6r3+Gn8IpGgEYFImszsPTO7Nrgm/CtmNi6Y/2UzW2zxa+0vNrMxwfxhFr/2/vLgp+3SHflm9svgmvJPBWeJiuSMgkBkVyWdNg2d3mHZFnc/HLiJ+BVmCR4vcPeDiF9M7cZg/o3As+5+MPFrQq0M5o8Hbnb3A4BNwHdC/W1EuqAzi0U6MbNt7t4/wfz3iF9uYE1wUbGP3H2wmW0ARrh7UzB/vbtXmFkdMMqD69oHfVQSv3zw+GD6CqDQ3a/ZDb+aSEIaEYh0jyd5nKxNIjs6PG5B++okxxQEIt1zeod/Xwwev0D8KrMA04HngseLiV+Dvu2GIm13pxLZo+gvEZFdlQR3gWrzhLu3HUJabGYvE/8j6oxg3sXAHWZ2OfE7yJ0bzL8EmGdm5xP/y38W8auIiuxRtI9AJE3BPoIqd8/0XgIiexRtGhIRiTiNCEREIk4jAhGRiFMQiIhEnIJARCTiFAQiIhGnIBARibj/D54E3ustO7xHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_and_acc({\n",
    "    \"batch_size=200\": [loss3, acc3],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}